{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import datetime, tqdm\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "pd.set_option('max_columns', 100)\n",
    "#from kaggle.competitions import nflrush\n",
    "from sklearn.model_selection import KFold, RepeatedKFold,GroupKFold\n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense,Dropout, PReLU, BatchNormalization, ELU, GaussianNoise, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\38980\\OneDrive\\Desktop\\study\\kaggle\\NFL\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team abbreviations correct\n",
    "def data_clean(df):\n",
    "#correct name   \n",
    "    df.loc[df['PossessionTeam'] == 'ARZ', 'PossessionTeam'] = 'ARI'\n",
    "    df.loc[df['PossessionTeam'] == 'BLT', 'PossessionTeam'] = 'BAL'\n",
    "    df.loc[df['PossessionTeam'] == 'CLV', 'PossessionTeam'] = 'CLE'\n",
    "    df.loc[df['PossessionTeam'] == 'HST', 'PossessionTeam'] = 'HOU'\n",
    "    df.loc[df['FieldPosition'] == 'ARZ', 'FieldPosition'] = 'ARI'\n",
    "    df.loc[df['FieldPosition'] == 'BLT', 'FieldPosition'] = 'BAL'\n",
    "    df.loc[df['FieldPosition'] == 'CLV', 'FieldPosition'] = 'CLE'\n",
    "    df.loc[df['FieldPosition'] == 'HST', 'FieldPosition'] = 'HOU'\n",
    "\n",
    "# fill null\n",
    "    df = df.fillna(df.median())\n",
    "\n",
    "# offense time and defence time\n",
    "    df['TeamOnOffense'] = \"home\"\n",
    "    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    df['IsOnOffense'] = df.Team == df.TeamOnOffense # Is player on offense?\n",
    "    \n",
    "#time\n",
    "    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    seconds_in_year = 60*60*24*365.25\n",
    "    df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "    df['GameClock'] = df['GameClock'].apply(lambda x: float(x.split(\":\")[0]) + float(x.split(\":\")[1])/60)\n",
    "    df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "#player height\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "\n",
    "#weather\n",
    "    def map_weather(txt):\n",
    "        ans = 1\n",
    "        if pd.isna(txt):\n",
    "            return 0\n",
    "        if 'partly' in txt:\n",
    "            ans*=0.5\n",
    "        if 'climate controlled' in txt or 'indoor' in txt:\n",
    "            return ans*3\n",
    "        if 'sunny' in txt or 'sun' in txt:\n",
    "            return ans*2\n",
    "        if 'clear' in txt:\n",
    "            return ans\n",
    "        if 'cloudy' in txt:\n",
    "            return -ans\n",
    "        if 'rain' in txt or 'rainy' in txt:\n",
    "            return -2*ans\n",
    "        if 'snow' in txt:\n",
    "            return -3*ans\n",
    "        return 0\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['Cleaned_GameWeather'].apply(map_weather)\n",
    "\n",
    "#diff Score    \n",
    "    df[\"DiffScoreBeforePlay_ob\"] = (df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"])\n",
    "    df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]] = - df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]]\n",
    "#Turf\n",
    "    def agrupar_gramado(Turf):\n",
    "        if Turf == 'Artifical':\n",
    "            return 'Artificial'\n",
    "\n",
    "        elif Turf in ('FieldTurf', 'Field turf'):\n",
    "            return 'Field Turf'\n",
    "\n",
    "        elif Turf in ('FieldTurf360', 'FieldTurf 360'):\n",
    "            return 'Field Turf 360'\n",
    "\n",
    "        elif Turf in ('Natural', 'Natural grass', 'Naturall Grass', 'grass', 'natural grass', 'SISGrass', 'Natural Grass'):\n",
    "            return \"Grass\"\n",
    "\n",
    "        elif Turf == \"UBU Sports Speed S5-M\":\n",
    "            return \"UBU Speed Series-S5-M\"\n",
    "\n",
    "        else:\n",
    "            return Turf\n",
    "    df['Turf'] = df['Turf'].apply(agrupar_gramado)\n",
    "#left to right\n",
    "    df['New_X'] = df['X']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_X'] = 120 - df.loc[df['PlayDirection'] == 'left','X']\n",
    "    df['New_Y'] = df['Y']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_Y'] = 160/3 - df.loc[df['PlayDirection'] == 'left','Y']\n",
    "    df['Orientation_std'] = df['Orientation']\n",
    "    df.loc[df['Season'] == 2017, 'Orientation_std'] = df.loc[df['Season'] == 2017, 'Orientation_std'] + 90\n",
    "    #df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std'] = 360 - df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Orientation_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Orientation_std'], 360)\n",
    "    df['Dir_std'] = df['Dir']\n",
    "    #df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = 360 - df.loc[df['PlayDirection'] == 'left', 'Dir_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Dir_std'], 360)\n",
    "    df['YardLine_std'] = 100 - df['YardLine']\n",
    "    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine_std'\n",
    "         ] = df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine']\n",
    "    df[\"Orientation_sin\"] = df[\"Orientation_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Orientation_cos\"] = df[\"Orientation_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_sin\"] = df[\"Dir_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_cos\"] = df[\"Dir_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "\n",
    "#distance and S\n",
    "    #distance to yardline\n",
    "    df['Dis_YardLine'] = df['New_X'] - df['YardLine_std'] - 10\n",
    "    #distance to rusher\n",
    "    def Distance(x1,x2,y1,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "    def Degree(x1,x2,y1,y2):\n",
    "        try:\n",
    "            tan = (y1-y2)/(x1-x2)\n",
    "        except:\n",
    "            tan = 0\n",
    "        degree = 90 - math.atan(tan)/(2*np.pi)*360\n",
    "        return degree\n",
    "    df['IsRusher'] = (df['NflId'] == df['NflIdRusher'])\n",
    "    Rusher =df.loc[df['IsRusher'],['PlayId','X','Y','Dir_std','S']].rename(columns={\"X\":\"Rusher_X\",\"Y\":\"Rusher_Y\",'PossessionTeam':'Offense_Team','Dir_std':'Rusher_Dir_std','S':'Rusher_Speed'})\n",
    "    df = df.merge(Rusher,how = 'left',on = 'PlayId')\n",
    "    df['Distance_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Distance(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Degree(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_Diff'] = df['Degree_to_Rusher'] - df['Rusher_Dir_std']\n",
    "    df['Speed_Ratio'] =  (df['Rusher_Speed']+0.01)/(df['S']+0.01)\n",
    "    #back_direction\n",
    "    def back_direction(orientation):\n",
    "        if orientation > 180.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df['back_oriented_down_field'] = df['Orientation_std'].apply(lambda x: back_direction(x))\n",
    "\n",
    "# Stadium and location clean\n",
    "    def agrupar_local(Location):\n",
    "        if Location == \"Arlington, Texas\":\n",
    "            return \"Arlington, TX\"\n",
    "        elif Location in (\"Baltimore, Maryland\",\"Baltimore, Md.\"):\n",
    "            return \"Baltimore, MD\"\n",
    "        elif Location == \"Charlotte, North Carolina\":\n",
    "            return \"Charlotte, NC\"\n",
    "        elif Location == \"Chicago. IL\":\n",
    "            return \"Chicago, IL\"\n",
    "        elif Location == \"Cincinnati, Ohio\":\n",
    "            return \"Cincinnati, OH\"\n",
    "        elif Location in (\"Cleveland\",\"Cleveland Ohio\",\"Cleveland, Ohio\",\"Cleveland,Ohio\"):\n",
    "            return \"Cleveland, OH\"\n",
    "        elif Location == \"Detroit\":\n",
    "            return \"Detroit, MI\"\n",
    "        elif Location == \"E. Rutherford, NJ\" or Location == \"East Rutherford, N.J.\":\n",
    "            return \"East Rutherford, NJ\"\n",
    "        elif Location == \"Foxborough, Ma\":\n",
    "            return \"Foxborough, MA\"\n",
    "        elif Location == \"Houston, Texas\":\n",
    "            return \"Houston, TX\"\n",
    "        elif Location in (\"Jacksonville Florida\",\"Jacksonville, Fl\",\"Jacksonville, Florida\"):\n",
    "            return \"Jacksonville, FL\"\n",
    "        elif Location == \"London\":\n",
    "            return \"London, England\"\n",
    "        elif Location == \"Los Angeles, Calif.\":\n",
    "            return \"Los Angeles, CA\"\n",
    "        elif Location == \"Miami Gardens, Fla.\":\n",
    "            return \"Miami Gardens, FLA\"\n",
    "        elif Location in (\"New Orleans\",\"New Orleans, La.\"):\n",
    "            return \"New Orleans, LA\"\n",
    "        elif Location == \"Orchard Park NY\":\n",
    "            return \"Orchard Park, NY\"\n",
    "        elif Location == \"Philadelphia, Pa.\":\n",
    "            return \"Philadelphia, PA\"\n",
    "        elif Location == \"Pittsburgh\":\n",
    "            return \"Pittsburgh, PA\"\n",
    "        elif Location == \"Seattle\":\n",
    "            return \"Seattle, WA\"\n",
    "        else:\n",
    "            return Location\n",
    "\n",
    "    df['Location'] = df['Location'].apply(agrupar_local)\n",
    "\n",
    "# stadium types\n",
    "    def agrupar_tipo_estadio(StadiumType):\n",
    "        outdoor       = ['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', 'Outside', 'Outddors', 'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n",
    "        indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', 'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n",
    "        indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "        dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "        dome_open     = ['Domed, Open', 'Domed, open']\n",
    "\n",
    "        if StadiumType in outdoor:\n",
    "            return 'outdoor'\n",
    "        elif StadiumType in indoor_closed:\n",
    "            return 'indoor_closed'\n",
    "        elif StadiumType in indoor_open:\n",
    "            return 'indoor_open'\n",
    "        elif StadiumType in dome_closed:\n",
    "            return 'dome_closed'\n",
    "        elif StadiumType in dome_open:\n",
    "            return 'dome_open'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    df['StadiumType'] = df['StadiumType'].apply(agrupar_tipo_estadio)\n",
    "\n",
    "# wind \n",
    "    def give_me_WindSpeed(x):\n",
    "            x = str(x)\n",
    "            x = x.replace('mph', '').strip()\n",
    "            if '-' in x:\n",
    "                x = (int(x.split('-')[0]) + int(x.split('-')[1])) / 2\n",
    "            elif 'gusts up to' in x:\n",
    "                x = (int(x.split()[0]) + int(x.split()[-1])) / 2\n",
    "            elif 'clam' in x:\n",
    "                x = 0\n",
    "            try:\n",
    "                return float(x)\n",
    "            except:\n",
    "                return -99\n",
    "    df['Cleaned_WindSpeed'] = df['WindSpeed'].apply(give_me_WindSpeed)\n",
    "\n",
    "# wind direction\n",
    "    def agrupa_wind_direction(WindDirection):\n",
    "        wd = str(WindDirection).upper()\n",
    "\n",
    "        if wd == 'N' or 'FROM N' in wd:\n",
    "            return 'north'\n",
    "        if wd == 'S' or 'FROM S' in wd:\n",
    "            return 'south'\n",
    "        if wd == 'W' or 'FROM W' in wd:\n",
    "            return 'west'\n",
    "        if wd == 'E' or 'FROM E' in wd:\n",
    "            return 'east'\n",
    "\n",
    "        if 'FROM SW' in wd or 'FROM SSW' in wd or 'FROM WSW' in wd:\n",
    "            return 'south west'\n",
    "        if 'FROM SE' in wd or 'FROM SSE' in wd or 'FROM ESE' in wd:\n",
    "            return 'south east'\n",
    "        if 'FROM NW' in wd or 'FROM NNW' in wd or 'FROM WNW' in wd:\n",
    "            return 'north west'\n",
    "        if 'FROM NE' in wd or 'FROM NNE' in wd or 'FROM ENE' in wd:\n",
    "            return 'north east'\n",
    "\n",
    "        if 'NW' in wd or 'NORTHWEST' in wd:\n",
    "            return 'north west'\n",
    "        if 'NE' in wd or 'NORTH EAST' in wd:\n",
    "            return 'north east'\n",
    "        if 'SW' in wd or 'SOUTHWEST' in wd:\n",
    "            return 'south west'\n",
    "        if 'SE' in wd or 'SOUTHEAST' in wd:\n",
    "            return 'south east'\n",
    "\n",
    "        return 'unknown'\n",
    "    \n",
    "    df['WindDirection'] = df['WindDirection'].apply(agrupa_wind_direction)\n",
    "\n",
    "# speed\n",
    "    df.loc[df['Season'] == 2017, 'S'] = (df.loc[df['Season'] == 2017, 'S'] - 2.4355) / 1.2930 * 1.4551 + 2.7570\n",
    "    df['Horizontal Speed'] = df['S']*df[\"Dir_sin\"]\n",
    "    df['Vertical Speed'] = df['S']*df[\"Dir_cos\"]\n",
    "# momentum\n",
    "    df['momentum'] = df['S']*df['PlayerWeight']\n",
    "\n",
    "#weight/ height\n",
    "    df['weight_over_height'] = df['PlayerWeight']/df['PlayerHeight']**2\n",
    "\n",
    "#2017?\n",
    "    df['2017'] = df['Season'] == 2017\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:115: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:115: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "train = data_clean(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    df1 = df.loc[df['IsRusher']]\n",
    "    df2 = df.loc[df['IsOnOffense'] & (~df['IsRusher'])]\n",
    "    df3 = df.loc[~df['IsOnOffense']]\n",
    "\n",
    "# max yards\n",
    "    df1['Max_Yards'] = df1['YardLine']\n",
    "    df1.loc[(df1.FieldPosition.fillna('') == df1.PossessionTeam)&(df1.PlayDirection =='left'),  'Max_Yards'] \\\n",
    "    = 100 - df1.loc[(df1.FieldPosition.fillna('') == df1.PossessionTeam)&(df1.PlayDirection =='left'),  'Max_Yards']\n",
    "    df1.loc[(df1.FieldPosition.fillna('') != df1.PossessionTeam)&(df1.PlayDirection =='right'),  'Max_Yards'] \\\n",
    "    = 100 - df1.loc[(df1.FieldPosition.fillna('') != df1.PossessionTeam)&(df1.PlayDirection =='right'),  'Max_Yards']\n",
    "# min_time_to_tacke\n",
    "    df3['Min_Time_Tacke'] = (df3['Distance_to_Rusher']+0.01)/(df3['S']+0.01)\n",
    "\n",
    "# defence_X_Y_spread\n",
    "    Defence_X_Y_std = df3[[\"PlayId\",'New_X','New_Y']].groupby(\"PlayId\").std().rename(columns={'New_X':'Defense_X_std','New_Y':'Defense_Y_std'}) \\\n",
    "    .reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed2_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed2_std'}).reset_index()\n",
    "\n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_Y_Removed2_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(4).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed4_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(2).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed4_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_Y_Removed4_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(4).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Defence_X_Y_std, how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "\n",
    "#distance to QB\n",
    "    dis_QB = df2.loc[df2[\"Position\"] =='QB',['PlayId','Distance_to_Rusher']].groupby(['PlayId']).mean().rename(columns={'Distance_to_Rusher':'dis_to_QB'})\n",
    "    df1 = df1.merge(dis_QB,how = 'left', on='PlayId')\n",
    "#defence min,max,mean,std distance to rusher\n",
    "    stat = df3.groupby(['GameId','PlayId']).agg({'Distance_to_Rusher':['min','max','mean','std']})\n",
    "    stat.columns = stat.columns.droplevel()\n",
    "    df1 = df1.merge(stat,how = 'left', on='PlayId')\n",
    "\n",
    "# offense_X_Y_spread\n",
    "    df2 = df2.sort_values(['PlayId','New_X'])\n",
    "    Offense_X_Removed2_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed2_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed2_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_X_Removed4_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed4_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed4_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Offense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    \n",
    "# nearest offenders to defender\n",
    "    dis_to_closest_offender = pd.DataFrame()\n",
    "    for playid in df3['PlayId'].unique():\n",
    "        offense = df2.loc[df2['PlayId'] == playid]\n",
    "        defence = df3.loc[df3['PlayId'] == playid]\n",
    "        ary = scipy.spatial.distance.cdist(defence[['New_X','New_Y']], offense[['New_X','New_Y']], metric='euclidean')\n",
    "        ary.sort(axis=1)\n",
    "        ary = pd.DataFrame(data = ary)\n",
    "        ary['PlayId'] = playid\n",
    "        ary.reset_index(drop=True, inplace=True)\n",
    "        ary = pd.concat([ary, defence[['NflId']].reset_index(drop=True)], axis=1)\n",
    "        dis_to_closest_offender = dis_to_closest_offender.append(ary)\n",
    "    df3 = df3.merge(dis_to_closest_offender,how = 'left',on = ['PlayId','NflId'])\n",
    "# distance to next defender\n",
    "    def Distance(x1,x2,y1,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "    df3[['Next_X','Next_Y']] = df3[['New_X','New_Y']].shift(periods=-1,fill_value=0)\n",
    "    df3['distance_to_next'] = df3[['Next_X','New_X','Next_Y','New_Y']].apply(lambda x: Distance(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "# personnel_features\n",
    "    def defense_formation(l):\n",
    "        dl = 0\n",
    "        lb = 0\n",
    "        db = 0\n",
    "        other = 0\n",
    "\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            if sub_string[1] == 'DL':\n",
    "                dl += int(sub_string[0])\n",
    "            elif sub_string[1] in ['LB','OL']:\n",
    "                lb += int(sub_string[0])\n",
    "            else:\n",
    "                db += int(sub_string[0])\n",
    "\n",
    "        counts = (dl,lb,db,other)\n",
    "\n",
    "        return counts\n",
    "    def offense_formation(l):\n",
    "        qb = 0\n",
    "        rb = 0\n",
    "        wr = 0\n",
    "        te = 0\n",
    "        ol = 0\n",
    "\n",
    "        sub_total = 0\n",
    "        qb_listed = False\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            pos = sub_string[1]\n",
    "            cnt = int(sub_string[0])\n",
    "\n",
    "            if pos == 'QB':\n",
    "                qb += cnt\n",
    "                sub_total += cnt\n",
    "                qb_listed = True\n",
    "            # Assuming LB is a line backer lined up as full back\n",
    "            elif pos in ['RB','LB']:\n",
    "                rb += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DB is a defensive back and lined up as WR\n",
    "            elif pos in ['WR','DB']:\n",
    "                wr += cnt\n",
    "                sub_total += cnt\n",
    "            elif pos == 'TE':\n",
    "                te += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DL is a defensive lineman lined up as an additional line man\n",
    "            else:\n",
    "                ol += cnt\n",
    "                sub_total += cnt\n",
    "\n",
    "        # If not all 11 players were noted at given positions we need to make some assumptions\n",
    "        # I will assume if a QB is not listed then there was 1 QB on the play\n",
    "        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n",
    "        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n",
    "        if sub_total < 11:\n",
    "            diff = 11 - sub_total\n",
    "            if not qb_listed:\n",
    "                qb += 1\n",
    "                diff -= 1\n",
    "            ol += diff\n",
    "\n",
    "        counts = (qb,rb,wr,te,ol)\n",
    "\n",
    "        return counts\n",
    "    def split_personnel(s):\n",
    "        splits = s.split(',')\n",
    "        for i in range(len(splits)):\n",
    "            splits[i] = splits[i].strip()\n",
    "\n",
    "        return splits    \n",
    "    def personnel_features(df):\n",
    "        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n",
    "        personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n",
    "\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n",
    "        personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n",
    "        personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n",
    "        personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n",
    "\n",
    "        # Let's create some features to specify if the OL is covered\n",
    "        personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n",
    "        personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n",
    "        # Let's create a feature to specify if the defense is preventing the run\n",
    "        # Let's just assume 7 or more DL and LB is run prevention\n",
    "        personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n",
    "\n",
    "        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n",
    "        \n",
    "        return personnel\n",
    "    \n",
    "    personnel = personnel_features(df1)   \n",
    "    df1 = df1.merge(personnel,how = 'left',  on ='PlayId')\n",
    "    \n",
    "#select useful columns    \n",
    "    rusher = df1[['PlayId','TimeDelta','Team','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y', \\\n",
    "                 'Orientation_std','Dir_std','Dis_YardLine','Horizontal Speed','Vertical Speed','S','A','Dis','Position',\\\n",
    "                 'Quarter','GameClock','Down','Distance','OffenseFormation',\\\n",
    "                  'DefendersInTheBox','HomeScoreBeforePlay','VisitorScoreBeforePlay',\\\n",
    "                 'Offense_X_Removed2_std','Offense_Y_Removed2_std','Offense_X_Removed4_std','Offense_Y_Removed4_std',\\\n",
    "                 'Defense_X_std','Defense_Y_std','Defense_X_Removed2_std','Defense_Y_Removed2_std','Defense_X_Removed4_std',\\\n",
    "                 'Defense_Y_Removed4_std',\\\n",
    "                  'num_DL','num_LB','num_DB','num_QB','num_RB','num_WR','num_TE','num_OL','OL_diff','OL_TE_diff','run_def',\\\n",
    "                 'min','max','std','mean','dis_to_QB','Max_Yards','back_oriented_down_field',\"DiffScoreBeforePlay_ob\"]]\n",
    "    rusher = rusher.sort_values('PlayId')\n",
    "    game = df1[['PlayId','Turf']]\n",
    "    game = game.sort_values('PlayId')\n",
    "    offender = df2[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std','back_oriented_down_field',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff']]\n",
    "    offender = offender.sort_values(['PlayId','Distance_to_Rusher'])\n",
    "    defender = df3[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std','back_oriented_down_field',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff','Min_Time_Tacke','Speed_Ratio','distance_to_next']+list(range(2))] #list(range(2)) two closest offenders\n",
    "    defender = defender.sort_values(['PlayId','Distance_to_Rusher'])\n",
    "\n",
    "    \n",
    "    return rusher, game, offender, defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "rusher, game, offender, defender = split_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove some columns\n",
    "rusher = rusher.drop('max',axis = 1)\n",
    "#game = game.drop(['Humidity'], axis = 1)\n",
    "\n",
    "offender = offender.drop(['back_oriented_down_field'],axis = 1)\n",
    "offender = offender.sort_values(['PlayId','Distance_to_Rusher']).groupby('PlayId').head(2)\n",
    "defender = defender.sort_values(['PlayId','Distance_to_Rusher']).drop(['New_Y','back_oriented_down_field','Position'],axis = 1).groupby('PlayId').head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A-Turf Titan', 'ACE', 'Artificial', 'C', 'CB', 'DD GrassMaster',\n",
       "       'DE', 'DT', 'EMPTY', 'FB', 'Field Turf', 'Field Turf 360', 'G',\n",
       "       'Grass', 'HB', 'I_FORM', 'JUMBO', 'NT', 'OG', 'OLB', 'OT',\n",
       "       'PISTOL', 'QB', 'RB', 'SHOTGUN', 'SINGLEBACK', 'T', 'TE',\n",
       "       'Twenty-Four/Seven Turf', 'UBU Speed Series-S5-M', 'WILDCAT', 'WR',\n",
       "       'away', 'home', 'nan'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding fit\n",
    "le = preprocessing.LabelEncoder()\n",
    "categories =[]\n",
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = rusher[i].astype(str)\n",
    "    categories.append(rusher[i].unique())\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = game[i].astype(str)\n",
    "    categories.append(game[i].unique())\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = offender[i].astype(str)\n",
    "    categories.append(offender[i].unique())\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = defender[i].astype(str)\n",
    "    categories.append(defender[i].unique())\n",
    "categories = np.hstack(categories)\n",
    "le.fit(categories)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding transform\n",
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = le.transform(rusher[i])\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = le.transform(game[i])\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = le.transform(offender[i])\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = le.transform(defender[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 32)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape offender\n",
    "offender_players = [offender.drop('PlayId',axis = 1).iloc[np.arange(k, len(offender), 2)].reset_index(drop = True) for k in range(2)]\n",
    "offender_players = np.hstack([t.values for t in offender_players])\n",
    "offender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 114)"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape defender\n",
    "defender_players = [defender.drop('PlayId',axis = 1).iloc[np.arange(k, len(defender), 6)].reset_index(drop = True) for k in range(6)]\n",
    "defender_players = np.hstack([t.values for t in defender_players])\n",
    "defender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_y =train.loc[train['IsRusher'],['Yards','PlayId']].sort_values('PlayId').drop('PlayId',axis = 1)\n",
    "train_x = np.hstack([rusher.drop('PlayId',axis = 1).values,game.drop('PlayId',axis = 1).values,defender_players,offender_players])\n",
    "train_y99 =(train_y + 99).reset_index(drop=True).Yards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def crps_eval(y_pred, dataset, is_higher_better=False):\n",
    "    labels = dataset.get_label()\n",
    "    labels = labels.astype('int')\n",
    "    y_true = np.zeros((len(labels),199))\n",
    "    for i, v in enumerate(labels):\n",
    "        y_true[i, v:] = 1\n",
    "    y_pred = y_pred.reshape(-1, 199, order='F')\n",
    "    y_pred = np.clip(y_pred.cumsum(axis=1), 0, 1)\n",
    "    return 'crps', np.mean((y_pred - y_true)**2), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "params = {'max_depth':5, 'lambda_l1': 1.6, 'lambda_l2': 1.2,\n",
    " 'num_leaves': 32, 'feature_fraction': 0.4,\n",
    " 'subsample': 0.4, 'min_child_samples': 15,\n",
    " 'learning_rate': 0.02,\n",
    " 'num_iterations': 10000, 'random_state': 42,\n",
    " 'objective': 'multiclass',\n",
    " 'min_gain_to_split':0.9,\n",
    " 'num_class':199,\n",
    " 'metric':'None',\n",
    " 'max_bin':200}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\ttraining's crps: 0.0127428\tvalid_1's crps: 0.0133483\n",
      "[200]\ttraining's crps: 0.0117391\tvalid_1's crps: 0.0130523\n",
      "[300]\ttraining's crps: 0.0111141\tvalid_1's crps: 0.012924\n",
      "[400]\ttraining's crps: 0.0107027\tvalid_1's crps: 0.0128641\n",
      "[500]\ttraining's crps: 0.0104175\tvalid_1's crps: 0.0128313\n",
      "[600]\ttraining's crps: 0.0102015\tvalid_1's crps: 0.0128089\n",
      "[700]\ttraining's crps: 0.0100485\tvalid_1's crps: 0.0127969\n",
      "[800]\ttraining's crps: 0.00993492\tvalid_1's crps: 0.0127884\n",
      "[900]\ttraining's crps: 0.00986698\tvalid_1's crps: 0.0127845\n",
      "Early stopping, best iteration is:\n",
      "[926]\ttraining's crps: 0.0098556\tvalid_1's crps: 0.0127836\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\ttraining's crps: 0.0127819\tvalid_1's crps: 0.0132707\n",
      "[200]\ttraining's crps: 0.0117908\tvalid_1's crps: 0.012961\n",
      "[300]\ttraining's crps: 0.0111756\tvalid_1's crps: 0.012834\n",
      "[400]\ttraining's crps: 0.0107908\tvalid_1's crps: 0.0127734\n",
      "[500]\ttraining's crps: 0.0105157\tvalid_1's crps: 0.0127386\n",
      "[600]\ttraining's crps: 0.0103011\tvalid_1's crps: 0.0127151\n",
      "[700]\ttraining's crps: 0.0101419\tvalid_1's crps: 0.0126979\n",
      "[800]\ttraining's crps: 0.0100281\tvalid_1's crps: 0.0126877\n",
      "[900]\ttraining's crps: 0.00995777\tvalid_1's crps: 0.0126828\n",
      "[1000]\ttraining's crps: 0.00992234\tvalid_1's crps: 0.0126793\n",
      "Early stopping, best iteration is:\n",
      "[1058]\ttraining's crps: 0.00991482\tvalid_1's crps: 0.0126786\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-532-6fb4ff5ea7b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                               feval=crps_eval)\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_train\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   2104\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2105\u001b[0m         \"\"\"\n\u001b[1;32m-> 2106\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   2606\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2607\u001b[0m                 \u001b[0mcur_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2608\u001b[1;33m             \u001b[0mfeval_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2609\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2610\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-526-c4b88d2830a2>\u001b[0m in \u001b[0;36mcrps_eval\u001b[1;34m(y_pred, dataset, is_higher_better)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m199\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'crps'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mclip\u001b[1;34m(a, a_min, a_max, out)\u001b[0m\n\u001b[0;32m   1956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m     \"\"\"\n\u001b[1;32m-> 1958\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'clip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "models = []\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "        tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "        vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "        dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "        dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "        model = lgb.train(params, dtrain,\n",
    "                              num_boost_round=100000,\n",
    "                              valid_sets=[dtrain,dvalid],\n",
    "                              early_stopping_rounds=20,\n",
    "                              verbose_eval=100,\n",
    "                              feval=crps_eval)\n",
    "        models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012891320000000001\n",
      "0.01278668\n",
      "0.012749200000000002\n",
      "0.012740859999999998\n",
      "0.012740200000000002\n",
      "0.01273776\n"
     ]
    }
   ],
   "source": [
    "#CV score\n",
    "\n",
    "# for leave out one feature importance compare\n",
    "print(np.mean([0.0129045,0.0128677,0.0127771,0.0127333,0.013174]))\n",
    "\n",
    "# all defense palyer\n",
    "print(np.mean([0.012802,0.0127486,0.0126934,0.0126226,0.0130668]))\n",
    "\n",
    "# 5 closest defender + 2 closest offender l1,l2 = 1.2\n",
    "print(np.mean([0.0127848,0.0127063,0.0126001,0.0126058,0.013049]))\n",
    "\n",
    "# 6 closest defender + 2 closest offender l1,l2 = 1.3, 1.2\n",
    "print(np.mean([0.0127827,0.012679,0.0126066,0.0125891,0.0130469]))\n",
    "\n",
    "# 6 closest defender + 2 closest offender l1,l2 = 1.3, 1.2\n",
    "print(np.mean([0.0127806,0.0126752,0.0126092,0.0125885,0.0130475]))\n",
    "\n",
    "# all defense palyer + 2 closest offender l1,l2 = 1.8  1.4\n",
    "print(np.mean([0.0127711,0.012681,0.0126273,0.0125774,0.013032]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Dense = rusher[['Dis_YardLine','PlayerAge','PlayerHeight','PlayerWeight', \\\n",
    "            'Orientation_std','Dir_std','New_X','New_Y','Horizontal Speed',\\\n",
    "            'Vertical Speed','S','A','Dis','GameClock',\\\n",
    "            'Distance','Max_Yards',\\\n",
    "            'Defense_X_std','Defense_Y_std','Defense_X_Removed2_std',\\\n",
    "            'Offense_Y_Removed2_std',\\\n",
    "           'min','std','mean','Max_Yards','dis_to_QB',\\\n",
    "                 'Quarter','Down','HomeScoreBeforePlay','VisitorScoreBeforePlay',\\\n",
    "                  \"DiffScoreBeforePlay_ob\"\\\n",
    "]]\n",
    "X_Dense = X_Dense.fillna(0)\n",
    "X_Cat = rusher[['Quarter','Down','Position','OffenseFormation']]\n",
    "\n",
    "yards = train.loc[train['IsRusher'],['Yards','PlayId']].\\\n",
    "sort_values('PlayId').drop('PlayId',axis = 1).Yards\n",
    "\n",
    "y = np.zeros((yards.shape[0], 199))\n",
    "for idx, target in enumerate(list(yards)):\n",
    "    y[idx][99 + target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_Dense\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import re\n",
    "from keras.losses import binary_crossentropy\n",
    "from  keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import codecs\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CRPSCallback(Callback):\n",
    "    \n",
    "    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n",
    "        super(CRPSCallback, self).__init__()\n",
    "        self.validation = validation\n",
    "        self.predict_batch_size = predict_batch_size\n",
    "        self.include_on_batch = include_on_batch\n",
    "        \n",
    "        print('validation shape',len(self.validation))\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('CRPS_score_val' in self.params['metrics']):\n",
    "            self.params['metrics'].append('CRPS_score_val')\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if (self.include_on_batch):\n",
    "            logs['CRPS_score_val'] = float('-inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['CRPS_score_val'] = float('-inf')\n",
    "            \n",
    "        if (self.validation):\n",
    "            X_valid, y_valid = self.validation[0], self.validation[1]\n",
    "            y_pred = self.model.predict(X_valid)\n",
    "            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "            val_s = np.round(val_s, 6)\n",
    "            logs['CRPS_score_val'] = val_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_tr,y_tr,x_val,y_val):\n",
    "    inp = Input(shape = (x_tr.shape[1],))\n",
    "    x = Dense(1024, input_dim=X.shape[1], activation='relu')(inp)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    out = Dense(199, activation='softmax')(x)\n",
    "    model = Model(inp,out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n",
    "    #add lookahead\n",
    "#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n",
    "#     lookahead.inject(model) # add into model\n",
    "\n",
    "    \n",
    "    es = EarlyStopping(monitor='CRPS_score_val', \n",
    "                       mode='min',\n",
    "                       restore_best_weights=True, \n",
    "                       verbose=1, \n",
    "                       patience=10)\n",
    "\n",
    "    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n",
    "                                   save_best_only=True, verbose=1, save_weights_only=True)\n",
    "    \n",
    "    bsz = 1024\n",
    "    steps = x_tr.shape[0]/bsz\n",
    "    \n",
    "\n",
    "\n",
    "    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=100, batch_size=bsz,verbose=1)\n",
    "    model.load_weights(\"best_model.h5\")\n",
    "    \n",
    "    y_pred = model.predict(x_val)\n",
    "    y_valid = y_val\n",
    "    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n",
    "    crps = np.round(val_s, 6)\n",
    "\n",
    "    return model,crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/100\n",
      "18536/18536 [==============================] - ETA: 12s - loss: 5.93 - ETA: 6s - loss: 5.8708 - ETA: 4s - loss: 5.859 - ETA: 3s - loss: 5.831 - ETA: 3s - loss: 5.798 - ETA: 2s - loss: 5.782 - ETA: 2s - loss: 5.761 - ETA: 2s - loss: 5.742 - ETA: 1s - loss: 5.731 - ETA: 1s - loss: 5.713 - ETA: 1s - loss: 5.698 - ETA: 1s - loss: 5.680 - ETA: 0s - loss: 5.667 - ETA: 0s - loss: 5.653 - ETA: 0s - loss: 5.643 - ETA: 0s - loss: 5.627 - ETA: 0s - loss: 5.617 - ETA: 0s - loss: 5.603 - 3s 164us/step - loss: 5.6030\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08250, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 5.338 - ETA: 2s - loss: 5.355 - ETA: 1s - loss: 5.310 - ETA: 1s - loss: 5.289 - ETA: 1s - loss: 5.275 - ETA: 1s - loss: 5.267 - ETA: 1s - loss: 5.259 - ETA: 1s - loss: 5.250 - ETA: 1s - loss: 5.244 - ETA: 1s - loss: 5.232 - ETA: 0s - loss: 5.224 - ETA: 0s - loss: 5.213 - ETA: 0s - loss: 5.199 - ETA: 0s - loss: 5.188 - ETA: 0s - loss: 5.174 - ETA: 0s - loss: 5.165 - ETA: 0s - loss: 5.153 - ETA: 0s - loss: 5.145 - 2s 125us/step - loss: 5.1432\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08250 to 0.07857, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 4.871 - ETA: 2s - loss: 4.858 - ETA: 1s - loss: 4.861 - ETA: 1s - loss: 4.825 - ETA: 1s - loss: 4.830 - ETA: 1s - loss: 4.820 - ETA: 1s - loss: 4.797 - ETA: 1s - loss: 4.787 - ETA: 1s - loss: 4.785 - ETA: 1s - loss: 4.778 - ETA: 0s - loss: 4.770 - ETA: 0s - loss: 4.762 - ETA: 0s - loss: 4.751 - ETA: 0s - loss: 4.744 - ETA: 0s - loss: 4.736 - ETA: 0s - loss: 4.725 - ETA: 0s - loss: 4.717 - ETA: 0s - loss: 4.707 - 2s 124us/step - loss: 4.7064\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.07857 to 0.06541, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 4.395 - ETA: 2s - loss: 4.414 - ETA: 1s - loss: 4.414 - ETA: 1s - loss: 4.397 - ETA: 1s - loss: 4.403 - ETA: 1s - loss: 4.400 - ETA: 1s - loss: 4.403 - ETA: 1s - loss: 4.398 - ETA: 1s - loss: 4.388 - ETA: 1s - loss: 4.379 - ETA: 0s - loss: 4.369 - ETA: 0s - loss: 4.358 - ETA: 0s - loss: 4.354 - ETA: 0s - loss: 4.352 - ETA: 0s - loss: 4.348 - ETA: 0s - loss: 4.338 - ETA: 0s - loss: 4.325 - ETA: 0s - loss: 4.308 - 2s 124us/step - loss: 4.3068\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.06541 to 0.04383, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 4.139 - ETA: 2s - loss: 4.096 - ETA: 1s - loss: 4.061 - ETA: 1s - loss: 4.059 - ETA: 1s - loss: 4.028 - ETA: 1s - loss: 4.018 - ETA: 1s - loss: 3.984 - ETA: 1s - loss: 3.979 - ETA: 1s - loss: 3.972 - ETA: 1s - loss: 3.963 - ETA: 0s - loss: 3.957 - ETA: 0s - loss: 3.948 - ETA: 0s - loss: 3.935 - ETA: 0s - loss: 3.930 - ETA: 0s - loss: 3.921 - ETA: 0s - loss: 3.915 - ETA: 0s - loss: 3.898 - ETA: 0s - loss: 3.894 - 2s 125us/step - loss: 3.8943\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.04383 to 0.02620, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 3.689 - ETA: 2s - loss: 3.718 - ETA: 1s - loss: 3.707 - ETA: 1s - loss: 3.700 - ETA: 1s - loss: 3.697 - ETA: 1s - loss: 3.696 - ETA: 1s - loss: 3.680 - ETA: 1s - loss: 3.665 - ETA: 1s - loss: 3.663 - ETA: 1s - loss: 3.648 - ETA: 0s - loss: 3.641 - ETA: 0s - loss: 3.637 - ETA: 0s - loss: 3.620 - ETA: 0s - loss: 3.608 - ETA: 0s - loss: 3.598 - ETA: 0s - loss: 3.591 - ETA: 0s - loss: 3.583 - ETA: 0s - loss: 3.572 - 2s 126us/step - loss: 3.5714\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.02620 to 0.01843, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 3.352 - ETA: 2s - loss: 3.366 - ETA: 1s - loss: 3.372 - ETA: 1s - loss: 3.336 - ETA: 1s - loss: 3.344 - ETA: 1s - loss: 3.341 - ETA: 1s - loss: 3.351 - ETA: 1s - loss: 3.359 - ETA: 1s - loss: 3.352 - ETA: 1s - loss: 3.341 - ETA: 0s - loss: 3.335 - ETA: 0s - loss: 3.327 - ETA: 0s - loss: 3.317 - ETA: 0s - loss: 3.318 - ETA: 0s - loss: 3.312 - ETA: 0s - loss: 3.303 - ETA: 0s - loss: 3.298 - ETA: 0s - loss: 3.293 - 2s 124us/step - loss: 3.2935\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01843 to 0.01555, saving model to best_model.h5\n",
      "Epoch 8/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 3.172 - ETA: 2s - loss: 3.147 - ETA: 1s - loss: 3.152 - ETA: 1s - loss: 3.161 - ETA: 1s - loss: 3.149 - ETA: 1s - loss: 3.148 - ETA: 1s - loss: 3.140 - ETA: 1s - loss: 3.142 - ETA: 1s - loss: 3.141 - ETA: 1s - loss: 3.126 - ETA: 0s - loss: 3.123 - ETA: 0s - loss: 3.122 - ETA: 0s - loss: 3.115 - ETA: 0s - loss: 3.114 - ETA: 0s - loss: 3.115 - ETA: 0s - loss: 3.111 - ETA: 0s - loss: 3.103 - ETA: 0s - loss: 3.100 - 2s 124us/step - loss: 3.1008\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01555 to 0.01439, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 3.033 - ETA: 2s - loss: 3.072 - ETA: 1s - loss: 3.086 - ETA: 1s - loss: 3.088 - ETA: 1s - loss: 3.084 - ETA: 1s - loss: 3.073 - ETA: 1s - loss: 3.060 - ETA: 1s - loss: 3.049 - ETA: 1s - loss: 3.046 - ETA: 1s - loss: 3.032 - ETA: 0s - loss: 3.025 - ETA: 0s - loss: 3.021 - ETA: 0s - loss: 3.012 - ETA: 0s - loss: 3.009 - ETA: 0s - loss: 3.010 - ETA: 0s - loss: 3.009 - ETA: 0s - loss: 3.001 - ETA: 0s - loss: 2.998 - 2s 124us/step - loss: 2.9982\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01439 to 0.01375, saving model to best_model.h5\n",
      "Epoch 10/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.994 - ETA: 2s - loss: 2.953 - ETA: 1s - loss: 2.930 - ETA: 1s - loss: 2.913 - ETA: 1s - loss: 2.903 - ETA: 1s - loss: 2.906 - ETA: 1s - loss: 2.899 - ETA: 1s - loss: 2.900 - ETA: 1s - loss: 2.900 - ETA: 1s - loss: 2.908 - ETA: 0s - loss: 2.905 - ETA: 0s - loss: 2.912 - ETA: 0s - loss: 2.914 - ETA: 0s - loss: 2.915 - ETA: 0s - loss: 2.914 - ETA: 0s - loss: 2.918 - ETA: 0s - loss: 2.918 - ETA: 0s - loss: 2.918 - 2s 125us/step - loss: 2.9188\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01375 to 0.01348, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.861 - ETA: 1s - loss: 2.874 - ETA: 1s - loss: 2.877 - ETA: 1s - loss: 2.881 - ETA: 1s - loss: 2.874 - ETA: 1s - loss: 2.867 - ETA: 1s - loss: 2.867 - ETA: 1s - loss: 2.872 - ETA: 1s - loss: 2.870 - ETA: 1s - loss: 2.870 - ETA: 0s - loss: 2.863 - ETA: 0s - loss: 2.865 - ETA: 0s - loss: 2.866 - ETA: 0s - loss: 2.867 - ETA: 0s - loss: 2.870 - ETA: 0s - loss: 2.868 - ETA: 0s - loss: 2.870 - ETA: 0s - loss: 2.872 - 2s 124us/step - loss: 2.8720\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01348 to 0.01335, saving model to best_model.h5\n",
      "Epoch 12/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.888 - ETA: 2s - loss: 2.881 - ETA: 2s - loss: 2.870 - ETA: 1s - loss: 2.860 - ETA: 1s - loss: 2.843 - ETA: 1s - loss: 2.853 - ETA: 1s - loss: 2.858 - ETA: 1s - loss: 2.854 - ETA: 1s - loss: 2.853 - ETA: 1s - loss: 2.853 - ETA: 0s - loss: 2.844 - ETA: 0s - loss: 2.843 - ETA: 0s - loss: 2.848 - ETA: 0s - loss: 2.845 - ETA: 0s - loss: 2.845 - ETA: 0s - loss: 2.839 - ETA: 0s - loss: 2.836 - ETA: 0s - loss: 2.834 - 2s 126us/step - loss: 2.8352\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01335 to 0.01328, saving model to best_model.h5\n",
      "Epoch 13/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.848 - ETA: 1s - loss: 2.817 - ETA: 1s - loss: 2.831 - ETA: 1s - loss: 2.828 - ETA: 1s - loss: 2.819 - ETA: 1s - loss: 2.818 - ETA: 1s - loss: 2.818 - ETA: 1s - loss: 2.818 - ETA: 1s - loss: 2.822 - ETA: 1s - loss: 2.822 - ETA: 0s - loss: 2.825 - ETA: 0s - loss: 2.819 - ETA: 0s - loss: 2.815 - ETA: 0s - loss: 2.814 - ETA: 0s - loss: 2.813 - ETA: 0s - loss: 2.813 - ETA: 0s - loss: 2.817 - ETA: 0s - loss: 2.819 - 2s 126us/step - loss: 2.8197\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01328 to 0.01323, saving model to best_model.h5\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 2s - loss: 2.842 - ETA: 1s - loss: 2.860 - ETA: 1s - loss: 2.848 - ETA: 1s - loss: 2.836 - ETA: 1s - loss: 2.823 - ETA: 1s - loss: 2.811 - ETA: 1s - loss: 2.806 - ETA: 1s - loss: 2.801 - ETA: 1s - loss: 2.802 - ETA: 1s - loss: 2.802 - ETA: 0s - loss: 2.794 - ETA: 0s - loss: 2.795 - ETA: 0s - loss: 2.792 - ETA: 0s - loss: 2.797 - ETA: 0s - loss: 2.797 - ETA: 0s - loss: 2.796 - ETA: 0s - loss: 2.798 - ETA: 0s - loss: 2.798 - 2s 124us/step - loss: 2.7994\n",
      "\n",
      "Epoch 00014: CRPS_score_val improved from 0.01323 to 0.01318, saving model to best_model.h5\n",
      "Epoch 15/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.734 - ETA: 1s - loss: 2.739 - ETA: 1s - loss: 2.765 - ETA: 1s - loss: 2.763 - ETA: 1s - loss: 2.755 - ETA: 1s - loss: 2.757 - ETA: 1s - loss: 2.758 - ETA: 1s - loss: 2.762 - ETA: 1s - loss: 2.766 - ETA: 1s - loss: 2.777 - ETA: 0s - loss: 2.777 - ETA: 0s - loss: 2.776 - ETA: 0s - loss: 2.778 - ETA: 0s - loss: 2.784 - ETA: 0s - loss: 2.781 - ETA: 0s - loss: 2.785 - ETA: 0s - loss: 2.784 - ETA: 0s - loss: 2.783 - 2s 124us/step - loss: 2.7827\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01318 to 0.01314, saving model to best_model.h5\n",
      "Epoch 16/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.761 - ETA: 1s - loss: 2.775 - ETA: 1s - loss: 2.757 - ETA: 1s - loss: 2.742 - ETA: 1s - loss: 2.752 - ETA: 1s - loss: 2.757 - ETA: 1s - loss: 2.759 - ETA: 1s - loss: 2.753 - ETA: 1s - loss: 2.747 - ETA: 1s - loss: 2.752 - ETA: 0s - loss: 2.763 - ETA: 0s - loss: 2.762 - ETA: 0s - loss: 2.768 - ETA: 0s - loss: 2.772 - ETA: 0s - loss: 2.778 - ETA: 0s - loss: 2.776 - ETA: 0s - loss: 2.776 - ETA: 0s - loss: 2.774 - 2s 124us/step - loss: 2.7768\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01314 to 0.01310, saving model to best_model.h5\n",
      "Epoch 17/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.821 - ETA: 1s - loss: 2.812 - ETA: 1s - loss: 2.798 - ETA: 1s - loss: 2.797 - ETA: 1s - loss: 2.783 - ETA: 1s - loss: 2.789 - ETA: 1s - loss: 2.798 - ETA: 1s - loss: 2.788 - ETA: 1s - loss: 2.782 - ETA: 1s - loss: 2.779 - ETA: 0s - loss: 2.774 - ETA: 0s - loss: 2.771 - ETA: 0s - loss: 2.766 - ETA: 0s - loss: 2.768 - ETA: 0s - loss: 2.765 - ETA: 0s - loss: 2.762 - ETA: 0s - loss: 2.765 - ETA: 0s - loss: 2.762 - 2s 130us/step - loss: 2.7636\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01310 to 0.01308, saving model to best_model.h5\n",
      "Epoch 18/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.786 - ETA: 2s - loss: 2.776 - ETA: 1s - loss: 2.776 - ETA: 1s - loss: 2.763 - ETA: 1s - loss: 2.774 - ETA: 1s - loss: 2.779 - ETA: 1s - loss: 2.782 - ETA: 1s - loss: 2.776 - ETA: 1s - loss: 2.770 - ETA: 1s - loss: 2.766 - ETA: 0s - loss: 2.764 - ETA: 0s - loss: 2.761 - ETA: 0s - loss: 2.757 - ETA: 0s - loss: 2.762 - ETA: 0s - loss: 2.761 - ETA: 0s - loss: 2.758 - ETA: 0s - loss: 2.757 - ETA: 0s - loss: 2.757 - 2s 123us/step - loss: 2.7582\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01308 to 0.01305, saving model to best_model.h5\n",
      "Epoch 19/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.765 - ETA: 2s - loss: 2.712 - ETA: 1s - loss: 2.714 - ETA: 1s - loss: 2.721 - ETA: 1s - loss: 2.722 - ETA: 1s - loss: 2.729 - ETA: 1s - loss: 2.730 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.739 - ETA: 1s - loss: 2.738 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.744 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.746 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.750 - 2s 124us/step - loss: 2.7515\n",
      "\n",
      "Epoch 00019: CRPS_score_val improved from 0.01305 to 0.01303, saving model to best_model.h5\n",
      "Epoch 20/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.745 - ETA: 1s - loss: 2.764 - ETA: 1s - loss: 2.768 - ETA: 1s - loss: 2.769 - ETA: 1s - loss: 2.767 - ETA: 1s - loss: 2.758 - ETA: 1s - loss: 2.754 - ETA: 1s - loss: 2.759 - ETA: 1s - loss: 2.758 - ETA: 1s - loss: 2.758 - ETA: 0s - loss: 2.758 - ETA: 0s - loss: 2.761 - ETA: 0s - loss: 2.757 - ETA: 0s - loss: 2.755 - ETA: 0s - loss: 2.755 - ETA: 0s - loss: 2.754 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.745 - 2s 125us/step - loss: 2.7471\n",
      "\n",
      "Epoch 00020: CRPS_score_val improved from 0.01303 to 0.01299, saving model to best_model.h5\n",
      "Epoch 21/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.774 - ETA: 2s - loss: 2.728 - ETA: 1s - loss: 2.729 - ETA: 1s - loss: 2.728 - ETA: 1s - loss: 2.714 - ETA: 1s - loss: 2.716 - ETA: 1s - loss: 2.717 - ETA: 1s - loss: 2.719 - ETA: 1s - loss: 2.730 - ETA: 1s - loss: 2.731 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.728 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.731 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.736 - 2s 127us/step - loss: 2.7378\n",
      "\n",
      "Epoch 00021: CRPS_score_val improved from 0.01299 to 0.01298, saving model to best_model.h5\n",
      "Epoch 22/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.742 - ETA: 2s - loss: 2.751 - ETA: 1s - loss: 2.753 - ETA: 1s - loss: 2.732 - ETA: 1s - loss: 2.732 - ETA: 1s - loss: 2.731 - ETA: 1s - loss: 2.735 - ETA: 1s - loss: 2.729 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.735 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.732 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.731 - 2s 129us/step - loss: 2.7327\n",
      "\n",
      "Epoch 00022: CRPS_score_val improved from 0.01298 to 0.01296, saving model to best_model.h5\n",
      "Epoch 23/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.757 - ETA: 2s - loss: 2.713 - ETA: 1s - loss: 2.722 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.713 - ETA: 0s - loss: 2.713 - ETA: 0s - loss: 2.715 - ETA: 0s - loss: 2.715 - ETA: 0s - loss: 2.716 - ETA: 0s - loss: 2.715 - ETA: 0s - loss: 2.717 - ETA: 0s - loss: 2.717 - ETA: 0s - loss: 2.718 - 2s 127us/step - loss: 2.7192\n",
      "\n",
      "Epoch 00023: CRPS_score_val improved from 0.01296 to 0.01294, saving model to best_model.h5\n",
      "Epoch 24/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.679 - ETA: 2s - loss: 2.708 - ETA: 1s - loss: 2.719 - ETA: 1s - loss: 2.713 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.709 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.709 - ETA: 1s - loss: 2.716 - ETA: 1s - loss: 2.709 - ETA: 0s - loss: 2.717 - ETA: 0s - loss: 2.713 - ETA: 0s - loss: 2.711 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.715 - ETA: 0s - loss: 2.712 - ETA: 0s - loss: 2.717 - ETA: 0s - loss: 2.718 - 2s 126us/step - loss: 2.7180\n",
      "\n",
      "Epoch 00024: CRPS_score_val improved from 0.01294 to 0.01294, saving model to best_model.h5\n",
      "Epoch 25/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.719 - ETA: 2s - loss: 2.698 - ETA: 1s - loss: 2.707 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.704 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.715 - ETA: 0s - loss: 2.712 - ETA: 0s - loss: 2.720 - ETA: 0s - loss: 2.715 - ETA: 0s - loss: 2.715 - ETA: 0s - loss: 2.718 - ETA: 0s - loss: 2.718 - ETA: 0s - loss: 2.717 - ETA: 0s - loss: 2.713 - 2s 127us/step - loss: 2.7151\n",
      "\n",
      "Epoch 00025: CRPS_score_val improved from 0.01294 to 0.01293, saving model to best_model.h5\n",
      "Epoch 26/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.654 - ETA: 2s - loss: 2.671 - ETA: 1s - loss: 2.671 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.699 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.701 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.702 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.709 - ETA: 0s - loss: 2.709 - ETA: 0s - loss: 2.712 - ETA: 0s - loss: 2.713 - 2s 127us/step - loss: 2.7138\n",
      "\n",
      "Epoch 00026: CRPS_score_val improved from 0.01293 to 0.01291, saving model to best_model.h5\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 2s - loss: 2.684 - ETA: 2s - loss: 2.704 - ETA: 1s - loss: 2.718 - ETA: 1s - loss: 2.718 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.688 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.705 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.709 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.706 - 2s 126us/step - loss: 2.7070\n",
      "\n",
      "Epoch 00027: CRPS_score_val improved from 0.01291 to 0.01291, saving model to best_model.h5\n",
      "Epoch 28/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.716 - ETA: 2s - loss: 2.725 - ETA: 1s - loss: 2.721 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.710 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.710 - ETA: 1s - loss: 2.709 - ETA: 1s - loss: 2.707 - ETA: 0s - loss: 2.709 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.708 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.707 - 2s 126us/step - loss: 2.7085\n",
      "\n",
      "Epoch 00028: CRPS_score_val improved from 0.01291 to 0.01290, saving model to best_model.h5\n",
      "Epoch 29/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.651 - ETA: 2s - loss: 2.686 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.699 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.694 - ETA: 1s - loss: 2.696 - ETA: 0s - loss: 2.702 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.702 - ETA: 0s - loss: 2.702 - ETA: 0s - loss: 2.699 - ETA: 0s - loss: 2.701 - ETA: 0s - loss: 2.699 - ETA: 0s - loss: 2.698 - 2s 125us/step - loss: 2.6981\n",
      "\n",
      "Epoch 00029: CRPS_score_val improved from 0.01290 to 0.01289, saving model to best_model.h5\n",
      "Epoch 30/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.657 - ETA: 2s - loss: 2.666 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.675 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.692 - ETA: 1s - loss: 2.692 - ETA: 1s - loss: 2.694 - ETA: 1s - loss: 2.693 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.694 - ETA: 0s - loss: 2.698 - ETA: 0s - loss: 2.697 - ETA: 0s - loss: 2.700 - ETA: 0s - loss: 2.697 - ETA: 0s - loss: 2.698 - ETA: 0s - loss: 2.696 - 2s 125us/step - loss: 2.6960\n",
      "\n",
      "Epoch 00030: CRPS_score_val improved from 0.01289 to 0.01289, saving model to best_model.h5\n",
      "Epoch 31/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.759 - ETA: 1s - loss: 2.743 - ETA: 1s - loss: 2.732 - ETA: 1s - loss: 2.729 - ETA: 1s - loss: 2.724 - ETA: 1s - loss: 2.704 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.694 - ETA: 0s - loss: 2.700 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.699 - ETA: 0s - loss: 2.699 - ETA: 0s - loss: 2.696 - ETA: 0s - loss: 2.695 - ETA: 0s - loss: 2.696 - ETA: 0s - loss: 2.696 - 2s 125us/step - loss: 2.6959\n",
      "\n",
      "Epoch 00031: CRPS_score_val did not improve from 0.01289\n",
      "Epoch 32/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.686 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.692 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.691 - ETA: 0s - loss: 2.690 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.689 - ETA: 0s - loss: 2.690 - ETA: 0s - loss: 2.689 - ETA: 0s - loss: 2.690 - 2s 126us/step - loss: 2.6914\n",
      "\n",
      "Epoch 00032: CRPS_score_val improved from 0.01289 to 0.01287, saving model to best_model.h5\n",
      "Epoch 33/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.693 - ETA: 2s - loss: 2.701 - ETA: 1s - loss: 2.691 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.691 - ETA: 1s - loss: 2.693 - ETA: 1s - loss: 2.685 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.682 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.689 - 2s 128us/step - loss: 2.6900\n",
      "\n",
      "Epoch 00033: CRPS_score_val improved from 0.01287 to 0.01287, saving model to best_model.h5\n",
      "Epoch 34/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.729 - ETA: 1s - loss: 2.690 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.689 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.685 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.684 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.689 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.682 - 2s 125us/step - loss: 2.6819\n",
      "\n",
      "Epoch 00034: CRPS_score_val improved from 0.01287 to 0.01286, saving model to best_model.h5\n",
      "Epoch 35/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.706 - ETA: 1s - loss: 2.709 - ETA: 1s - loss: 2.697 - ETA: 1s - loss: 2.686 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.686 - ETA: 1s - loss: 2.685 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.675 - ETA: 1s - loss: 2.674 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.683 - 2s 125us/step - loss: 2.6849\n",
      "\n",
      "Epoch 00035: CRPS_score_val improved from 0.01286 to 0.01286, saving model to best_model.h5\n",
      "Epoch 36/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.692 - ETA: 2s - loss: 2.693 - ETA: 1s - loss: 2.691 - ETA: 1s - loss: 2.691 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.678 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.675 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.682 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.678 - 2s 125us/step - loss: 2.6791\n",
      "\n",
      "Epoch 00036: CRPS_score_val improved from 0.01286 to 0.01285, saving model to best_model.h5\n",
      "Epoch 37/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.666 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.657 - ETA: 1s - loss: 2.659 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.677 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.675 - 2s 126us/step - loss: 2.6758\n",
      "\n",
      "Epoch 00037: CRPS_score_val improved from 0.01285 to 0.01285, saving model to best_model.h5\n",
      "Epoch 38/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.648 - ETA: 1s - loss: 2.659 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.671 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.674 - ETA: 1s - loss: 2.673 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.677 - 2s 128us/step - loss: 2.6779\n",
      "\n",
      "Epoch 00038: CRPS_score_val improved from 0.01285 to 0.01285, saving model to best_model.h5\n",
      "Epoch 39/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.654 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.685 - ETA: 1s - loss: 2.678 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.666 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.670 - 2s 125us/step - loss: 2.6706\n",
      "\n",
      "Epoch 00039: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 2s - loss: 2.664 - ETA: 2s - loss: 2.636 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.672 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.665 - 2s 126us/step - loss: 2.6662\n",
      "\n",
      "Epoch 00040: CRPS_score_val improved from 0.01285 to 0.01284, saving model to best_model.h5\n",
      "Epoch 41/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.706 - ETA: 2s - loss: 2.698 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.682 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.673 - 2s 125us/step - loss: 2.6730\n",
      "\n",
      "Epoch 00041: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 42/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.673 - ETA: 2s - loss: 2.668 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.667 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.660 - ETA: 0s - loss: 2.662 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.662 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.666 - 2s 124us/step - loss: 2.6667\n",
      "\n",
      "Epoch 00042: CRPS_score_val improved from 0.01284 to 0.01284, saving model to best_model.h5\n",
      "Epoch 43/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.653 - ETA: 2s - loss: 2.653 - ETA: 1s - loss: 2.649 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.657 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.655 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.657 - 2s 125us/step - loss: 2.6576\n",
      "\n",
      "Epoch 00043: CRPS_score_val improved from 0.01284 to 0.01283, saving model to best_model.h5\n",
      "Epoch 44/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.696 - ETA: 1s - loss: 2.659 - ETA: 1s - loss: 2.688 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.658 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.655 - 2s 125us/step - loss: 2.6558\n",
      "\n",
      "Epoch 00044: CRPS_score_val did not improve from 0.01283\n",
      "Epoch 45/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.592 - ETA: 2s - loss: 2.631 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.647 - ETA: 1s - loss: 2.650 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.653 - ETA: 0s - loss: 2.653 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.654 - 2s 126us/step - loss: 2.6542\n",
      "\n",
      "Epoch 00045: CRPS_score_val improved from 0.01283 to 0.01283, saving model to best_model.h5\n",
      "Epoch 46/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.631 - ETA: 2s - loss: 2.664 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.656 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.653 - 2s 125us/step - loss: 2.6528\n",
      "\n",
      "Epoch 00046: CRPS_score_val did not improve from 0.01283\n",
      "Epoch 47/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.661 - ETA: 2s - loss: 2.689 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.659 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.658 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.653 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.652 - 2s 126us/step - loss: 2.6515\n",
      "\n",
      "Epoch 00047: CRPS_score_val did not improve from 0.01283\n",
      "Epoch 48/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.656 - ETA: 2s - loss: 2.636 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.633 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.643 - 2s 127us/step - loss: 2.6437\n",
      "\n",
      "Epoch 00048: CRPS_score_val did not improve from 0.01283\n",
      "Epoch 49/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.629 - ETA: 2s - loss: 2.648 - ETA: 2s - loss: 2.659 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.655 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.645 - 2s 129us/step - loss: 2.6453\n",
      "\n",
      "Epoch 00049: CRPS_score_val improved from 0.01283 to 0.01282, saving model to best_model.h5\n",
      "Epoch 50/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.591 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.632 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.640 - 2s 129us/step - loss: 2.6413\n",
      "\n",
      "Epoch 00050: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 51/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.611 - ETA: 2s - loss: 2.608 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.640 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.639 - 2s 127us/step - loss: 2.6399\n",
      "\n",
      "Epoch 00051: CRPS_score_val improved from 0.01282 to 0.01282, saving model to best_model.h5\n",
      "Epoch 52/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.654 - ETA: 2s - loss: 2.655 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.650 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.641 - 2s 126us/step - loss: 2.6419\n",
      "\n",
      "Epoch 00052: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 2s - loss: 2.622 - ETA: 2s - loss: 2.635 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.630 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.634 - 2s 125us/step - loss: 2.6346\n",
      "\n",
      "Epoch 00053: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 54/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.651 - ETA: 2s - loss: 2.631 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.630 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.635 - 2s 129us/step - loss: 2.6360\n",
      "\n",
      "Epoch 00054: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 55/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.581 - ETA: 2s - loss: 2.604 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.627 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.631 - 2s 125us/step - loss: 2.6318\n",
      "\n",
      "Epoch 00055: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 56/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.652 - ETA: 2s - loss: 2.642 - ETA: 2s - loss: 2.635 - ETA: 1s - loss: 2.623 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.623 - ETA: 1s - loss: 2.625 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.628 - 2s 126us/step - loss: 2.6284\n",
      "\n",
      "Epoch 00056: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 57/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.632 - ETA: 2s - loss: 2.638 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.624 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.622 - 2s 124us/step - loss: 2.6219\n",
      "\n",
      "Epoch 00057: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 58/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.626 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.623 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.630 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.623 - 2s 125us/step - loss: 2.6242\n",
      "\n",
      "Epoch 00058: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 59/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.589 - ETA: 2s - loss: 2.605 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.623 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.622 - 2s 125us/step - loss: 2.6229\n",
      "\n",
      "Epoch 00059: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 60/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.594 - ETA: 2s - loss: 2.595 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.606 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.620 - 2s 124us/step - loss: 2.6204\n",
      "\n",
      "Epoch 00060: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 61/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.612 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.600 - ETA: 1s - loss: 2.597 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.611 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.612 - 2s 126us/step - loss: 2.6130\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00061: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 00061: early stopping\n",
      "the 1 fold crps is 0.012820\n",
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/100\n",
      "18537/18537 [==============================] - ETA: 12s - loss: 5.84 - ETA: 6s - loss: 5.8594 - ETA: 4s - loss: 5.811 - ETA: 3s - loss: 5.802 - ETA: 3s - loss: 5.777 - ETA: 2s - loss: 5.768 - ETA: 2s - loss: 5.756 - ETA: 2s - loss: 5.744 - ETA: 1s - loss: 5.722 - ETA: 1s - loss: 5.700 - ETA: 1s - loss: 5.688 - ETA: 1s - loss: 5.674 - ETA: 0s - loss: 5.655 - ETA: 0s - loss: 5.642 - ETA: 0s - loss: 5.632 - ETA: 0s - loss: 5.621 - ETA: 0s - loss: 5.606 - ETA: 0s - loss: 5.592 - 3s 156us/step - loss: 5.5909\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08282, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 5.321 - ETA: 1s - loss: 5.305 - ETA: 1s - loss: 5.285 - ETA: 1s - loss: 5.266 - ETA: 1s - loss: 5.246 - ETA: 1s - loss: 5.246 - ETA: 1s - loss: 5.226 - ETA: 1s - loss: 5.219 - ETA: 1s - loss: 5.198 - ETA: 1s - loss: 5.186 - ETA: 0s - loss: 5.178 - ETA: 0s - loss: 5.171 - ETA: 0s - loss: 5.165 - ETA: 0s - loss: 5.159 - ETA: 0s - loss: 5.151 - ETA: 0s - loss: 5.145 - ETA: 0s - loss: 5.131 - ETA: 0s - loss: 5.118 - 2s 123us/step - loss: 5.1167\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08282 to 0.07826, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 4.823 - ETA: 1s - loss: 4.837 - ETA: 1s - loss: 4.811 - ETA: 1s - loss: 4.808 - ETA: 1s - loss: 4.800 - ETA: 1s - loss: 4.816 - ETA: 1s - loss: 4.803 - ETA: 1s - loss: 4.791 - ETA: 1s - loss: 4.774 - ETA: 1s - loss: 4.759 - ETA: 0s - loss: 4.753 - ETA: 0s - loss: 4.744 - ETA: 0s - loss: 4.733 - ETA: 0s - loss: 4.727 - ETA: 0s - loss: 4.718 - ETA: 0s - loss: 4.712 - ETA: 0s - loss: 4.703 - ETA: 0s - loss: 4.692 - 2s 123us/step - loss: 4.6914\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.07826 to 0.06480, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 4.406 - ETA: 1s - loss: 4.454 - ETA: 1s - loss: 4.447 - ETA: 1s - loss: 4.409 - ETA: 1s - loss: 4.402 - ETA: 1s - loss: 4.397 - ETA: 1s - loss: 4.384 - ETA: 1s - loss: 4.377 - ETA: 1s - loss: 4.359 - ETA: 1s - loss: 4.350 - ETA: 0s - loss: 4.349 - ETA: 0s - loss: 4.343 - ETA: 0s - loss: 4.334 - ETA: 0s - loss: 4.327 - ETA: 0s - loss: 4.317 - ETA: 0s - loss: 4.314 - ETA: 0s - loss: 4.306 - ETA: 0s - loss: 4.295 - 2s 123us/step - loss: 4.2952\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.06480 to 0.04382, saving model to best_model.h5\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 4.053 - ETA: 1s - loss: 4.047 - ETA: 1s - loss: 4.031 - ETA: 1s - loss: 4.020 - ETA: 1s - loss: 4.015 - ETA: 1s - loss: 4.026 - ETA: 1s - loss: 4.020 - ETA: 1s - loss: 4.016 - ETA: 1s - loss: 4.009 - ETA: 1s - loss: 4.000 - ETA: 0s - loss: 3.977 - ETA: 0s - loss: 3.973 - ETA: 0s - loss: 3.967 - ETA: 0s - loss: 3.949 - ETA: 0s - loss: 3.948 - ETA: 0s - loss: 3.942 - ETA: 0s - loss: 3.939 - ETA: 0s - loss: 3.930 - 2s 124us/step - loss: 3.9312\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.04382 to 0.02732, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.670 - ETA: 2s - loss: 3.694 - ETA: 1s - loss: 3.695 - ETA: 1s - loss: 3.671 - ETA: 1s - loss: 3.667 - ETA: 1s - loss: 3.654 - ETA: 1s - loss: 3.635 - ETA: 1s - loss: 3.644 - ETA: 1s - loss: 3.647 - ETA: 1s - loss: 3.630 - ETA: 0s - loss: 3.629 - ETA: 0s - loss: 3.630 - ETA: 0s - loss: 3.621 - ETA: 0s - loss: 3.617 - ETA: 0s - loss: 3.608 - ETA: 0s - loss: 3.599 - ETA: 0s - loss: 3.592 - ETA: 0s - loss: 3.582 - 2s 126us/step - loss: 3.5822\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.02732 to 0.01938, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.358 - ETA: 1s - loss: 3.387 - ETA: 1s - loss: 3.388 - ETA: 1s - loss: 3.368 - ETA: 1s - loss: 3.375 - ETA: 1s - loss: 3.367 - ETA: 1s - loss: 3.367 - ETA: 1s - loss: 3.364 - ETA: 1s - loss: 3.374 - ETA: 1s - loss: 3.360 - ETA: 0s - loss: 3.354 - ETA: 0s - loss: 3.361 - ETA: 0s - loss: 3.353 - ETA: 0s - loss: 3.346 - ETA: 0s - loss: 3.340 - ETA: 0s - loss: 3.334 - ETA: 0s - loss: 3.331 - ETA: 0s - loss: 3.323 - 2s 123us/step - loss: 3.3243\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01938 to 0.01579, saving model to best_model.h5\n",
      "Epoch 8/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.277 - ETA: 2s - loss: 3.202 - ETA: 1s - loss: 3.195 - ETA: 1s - loss: 3.185 - ETA: 1s - loss: 3.170 - ETA: 1s - loss: 3.176 - ETA: 1s - loss: 3.177 - ETA: 1s - loss: 3.171 - ETA: 1s - loss: 3.156 - ETA: 1s - loss: 3.152 - ETA: 0s - loss: 3.151 - ETA: 0s - loss: 3.147 - ETA: 0s - loss: 3.141 - ETA: 0s - loss: 3.138 - ETA: 0s - loss: 3.129 - ETA: 0s - loss: 3.125 - ETA: 0s - loss: 3.126 - ETA: 0s - loss: 3.123 - 2s 123us/step - loss: 3.1230\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01579 to 0.01434, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.058 - ETA: 1s - loss: 3.035 - ETA: 1s - loss: 3.054 - ETA: 1s - loss: 3.049 - ETA: 1s - loss: 3.059 - ETA: 1s - loss: 3.038 - ETA: 1s - loss: 3.041 - ETA: 1s - loss: 3.040 - ETA: 1s - loss: 3.027 - ETA: 1s - loss: 3.025 - ETA: 0s - loss: 3.025 - ETA: 0s - loss: 3.017 - ETA: 0s - loss: 3.009 - ETA: 0s - loss: 3.008 - ETA: 0s - loss: 3.000 - ETA: 0s - loss: 2.998 - ETA: 0s - loss: 2.999 - ETA: 0s - loss: 2.998 - 2s 122us/step - loss: 2.9966\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01434 to 0.01376, saving model to best_model.h5\n",
      "Epoch 10/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.921 - ETA: 1s - loss: 2.920 - ETA: 1s - loss: 2.923 - ETA: 1s - loss: 2.917 - ETA: 1s - loss: 2.934 - ETA: 1s - loss: 2.945 - ETA: 1s - loss: 2.947 - ETA: 1s - loss: 2.943 - ETA: 1s - loss: 2.934 - ETA: 0s - loss: 2.931 - ETA: 0s - loss: 2.934 - ETA: 0s - loss: 2.932 - ETA: 0s - loss: 2.930 - ETA: 0s - loss: 2.928 - ETA: 0s - loss: 2.927 - ETA: 0s - loss: 2.922 - ETA: 0s - loss: 2.922 - ETA: 0s - loss: 2.927 - 2s 122us/step - loss: 2.9277\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01376 to 0.01341, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.954 - ETA: 1s - loss: 2.919 - ETA: 1s - loss: 2.903 - ETA: 1s - loss: 2.912 - ETA: 1s - loss: 2.905 - ETA: 1s - loss: 2.906 - ETA: 1s - loss: 2.908 - ETA: 1s - loss: 2.906 - ETA: 1s - loss: 2.891 - ETA: 0s - loss: 2.881 - ETA: 0s - loss: 2.876 - ETA: 0s - loss: 2.880 - ETA: 0s - loss: 2.880 - ETA: 0s - loss: 2.877 - ETA: 0s - loss: 2.876 - ETA: 0s - loss: 2.880 - ETA: 0s - loss: 2.879 - ETA: 0s - loss: 2.882 - 2s 123us/step - loss: 2.8824\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01341 to 0.01332, saving model to best_model.h5\n",
      "Epoch 12/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.826 - ETA: 1s - loss: 2.818 - ETA: 1s - loss: 2.830 - ETA: 1s - loss: 2.833 - ETA: 1s - loss: 2.830 - ETA: 1s - loss: 2.840 - ETA: 1s - loss: 2.829 - ETA: 1s - loss: 2.836 - ETA: 1s - loss: 2.841 - ETA: 0s - loss: 2.839 - ETA: 0s - loss: 2.838 - ETA: 0s - loss: 2.840 - ETA: 0s - loss: 2.842 - ETA: 0s - loss: 2.843 - ETA: 0s - loss: 2.844 - ETA: 0s - loss: 2.844 - ETA: 0s - loss: 2.845 - ETA: 0s - loss: 2.845 - 2s 121us/step - loss: 2.8448\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01332 to 0.01325, saving model to best_model.h5\n",
      "Epoch 13/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.827 - ETA: 1s - loss: 2.844 - ETA: 1s - loss: 2.861 - ETA: 1s - loss: 2.855 - ETA: 1s - loss: 2.846 - ETA: 1s - loss: 2.840 - ETA: 1s - loss: 2.846 - ETA: 1s - loss: 2.847 - ETA: 1s - loss: 2.846 - ETA: 0s - loss: 2.837 - ETA: 0s - loss: 2.835 - ETA: 0s - loss: 2.838 - ETA: 0s - loss: 2.833 - ETA: 0s - loss: 2.841 - ETA: 0s - loss: 2.836 - ETA: 0s - loss: 2.839 - ETA: 0s - loss: 2.836 - ETA: 0s - loss: 2.833 - 2s 122us/step - loss: 2.8338\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01325 to 0.01323, saving model to best_model.h5\n",
      "Epoch 14/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.824 - ETA: 1s - loss: 2.846 - ETA: 1s - loss: 2.817 - ETA: 1s - loss: 2.843 - ETA: 1s - loss: 2.837 - ETA: 1s - loss: 2.825 - ETA: 1s - loss: 2.813 - ETA: 1s - loss: 2.817 - ETA: 1s - loss: 2.819 - ETA: 0s - loss: 2.813 - ETA: 0s - loss: 2.811 - ETA: 0s - loss: 2.811 - ETA: 0s - loss: 2.812 - ETA: 0s - loss: 2.812 - ETA: 0s - loss: 2.813 - ETA: 0s - loss: 2.809 - ETA: 0s - loss: 2.807 - ETA: 0s - loss: 2.804 - 2s 121us/step - loss: 2.8042\n",
      "\n",
      "Epoch 00014: CRPS_score_val improved from 0.01323 to 0.01316, saving model to best_model.h5\n",
      "Epoch 15/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.792 - ETA: 1s - loss: 2.807 - ETA: 1s - loss: 2.815 - ETA: 1s - loss: 2.827 - ETA: 1s - loss: 2.820 - ETA: 1s - loss: 2.817 - ETA: 1s - loss: 2.817 - ETA: 1s - loss: 2.812 - ETA: 1s - loss: 2.806 - ETA: 0s - loss: 2.805 - ETA: 0s - loss: 2.798 - ETA: 0s - loss: 2.797 - ETA: 0s - loss: 2.793 - ETA: 0s - loss: 2.791 - ETA: 0s - loss: 2.793 - ETA: 0s - loss: 2.793 - ETA: 0s - loss: 2.790 - ETA: 0s - loss: 2.789 - 2s 121us/step - loss: 2.7891\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01316 to 0.01313, saving model to best_model.h5\n",
      "Epoch 16/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.837 - ETA: 1s - loss: 2.811 - ETA: 1s - loss: 2.810 - ETA: 1s - loss: 2.800 - ETA: 1s - loss: 2.802 - ETA: 1s - loss: 2.793 - ETA: 1s - loss: 2.789 - ETA: 1s - loss: 2.788 - ETA: 1s - loss: 2.789 - ETA: 1s - loss: 2.788 - ETA: 0s - loss: 2.779 - ETA: 0s - loss: 2.777 - ETA: 0s - loss: 2.783 - ETA: 0s - loss: 2.780 - ETA: 0s - loss: 2.784 - ETA: 0s - loss: 2.778 - ETA: 0s - loss: 2.779 - ETA: 0s - loss: 2.777 - 2s 126us/step - loss: 2.7783\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01313 to 0.01310, saving model to best_model.h5\n",
      "Epoch 17/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.813 - ETA: 2s - loss: 2.755 - ETA: 1s - loss: 2.762 - ETA: 1s - loss: 2.757 - ETA: 1s - loss: 2.762 - ETA: 1s - loss: 2.764 - ETA: 1s - loss: 2.788 - ETA: 1s - loss: 2.793 - ETA: 1s - loss: 2.785 - ETA: 1s - loss: 2.776 - ETA: 0s - loss: 2.780 - ETA: 0s - loss: 2.773 - ETA: 0s - loss: 2.767 - ETA: 0s - loss: 2.768 - ETA: 0s - loss: 2.764 - ETA: 0s - loss: 2.763 - ETA: 0s - loss: 2.766 - ETA: 0s - loss: 2.765 - 2s 125us/step - loss: 2.7652\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01310 to 0.01307, saving model to best_model.h5\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 2.806 - ETA: 1s - loss: 2.777 - ETA: 1s - loss: 2.762 - ETA: 1s - loss: 2.764 - ETA: 1s - loss: 2.765 - ETA: 1s - loss: 2.764 - ETA: 1s - loss: 2.770 - ETA: 1s - loss: 2.770 - ETA: 1s - loss: 2.769 - ETA: 1s - loss: 2.770 - ETA: 0s - loss: 2.770 - ETA: 0s - loss: 2.766 - ETA: 0s - loss: 2.756 - ETA: 0s - loss: 2.759 - ETA: 0s - loss: 2.762 - ETA: 0s - loss: 2.762 - ETA: 0s - loss: 2.760 - ETA: 0s - loss: 2.758 - 2s 122us/step - loss: 2.7585\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01307 to 0.01303, saving model to best_model.h5\n",
      "Epoch 19/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.726 - ETA: 1s - loss: 2.741 - ETA: 1s - loss: 2.761 - ETA: 1s - loss: 2.754 - ETA: 1s - loss: 2.748 - ETA: 1s - loss: 2.751 - ETA: 1s - loss: 2.755 - ETA: 1s - loss: 2.751 - ETA: 1s - loss: 2.745 - ETA: 1s - loss: 2.743 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.744 - ETA: 0s - loss: 2.743 - ETA: 0s - loss: 2.744 - ETA: 0s - loss: 2.746 - ETA: 0s - loss: 2.747 - ETA: 0s - loss: 2.749 - 2s 122us/step - loss: 2.7495\n",
      "\n",
      "Epoch 00019: CRPS_score_val improved from 0.01303 to 0.01302, saving model to best_model.h5\n",
      "Epoch 20/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.723 - ETA: 2s - loss: 2.746 - ETA: 1s - loss: 2.744 - ETA: 1s - loss: 2.744 - ETA: 1s - loss: 2.754 - ETA: 1s - loss: 2.750 - ETA: 1s - loss: 2.745 - ETA: 1s - loss: 2.748 - ETA: 1s - loss: 2.743 - ETA: 1s - loss: 2.746 - ETA: 0s - loss: 2.746 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.743 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.742 - 2s 123us/step - loss: 2.7429\n",
      "\n",
      "Epoch 00020: CRPS_score_val improved from 0.01302 to 0.01298, saving model to best_model.h5\n",
      "Epoch 21/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.724 - ETA: 1s - loss: 2.729 - ETA: 1s - loss: 2.719 - ETA: 1s - loss: 2.716 - ETA: 1s - loss: 2.722 - ETA: 1s - loss: 2.724 - ETA: 1s - loss: 2.729 - ETA: 1s - loss: 2.727 - ETA: 1s - loss: 2.734 - ETA: 1s - loss: 2.732 - ETA: 0s - loss: 2.730 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.735 - ETA: 0s - loss: 2.735 - ETA: 0s - loss: 2.735 - ETA: 0s - loss: 2.735 - 2s 122us/step - loss: 2.7353\n",
      "\n",
      "Epoch 00021: CRPS_score_val improved from 0.01298 to 0.01297, saving model to best_model.h5\n",
      "Epoch 22/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.676 - ETA: 1s - loss: 2.713 - ETA: 1s - loss: 2.707 - ETA: 1s - loss: 2.704 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.710 - ETA: 1s - loss: 2.715 - ETA: 1s - loss: 2.721 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.722 - ETA: 0s - loss: 2.725 - ETA: 0s - loss: 2.724 - ETA: 0s - loss: 2.722 - ETA: 0s - loss: 2.722 - ETA: 0s - loss: 2.729 - ETA: 0s - loss: 2.726 - 2s 123us/step - loss: 2.7273\n",
      "\n",
      "Epoch 00022: CRPS_score_val did not improve from 0.01297\n",
      "Epoch 23/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.660 - ETA: 2s - loss: 2.678 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.722 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.708 - ETA: 0s - loss: 2.708 - ETA: 0s - loss: 2.712 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.716 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.715 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.716 - 2s 122us/step - loss: 2.7169\n",
      "\n",
      "Epoch 00023: CRPS_score_val improved from 0.01297 to 0.01293, saving model to best_model.h5\n",
      "Epoch 24/100\n",
      "18537/18537 [==============================] - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.699 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.699 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.713 - ETA: 1s - loss: 2.714 - ETA: 1s - loss: 2.717 - ETA: 1s - loss: 2.720 - ETA: 0s - loss: 2.718 - ETA: 0s - loss: 2.724 - ETA: 0s - loss: 2.727 - ETA: 0s - loss: 2.727 - ETA: 0s - loss: 2.727 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.720 - 2s 122us/step - loss: 2.7210\n",
      "\n",
      "Epoch 00024: CRPS_score_val did not improve from 0.01293\n",
      "Epoch 25/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.698 - ETA: 2s - loss: 2.723 - ETA: 1s - loss: 2.718 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.710 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.713 - ETA: 1s - loss: 2.715 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.706 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.713 - ETA: 0s - loss: 2.708 - ETA: 0s - loss: 2.711 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.710 - 2s 123us/step - loss: 2.7109\n",
      "\n",
      "Epoch 00025: CRPS_score_val improved from 0.01293 to 0.01291, saving model to best_model.h5\n",
      "Epoch 26/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.705 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.719 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.704 - ETA: 1s - loss: 2.697 - ETA: 1s - loss: 2.693 - ETA: 1s - loss: 2.699 - ETA: 1s - loss: 2.700 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.701 - ETA: 0s - loss: 2.701 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.704 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.705 - 2s 122us/step - loss: 2.7058\n",
      "\n",
      "Epoch 00026: CRPS_score_val improved from 0.01291 to 0.01291, saving model to best_model.h5\n",
      "Epoch 27/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.693 - ETA: 1s - loss: 2.674 - ETA: 1s - loss: 2.675 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.709 - ETA: 1s - loss: 2.713 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.712 - ETA: 0s - loss: 2.709 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.702 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.704 - ETA: 0s - loss: 2.703 - 2s 122us/step - loss: 2.7036\n",
      "\n",
      "Epoch 00027: CRPS_score_val improved from 0.01291 to 0.01290, saving model to best_model.h5\n",
      "Epoch 28/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.721 - ETA: 2s - loss: 2.719 - ETA: 1s - loss: 2.726 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.691 - ETA: 1s - loss: 2.693 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.694 - ETA: 0s - loss: 2.699 - ETA: 0s - loss: 2.697 - ETA: 0s - loss: 2.693 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.694 - ETA: 0s - loss: 2.698 - ETA: 0s - loss: 2.694 - ETA: 0s - loss: 2.696 - 2s 127us/step - loss: 2.6978\n",
      "\n",
      "Epoch 00028: CRPS_score_val improved from 0.01290 to 0.01289, saving model to best_model.h5\n",
      "Epoch 29/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.681 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.659 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.683 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.692 - ETA: 0s - loss: 2.696 - 2s 122us/step - loss: 2.6964\n",
      "\n",
      "Epoch 00029: CRPS_score_val improved from 0.01289 to 0.01288, saving model to best_model.h5\n",
      "Epoch 30/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.717 - ETA: 2s - loss: 2.701 - ETA: 1s - loss: 2.699 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.699 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.694 - ETA: 1s - loss: 2.693 - ETA: 1s - loss: 2.688 - ETA: 1s - loss: 2.687 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.689 - ETA: 0s - loss: 2.694 - ETA: 0s - loss: 2.695 - ETA: 0s - loss: 2.696 - ETA: 0s - loss: 2.695 - 2s 126us/step - loss: 2.6959\n",
      "\n",
      "Epoch 00030: CRPS_score_val did not improve from 0.01288\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 2.670 - ETA: 2s - loss: 2.689 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.690 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.686 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.682 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.688 - 2s 126us/step - loss: 2.6882\n",
      "\n",
      "Epoch 00031: CRPS_score_val improved from 0.01288 to 0.01287, saving model to best_model.h5\n",
      "Epoch 32/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.722 - ETA: 2s - loss: 2.729 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.694 - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.689 - ETA: 1s - loss: 2.683 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.681 - 2s 125us/step - loss: 2.6817\n",
      "\n",
      "Epoch 00032: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 33/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.750 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.689 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.678 - ETA: 1s - loss: 2.690 - ETA: 1s - loss: 2.686 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.687 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.690 - ETA: 0s - loss: 2.690 - ETA: 0s - loss: 2.692 - ETA: 0s - loss: 2.689 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.685 - 2s 127us/step - loss: 2.6836\n",
      "\n",
      "Epoch 00033: CRPS_score_val improved from 0.01287 to 0.01285, saving model to best_model.h5\n",
      "Epoch 34/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.616 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.665 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.685 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.672 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.678 - 2s 122us/step - loss: 2.6787\n",
      "\n",
      "Epoch 00034: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 35/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.672 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.659 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.660 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.662 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.668 - 2s 121us/step - loss: 2.6688\n",
      "\n",
      "Epoch 00035: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 36/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.669 - ETA: 1s - loss: 2.675 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.673 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.669 - 2s 122us/step - loss: 2.6700\n",
      "\n",
      "Epoch 00036: CRPS_score_val improved from 0.01285 to 0.01285, saving model to best_model.h5\n",
      "Epoch 37/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.700 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.686 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.668 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.670 - 2s 122us/step - loss: 2.6705\n",
      "\n",
      "Epoch 00037: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 38/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.633 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.659 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.669 - 2s 123us/step - loss: 2.6689\n",
      "\n",
      "Epoch 00038: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 39/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.606 - ETA: 2s - loss: 2.620 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.666 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.664 - 2s 128us/step - loss: 2.6646\n",
      "\n",
      "Epoch 00039: CRPS_score_val improved from 0.01285 to 0.01285, saving model to best_model.h5\n",
      "Epoch 40/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.651 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.671 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.663 - ETA: 0s - loss: 2.661 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.661 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.660 - 2s 121us/step - loss: 2.6598\n",
      "\n",
      "Epoch 00040: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 41/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.629 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.647 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.656 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.660 - 2s 122us/step - loss: 2.6612\n",
      "\n",
      "Epoch 00041: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 42/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.644 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.650 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.657 - 2s 121us/step - loss: 2.6567\n",
      "\n",
      "Epoch 00042: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 43/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.586 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.649 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.661 - ETA: 1s - loss: 2.663 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.662 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.656 - 2s 122us/step - loss: 2.6575\n",
      "\n",
      "Epoch 00043: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 44/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.616 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.628 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.650 - 2s 123us/step - loss: 2.6505\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00044: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 45/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.657 - ETA: 2s - loss: 2.631 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.638 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.647 - 2s 122us/step - loss: 2.6468\n",
      "\n",
      "Epoch 00045: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 46/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.662 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.649 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.647 - ETA: 1s - loss: 2.643 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.642 - 2s 122us/step - loss: 2.6433\n",
      "\n",
      "Epoch 00046: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 47/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.636 - ETA: 2s - loss: 2.634 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.637 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.646 - 2s 123us/step - loss: 2.6458\n",
      "\n",
      "Epoch 00047: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 48/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.625 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.632 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.641 - 2s 121us/step - loss: 2.6411\n",
      "\n",
      "Epoch 00048: CRPS_score_val did not improve from 0.01285\n",
      "Epoch 49/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.672 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.640 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.638 - 2s 122us/step - loss: 2.6388\n",
      "\n",
      "Epoch 00049: CRPS_score_val improved from 0.01285 to 0.01284, saving model to best_model.h5\n",
      "Epoch 50/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.618 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.638 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.630 - 2s 124us/step - loss: 2.6317\n",
      "\n",
      "Epoch 00050: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 51/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.637 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.630 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.634 - 2s 123us/step - loss: 2.6348\n",
      "\n",
      "Epoch 00051: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 52/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.665 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.623 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.626 - 2s 122us/step - loss: 2.6266\n",
      "\n",
      "Epoch 00052: CRPS_score_val improved from 0.01284 to 0.01284, saving model to best_model.h5\n",
      "Epoch 53/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.617 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.629 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.626 - 2s 122us/step - loss: 2.6260\n",
      "\n",
      "Epoch 00053: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 54/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.604 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.609 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.619 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.626 - 2s 126us/step - loss: 2.6266\n",
      "\n",
      "Epoch 00054: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 55/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.602 - ETA: 2s - loss: 2.638 - ETA: 1s - loss: 2.609 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.603 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.618 - 2s 122us/step - loss: 2.6196\n",
      "\n",
      "Epoch 00055: CRPS_score_val improved from 0.01284 to 0.01284, saving model to best_model.h5\n",
      "Epoch 56/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.668 - ETA: 2s - loss: 2.678 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.613 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.616 - 2s 123us/step - loss: 2.6167\n",
      "\n",
      "Epoch 00056: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 57/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.545 - ETA: 2s - loss: 2.584 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.606 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.615 - 2s 122us/step - loss: 2.6160\n",
      "\n",
      "Epoch 00057: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 58/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.571 - ETA: 2s - loss: 2.612 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.609 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.615 - 2s 123us/step - loss: 2.6157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00058: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 59/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.663 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.599 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.605 - 2s 122us/step - loss: 2.6062\n",
      "\n",
      "Epoch 00059: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 60/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.553 - ETA: 2s - loss: 2.561 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.600 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.607 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.608 - 2s 122us/step - loss: 2.6087\n",
      "\n",
      "Epoch 00060: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 61/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.597 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.571 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.593 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.600 - 2s 124us/step - loss: 2.6016\n",
      "\n",
      "Epoch 00061: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 62/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.565 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.597 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.600 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.603 - 2s 121us/step - loss: 2.6032\n",
      "\n",
      "Epoch 00062: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 63/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.613 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.600 - ETA: 1s - loss: 2.599 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.600 - 2s 122us/step - loss: 2.6009\n",
      "\n",
      "Epoch 00063: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 64/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.532 - ETA: 2s - loss: 2.537 - ETA: 1s - loss: 2.543 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.571 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.589 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.598 - 2s 122us/step - loss: 2.5982\n",
      "\n",
      "Epoch 00064: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 65/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.622 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.575 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.573 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.581 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.586 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.597 - 2s 121us/step - loss: 2.5975\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00065: CRPS_score_val did not improve from 0.01284\n",
      "Epoch 00065: early stopping\n",
      "the 2 fold crps is 0.012838\n",
      "-----------\n",
      "-----------\n",
      "validation shape 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2382\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2384\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'dropout_56/cond' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m       \u001b[0mxla_compile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaCompile\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2386\u001b[0m       \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2387\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2388\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Operation 'dropout_56/cond' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-9b1f097e8a72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcrps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"the %d fold crps is %f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcrps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-96-dfa7820fa62f>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCRPSCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbsz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    314\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[0;32m    315\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                         loss=self.total_loss)\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbolic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   3023\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3024\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3025\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients_v2\u001b[1;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         unconnected_gradients)\n\u001b[0m\u001b[0;32m    275\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    677\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 679\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    680\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaScope\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    677\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 679\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    680\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;31m# Get the if operator (this logic handles the case where op is a MockOp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m   \u001b[0mif_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m   \u001b[0mtrue_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfalse_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_func_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mif_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m   \u001b[1;31m# Note: op.graph != ops.get_default_graph() when we are computing the gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m   \u001b[1;31m# of a nested cond.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36mget_func_graphs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    330\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"If\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"StatelessIf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     return (_get_func_graph_for_branch(op.get_attr(\"then_branch\")),\n\u001b[1;32m--> 332\u001b[1;33m             _get_func_graph_for_branch(op.get_attr(\"else_branch\")))\n\u001b[0m\u001b[0;32m    333\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Case\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     return [_get_func_graph_for_branch(branch_fn)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_get_func_graph_for_branch\u001b[1;34m(name_attr_list)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m       func_graph = function_def_to_graph.function_def_to_graph(\n\u001b[1;32m--> 322\u001b[1;33m           fdef, input_shapes)\n\u001b[0m\u001b[0;32m    323\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mexternal_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_t\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m       \u001b[0mcustom_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexternal_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, input_shapes, copy_functions)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# Add all function nodes to the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mimporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_graph_def_for_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Initialize fields specific to FuncGraph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def_for_function\u001b[1;34m(graph_def, name)\u001b[0m\n\u001b[0;32m    410\u001b[0m   \u001b[1;34m\"\"\"Like import_graph_def but does not validate colocation constraints.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m   return _import_graph_def_internal(\n\u001b[1;32m--> 412\u001b[1;33m       graph_def, validate_colocation_constraints=False, name=name)\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[1;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, op_dict, producer_op_list)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m     \u001b[0mfunctions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_library\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m       \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\function.py\u001b[0m in \u001b[0;36mfrom_library\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfunc_to_grad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m       \u001b[1;32massert\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m     \u001b[0mdefined_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_from_definition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfdef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m     \u001b[0minitialized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefined_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_from_definition\u001b[1;34m(fdef, grad_func)\u001b[0m\n\u001b[0;32m   1100\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m   \u001b[0mserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfdef\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m   \u001b[0mc_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FunctionImportFunctionDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m   \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScopedTFFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m   \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extra_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import time\n",
    "\n",
    "losses = []\n",
    "models = []\n",
    "crps_csv = []\n",
    "\n",
    "s_time = time.time()\n",
    "\n",
    "\n",
    "for k in range(2):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n",
    "        print(\"-----------\")\n",
    "        print(\"-----------\")\n",
    "        tr_x,tr_y = X[tr_inds],y[tr_inds]\n",
    "        val_x,val_y = X[val_inds],y[val_inds]\n",
    "        model,crps = get_model(tr_x,tr_y,val_x,val_y)\n",
    "        models.append(model)\n",
    "        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n",
    "        crps_csv.append(crps)\n",
    " \n",
    "print(\"mean crps is %f\"%np.mean(crps_csv))\n",
    "\n",
    "\n",
    "def predict(x_te):\n",
    "    model_num = len(models)\n",
    "    for k,m in enumerate(models):\n",
    "        if k==0:\n",
    "            y_pred = m.predict(x_te,batch_size=1024)\n",
    "        else:\n",
    "            y_pred+=m.predict(x_te,batch_size=1024)\n",
    "            \n",
    "    y_pred = y_pred / model_num\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
