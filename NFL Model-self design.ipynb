{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import datetime, tqdm\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "pd.set_option('max_columns', 100)\n",
    "#from kaggle.competitions import nflrush\n",
    "from sklearn.model_selection import KFold, RepeatedKFold,GroupKFold\n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense,Dropout, PReLU, BatchNormalization, ELU, GaussianNoise, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import keras.backend as K\n",
    "#note： \n",
    "#1. As a result it might not be worthwhile to use features related to game clock/quarter of the game。\n",
    "#2. There is no relationships between number of rushes before and running yards gained。\n",
    "#3. rushing success larger depends on defender in box, or defender that are close to offensive lineman and attempt \n",
    "#   to counter the blocking.\n",
    "#4. highly drafted player has the same average rushing yards as the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\38980\\OneDrive\\Desktop\\study\\kaggle\\NFL\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team abbreviations correct\n",
    "def data_clean(df):\n",
    "#correct name   \n",
    "    df.loc[df['PossessionTeam'] == 'ARZ', 'PossessionTeam'] = 'ARI'\n",
    "    df.loc[df['PossessionTeam'] == 'BLT', 'PossessionTeam'] = 'BAL'\n",
    "    df.loc[df['PossessionTeam'] == 'CLV', 'PossessionTeam'] = 'CLE'\n",
    "    df.loc[df['PossessionTeam'] == 'HST', 'PossessionTeam'] = 'HOU'\n",
    "    df.loc[df['FieldPosition'] == 'ARZ', 'FieldPosition'] = 'ARI'\n",
    "    df.loc[df['FieldPosition'] == 'BLT', 'FieldPosition'] = 'BAL'\n",
    "    df.loc[df['FieldPosition'] == 'CLV', 'FieldPosition'] = 'CLE'\n",
    "    df.loc[df['FieldPosition'] == 'HST', 'FieldPosition'] = 'HOU'\n",
    "\n",
    "# fill null\n",
    "    df = df.fillna(df.median())\n",
    "\n",
    "# offense time and defence time\n",
    "    df['TeamOnOffense'] = \"home\"\n",
    "    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    df['IsOnOffense'] = df.Team == df.TeamOnOffense # Is player on offense?\n",
    "    \n",
    "#time\n",
    "    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    seconds_in_year = 60*60*24*365.25\n",
    "    df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "    df['GameClock'] = df['GameClock'].apply(lambda x: float(x.split(\":\")[0]) + float(x.split(\":\")[1])/60)\n",
    "    df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "#player height\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "\n",
    "#weather\n",
    "    def map_weather(txt):\n",
    "        ans = 1\n",
    "        if pd.isna(txt):\n",
    "            return 0\n",
    "        if 'partly' in txt:\n",
    "            ans*=0.5\n",
    "        if 'climate controlled' in txt or 'indoor' in txt:\n",
    "            return ans*3\n",
    "        if 'sunny' in txt or 'sun' in txt:\n",
    "            return ans*2\n",
    "        if 'clear' in txt:\n",
    "            return ans\n",
    "        if 'cloudy' in txt:\n",
    "            return -ans\n",
    "        if 'rain' in txt or 'rainy' in txt:\n",
    "            return -2*ans\n",
    "        if 'snow' in txt:\n",
    "            return -3*ans\n",
    "        return 0\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['Cleaned_GameWeather'].apply(map_weather)\n",
    "\n",
    "#diff Score    \n",
    "    df[\"DiffScoreBeforePlay_ob\"] = (df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"])\n",
    "    df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]] = - df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]]\n",
    "#Turf\n",
    "    def agrupar_gramado(Turf):\n",
    "        if Turf == 'Artifical':\n",
    "            return 'Artificial'\n",
    "\n",
    "        elif Turf in ('FieldTurf', 'Field turf'):\n",
    "            return 'Field Turf'\n",
    "\n",
    "        elif Turf in ('FieldTurf360', 'FieldTurf 360'):\n",
    "            return 'Field Turf 360'\n",
    "\n",
    "        elif Turf in ('Natural', 'Natural grass', 'Naturall Grass', 'grass', 'natural grass', 'SISGrass', 'Natural Grass'):\n",
    "            return \"Grass\"\n",
    "\n",
    "        elif Turf == \"UBU Sports Speed S5-M\":\n",
    "            return \"UBU Speed Series-S5-M\"\n",
    "\n",
    "        else:\n",
    "            return Turf\n",
    "        df['Turf'] = df['Turf'].apply(agrupar_gramado)\n",
    "#left to right\n",
    "    df['New_X'] = df['X']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_X'] = 120 - df.loc[df['PlayDirection'] == 'left','X']\n",
    "    df['New_Y'] = df['Y']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_Y'] = 160/3 - df.loc[df['PlayDirection'] == 'left','Y']\n",
    "    df['Orientation_std'] = df['Orientation']\n",
    "    df.loc[df['Season'] == 2017, 'Orientation_std'] = df.loc[df['Season'] == 2017, 'Orientation_std'] + 90\n",
    "    #df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std'] = 360 - df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Orientation_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Orientation_std'], 360)\n",
    "    df['Dir_std'] = df['Dir']\n",
    "    #df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = 360 - df.loc[df['PlayDirection'] == 'left', 'Dir_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Dir_std'], 360)\n",
    "    df['YardLine_std'] = 100 - df['YardLine']\n",
    "    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine_std'\n",
    "         ] = df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine']\n",
    "    df[\"Orientation_sin\"] = df[\"Orientation_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Orientation_cos\"] = df[\"Orientation_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_sin\"] = df[\"Dir_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_cos\"] = df[\"Dir_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "\n",
    "#distance\n",
    "    #distance to yardline\n",
    "    df['Dis_YardLine'] = df['New_X'] - df['YardLine_std'] - 10\n",
    "    #distance to rusher\n",
    "    def Distance(x1,x2,y1,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "    def Degree(x1,x2,y1,y2):\n",
    "        try:\n",
    "            tan = (y1-y2)/(x1-x2)\n",
    "        except:\n",
    "            tan = 0\n",
    "        degree = 90 - math.atan(tan)/(2*np.pi)*360\n",
    "        return degree\n",
    "    df['IsRusher'] = (df['NflId'] == df['NflIdRusher'])\n",
    "    Rusher =df.loc[df['IsRusher'],['PlayId','X','Y','Dir_std']].rename(columns={\"X\":\"Rusher_X\",\"Y\":\"Rusher_Y\",'PossessionTeam':'Offense_Team','Dir_std':'Rusher_Dir_std'})\n",
    "    df = df.merge(Rusher,how = 'left',on = 'PlayId')\n",
    "    df['Distance_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Distance(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Degree(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_Diff'] = abs(df['Degree_to_Rusher'] - df['Rusher_Dir_std'])\n",
    "    #back_direction\n",
    "    def back_direction(orientation):\n",
    "        if orientation > 180.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df['back_oriented_down_field'] = df['Orientation_std'].apply(lambda x: back_direction(x))\n",
    "\n",
    "# Stadium and location clean\n",
    "    def agrupar_local(Location):\n",
    "        if Location == \"Arlington, Texas\":\n",
    "            return \"Arlington, TX\"\n",
    "        elif Location in (\"Baltimore, Maryland\",\"Baltimore, Md.\"):\n",
    "            return \"Baltimore, MD\"\n",
    "        elif Location == \"Charlotte, North Carolina\":\n",
    "            return \"Charlotte, NC\"\n",
    "        elif Location == \"Chicago. IL\":\n",
    "            return \"Chicago, IL\"\n",
    "        elif Location == \"Cincinnati, Ohio\":\n",
    "            return \"Cincinnati, OH\"\n",
    "        elif Location in (\"Cleveland\",\"Cleveland Ohio\",\"Cleveland, Ohio\",\"Cleveland,Ohio\"):\n",
    "            return \"Cleveland, OH\"\n",
    "        elif Location == \"Detroit\":\n",
    "            return \"Detroit, MI\"\n",
    "        elif Location == \"E. Rutherford, NJ\" or Location == \"East Rutherford, N.J.\":\n",
    "            return \"East Rutherford, NJ\"\n",
    "        elif Location == \"Foxborough, Ma\":\n",
    "            return \"Foxborough, MA\"\n",
    "        elif Location == \"Houston, Texas\":\n",
    "            return \"Houston, TX\"\n",
    "        elif Location in (\"Jacksonville Florida\",\"Jacksonville, Fl\",\"Jacksonville, Florida\"):\n",
    "            return \"Jacksonville, FL\"\n",
    "        elif Location == \"London\":\n",
    "            return \"London, England\"\n",
    "        elif Location == \"Los Angeles, Calif.\":\n",
    "            return \"Los Angeles, CA\"\n",
    "        elif Location == \"Miami Gardens, Fla.\":\n",
    "            return \"Miami Gardens, FLA\"\n",
    "        elif Location in (\"New Orleans\",\"New Orleans, La.\"):\n",
    "            return \"New Orleans, LA\"\n",
    "        elif Location == \"Orchard Park NY\":\n",
    "            return \"Orchard Park, NY\"\n",
    "        elif Location == \"Philadelphia, Pa.\":\n",
    "            return \"Philadelphia, PA\"\n",
    "        elif Location == \"Pittsburgh\":\n",
    "            return \"Pittsburgh, PA\"\n",
    "        elif Location == \"Seattle\":\n",
    "            return \"Seattle, WA\"\n",
    "        else:\n",
    "            return Location\n",
    "\n",
    "    df['Location'] = df['Location'].apply(agrupar_local)\n",
    "\n",
    "# stadium types\n",
    "    def agrupar_tipo_estadio(StadiumType):\n",
    "        outdoor       = ['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', 'Outside', 'Outddors', 'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n",
    "        indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', 'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n",
    "        indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "        dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "        dome_open     = ['Domed, Open', 'Domed, open']\n",
    "\n",
    "        if StadiumType in outdoor:\n",
    "            return 'outdoor'\n",
    "        elif StadiumType in indoor_closed:\n",
    "            return 'indoor_closed'\n",
    "        elif StadiumType in indoor_open:\n",
    "            return 'indoor_open'\n",
    "        elif StadiumType in dome_closed:\n",
    "            return 'dome_closed'\n",
    "        elif StadiumType in dome_open:\n",
    "            return 'dome_open'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    df['StadiumType'] = df['StadiumType'].apply(agrupar_tipo_estadio)\n",
    "# wind \n",
    "    def give_me_WindSpeed(x):\n",
    "            x = str(x)\n",
    "            x = x.replace('mph', '').strip()\n",
    "            if '-' in x:\n",
    "                x = (int(x.split('-')[0]) + int(x.split('-')[1])) / 2\n",
    "            elif 'gusts up to' in x:\n",
    "                x = (int(x.split()[0]) + int(x.split()[-1])) / 2\n",
    "            elif 'clam' in x:\n",
    "                x = 0\n",
    "            try:\n",
    "                return float(x)\n",
    "            except:\n",
    "                return -99\n",
    "    df['Cleaned_WindSpeed'] = df['WindSpeed'].apply(give_me_WindSpeed)\n",
    "\n",
    "# wind direction\n",
    "    def agrupa_wind_direction(WindDirection):\n",
    "        wd = str(WindDirection).upper()\n",
    "\n",
    "        if wd == 'N' or 'FROM N' in wd:\n",
    "            return 'north'\n",
    "        if wd == 'S' or 'FROM S' in wd:\n",
    "            return 'south'\n",
    "        if wd == 'W' or 'FROM W' in wd:\n",
    "            return 'west'\n",
    "        if wd == 'E' or 'FROM E' in wd:\n",
    "            return 'east'\n",
    "\n",
    "        if 'FROM SW' in wd or 'FROM SSW' in wd or 'FROM WSW' in wd:\n",
    "            return 'south west'\n",
    "        if 'FROM SE' in wd or 'FROM SSE' in wd or 'FROM ESE' in wd:\n",
    "            return 'south east'\n",
    "        if 'FROM NW' in wd or 'FROM NNW' in wd or 'FROM WNW' in wd:\n",
    "            return 'north west'\n",
    "        if 'FROM NE' in wd or 'FROM NNE' in wd or 'FROM ENE' in wd:\n",
    "            return 'north east'\n",
    "\n",
    "        if 'NW' in wd or 'NORTHWEST' in wd:\n",
    "            return 'north west'\n",
    "        if 'NE' in wd or 'NORTH EAST' in wd:\n",
    "            return 'north east'\n",
    "        if 'SW' in wd or 'SOUTHWEST' in wd:\n",
    "            return 'south west'\n",
    "        if 'SE' in wd or 'SOUTHEAST' in wd:\n",
    "            return 'south east'\n",
    "\n",
    "        return 'unknown'\n",
    "    \n",
    "    df['WindDirection'] = df['WindDirection'].apply(agrupa_wind_direction)\n",
    "# speed\n",
    "    df.loc[df['Season'] == 2017, 'S'] = (df.loc[df['Season'] == 2017, 'S'] - 2.4355) / 1.2930 * 1.4551 + 2.7570\n",
    "    df['Horizontal Speed'] = df['S']*df[\"Dir_sin\"]\n",
    "    df['Vertical Speed'] = df['S']*df[\"Dir_cos\"]\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:115: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:115: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "train = data_clean(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    df1 = df.loc[df['IsRusher']]\n",
    "    df2 = df.loc[df['IsOnOffense'] & (~df['IsRusher'])]\n",
    "    df3 = df.loc[~df['IsOnOffense']]\n",
    "\n",
    "# handoff times\n",
    "    df1 = df1.sort_values(['GameId','PlayId','Quarter','GameClock'])\n",
    "    df1['# of Handoff Play'] = 1\n",
    "    df1['# of Handoff Play'] = df1[['GameId','NflId','# of Handoff Play']].groupby(['GameId','NflId']).cumsum()\n",
    "# min_time_to_tacke\n",
    "    df3['Min_Time_Tacke'] = df3['Distance_to_Rusher']/df3['S']\n",
    "    df3.loc[df3['Min_Time_Tacke'] == np.inf, 'Min_Time_Tacke'] = 20\n",
    "# defence_X_Y_spread\n",
    "    Defence_X_Y_std = df3[[\"PlayId\",'New_X','New_Y']].groupby(\"PlayId\").std().rename(columns={'New_X':'Defense_X_std','New_Y':'Defense_Y_std'}) \\\n",
    "    .reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed2_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(1).index, df3.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed2_std'}).reset_index()\n",
    "\n",
    "    df3 = df3.sort_values(['PlayId','New_Y'])\n",
    "    Defense_Y_Removed2_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(1).index, df3.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed4_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(2).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed4_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_Y'])\n",
    "    Defense_Y_Removed4_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(2).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Defence_X_Y_std, how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "\n",
    "#distance to QB\n",
    "    dis_QB = df2.loc[df2[\"Position\"] =='QB',['PlayId','Distance_to_Rusher']].groupby(['PlayId']).mean().rename(columns={'Distance_to_Rusher':'dis_to_QB'})\n",
    "    df1 = df1.merge(dis_QB,how = 'left', on='PlayId')\n",
    "#defence min,max,mean,std distance to rusher\n",
    "    stat = df3.groupby(['GameId','PlayId']).agg({'Distance_to_Rusher':['min','max','mean','std']})\n",
    "    stat.columns = stat.columns.droplevel()\n",
    "    df1 = df1.merge(stat,how = 'left', on='PlayId')\n",
    "\n",
    "# offense_X_Y_spread\n",
    "    df2 = df2.sort_values(['PlayId','New_X'])\n",
    "    Offense_X_Removed2_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed2_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed2_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_X_Removed4_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed4_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed4_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Offense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    \n",
    "# nearest offenders to defender\n",
    "    dis_to_closest_offender = pd.DataFrame()\n",
    "    for playid in df3['PlayId'].unique():\n",
    "        offense = df2.loc[df2['PlayId'] == playid]\n",
    "        defence = df3.loc[df3['PlayId'] == playid]\n",
    "        ary = scipy.spatial.distance.cdist(defence[['New_X','New_Y']], offense[['New_X','New_Y']], metric='euclidean')\n",
    "        ary.sort(axis=1)\n",
    "        ary = pd.DataFrame(data = ary)\n",
    "        ary['PlayId'] = playid\n",
    "        ary.reset_index(drop=True, inplace=True)\n",
    "        ary = pd.concat([ary, defence[['NflId']].reset_index(drop=True)], axis=1)\n",
    "        dis_to_closest_offender = dis_to_closest_offender.append(ary)\n",
    "    df3 = df3.merge(dis_to_closest_offender,how = 'left',on = ['PlayId','NflId'])\n",
    "\n",
    "# personnel_features\n",
    "    def defense_formation(l):\n",
    "        dl = 0\n",
    "        lb = 0\n",
    "        db = 0\n",
    "        other = 0\n",
    "\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            if sub_string[1] == 'DL':\n",
    "                dl += int(sub_string[0])\n",
    "            elif sub_string[1] in ['LB','OL']:\n",
    "                lb += int(sub_string[0])\n",
    "            else:\n",
    "                db += int(sub_string[0])\n",
    "\n",
    "        counts = (dl,lb,db,other)\n",
    "\n",
    "        return counts\n",
    "    def offense_formation(l):\n",
    "        qb = 0\n",
    "        rb = 0\n",
    "        wr = 0\n",
    "        te = 0\n",
    "        ol = 0\n",
    "\n",
    "        sub_total = 0\n",
    "        qb_listed = False\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            pos = sub_string[1]\n",
    "            cnt = int(sub_string[0])\n",
    "\n",
    "            if pos == 'QB':\n",
    "                qb += cnt\n",
    "                sub_total += cnt\n",
    "                qb_listed = True\n",
    "            # Assuming LB is a line backer lined up as full back\n",
    "            elif pos in ['RB','LB']:\n",
    "                rb += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DB is a defensive back and lined up as WR\n",
    "            elif pos in ['WR','DB']:\n",
    "                wr += cnt\n",
    "                sub_total += cnt\n",
    "            elif pos == 'TE':\n",
    "                te += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DL is a defensive lineman lined up as an additional line man\n",
    "            else:\n",
    "                ol += cnt\n",
    "                sub_total += cnt\n",
    "\n",
    "        # If not all 11 players were noted at given positions we need to make some assumptions\n",
    "        # I will assume if a QB is not listed then there was 1 QB on the play\n",
    "        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n",
    "        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n",
    "        if sub_total < 11:\n",
    "            diff = 11 - sub_total\n",
    "            if not qb_listed:\n",
    "                qb += 1\n",
    "                diff -= 1\n",
    "            ol += diff\n",
    "\n",
    "        counts = (qb,rb,wr,te,ol)\n",
    "\n",
    "        return counts\n",
    "    def split_personnel(s):\n",
    "        splits = s.split(',')\n",
    "        for i in range(len(splits)):\n",
    "            splits[i] = splits[i].strip()\n",
    "\n",
    "        return splits    \n",
    "    def personnel_features(df):\n",
    "        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n",
    "        personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n",
    "\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n",
    "        personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n",
    "        personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n",
    "        personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n",
    "\n",
    "        # Let's create some features to specify if the OL is covered\n",
    "        personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n",
    "        personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n",
    "        # Let's create a feature to specify if the defense is preventing the run\n",
    "        # Let's just assume 7 or more DL and LB is run prevention\n",
    "        personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n",
    "\n",
    "        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n",
    "        \n",
    "        return personnel\n",
    "    \n",
    "    personnel = personnel_features(df1)   \n",
    "    df1 = df1.merge(personnel,how = 'left',  on ='PlayId')\n",
    "    \n",
    "#select useful columns    \n",
    "    rusher = df1[['PlayId','TimeDelta','Team','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y', \\\n",
    "                 'Orientation_std','Dir_std','Dis_YardLine','Horizontal Speed','Vertical Speed','S','A','Dis','Position',\\\n",
    "                 '# of Handoff Play','Quarter','GameClock','Down','Distance','OffenseFormation',\\\n",
    "                  'DefendersInTheBox','HomeScoreBeforePlay','VisitorScoreBeforePlay',\\\n",
    "                 'Offense_X_Removed2_std','Offense_Y_Removed2_std','Offense_X_Removed4_std','Offense_Y_Removed4_std',\\\n",
    "                 'Defense_X_std','Defense_Y_std','Defense_X_Removed2_std','Offense_Y_Removed2_std','Defense_X_Removed4_std',\\\n",
    "                 'Defense_Y_Removed4_std',\\\n",
    "                  'num_DL','num_LB','num_DB','num_QB','num_RB','num_WR','num_TE','num_OL','OL_diff','OL_TE_diff','run_def',\\\n",
    "                 'min','max','std','mean','dis_to_QB']]\n",
    "    rusher = rusher.sort_values('PlayId')\n",
    "    game = df1[['PlayId','Cleaned_GameWeather','Humidity','Temperature', \\\n",
    "              'Week','WindDirection','Cleaned_WindSpeed','Location','StadiumType','PlayDirection']]\n",
    "    game = game.sort_values('PlayId')\n",
    "    offender = df2[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std','back_oriented_down_field',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff']]\n",
    "    offender = offender.sort_values(['PlayId','New_Y'])\n",
    "    defender = df3[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std','back_oriented_down_field',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff','Min_Time_Tacke']+list(range(2))]\n",
    "    defender = defender.sort_values(['PlayId','Distance_to_Rusher'])\n",
    "\n",
    "    \n",
    "    return rusher, game, offender, defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "rusher, game, offender, defender = split_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rusher = rusher.drop('max',axis = 1)\n",
    "#game = game.drop(['Week','PlayDirection','StadiumType',], axis = 1)\n",
    "\n",
    "#offender = offender.drop(['back_oriented_down_field'],axis = 1)\n",
    "\n",
    "#defender = defender.sort_values(['PlayId','Distance_to_Rusher']).groupby('PlayId').head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACE', 'Arlington, TX', 'Atlanta, GA', 'Baltimore, MD', 'C', 'CB',\n",
       "       'Carson, CA', 'Charlotte, NC', 'Chicago, IL', 'Cincinnati, OH',\n",
       "       'Cleveland, OH', 'DB', 'DE', 'DL', 'DT', 'Denver, CO',\n",
       "       'Detroit, MI', 'EMPTY', 'East Rutherford, NJ', 'FB', 'FS',\n",
       "       'Foxborough, MA', 'G', 'Glendale, AZ', 'Green Bay, WI', 'HB',\n",
       "       'Houston, TX', 'ILB', 'I_FORM', 'Indianapolis, Ind.', 'JUMBO',\n",
       "       'Jacksonville, FL', 'Kansas City,  MO', 'Kansas City, MO', 'LB',\n",
       "       'Landover, MD', 'London, England', 'Los Angeles, CA', 'MLB',\n",
       "       'Mexico City', 'Miami Gardens, FLA', 'Minneapolis, MN', 'NT',\n",
       "       'Nashville, TN', 'New Orleans, LA', 'OG', 'OLB', 'OT',\n",
       "       'Oakland, CA', 'Orchard Park, NY', 'PISTOL', 'Philadelphia, PA',\n",
       "       'Pittsburgh, PA', 'QB', 'RB', 'S', 'SAF', 'SHOTGUN', 'SINGLEBACK',\n",
       "       'SS', 'Santa Clara, CA', 'Seattle, WA', 'T', 'TE', 'Tampa, FL',\n",
       "       'WILDCAT', 'WR', 'away', 'dome_closed', 'dome_open', 'east',\n",
       "       'home', 'indoor_closed', 'indoor_open', 'left', 'nan', 'north',\n",
       "       'north east', 'north west', 'outdoor', 'right', 'south',\n",
       "       'south east', 'south west', 'unknown', 'west'], dtype=object)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_dummy\n",
    "le = preprocessing.LabelEncoder()\n",
    "categories =[]\n",
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = rusher[i].astype(str)\n",
    "    categories.append(rusher[i].unique())\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = game[i].astype(str)\n",
    "    categories.append(game[i].unique())\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = offender[i].astype(str)\n",
    "    categories.append(offender[i].unique())\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = defender[i].astype(str)\n",
    "    categories.append(defender[i].unique())\n",
    "categories = np.hstack(categories)\n",
    "le.fit(categories)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = le.transform(rusher[i])\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = le.transform(game[i])\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = le.transform(offender[i])\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = le.transform(defender[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 170)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offender_players = [offender.drop('PlayId',axis = 1).iloc[np.arange(k, len(offender), 10)].reset_index(drop = True) for k in range(10)]\n",
    "offender_players = np.hstack([t.values for t in offender_players])\n",
    "offender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 220)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defender_players = [defender.drop('PlayId',axis = 1).iloc[np.arange(k, len(defender), 11)].reset_index(drop = True) for k in range(11)]\n",
    "defender_players = np.hstack([t.values for t in defender_players])\n",
    "defender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y =train.loc[train['IsRusher'],['Yards','PlayId']].sort_values('PlayId').drop('PlayId',axis = 1)\n",
    "train_x = np.hstack([rusher.drop('PlayId',axis = 1).values,defender_players])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps_eval(y_pred, dataset, is_higher_better=False):\n",
    "    labels = dataset.get_label()\n",
    "    labels = labels.astype('int')\n",
    "    y_true = np.zeros((len(labels),199))\n",
    "    for i, v in enumerate(labels):\n",
    "        y_true[i, v:] = 1\n",
    "    y_pred = y_pred.reshape(-1, 199, order='F')\n",
    "    y_pred = np.clip(y_pred.cumsum(axis=1), 0, 1)\n",
    "    return 'crps', np.mean((y_pred - y_true)**2), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':5, 'lambda_l1': 1, 'lambda_l2': 1,\n",
    " 'num_leaves': 32, 'feature_fraction': 0.4,\n",
    " 'subsample': 0.4, 'min_child_samples': 15,\n",
    " 'learning_rate': 0.02,\n",
    " 'num_iterations': 1000, 'random_state': 42,\n",
    " 'objective': 'multiclass',\n",
    " 'min_gain_to_split':1,\n",
    " 'num_class':199,\n",
    " 'metric':'None'}\n",
    "train_y99 =(train_y + 99).reset_index(drop=True).Yards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0128973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\ttraining's crps: 0.012384\tvalid_1's crps: 0.013373\n",
      "[200]\ttraining's crps: 0.0108773\tvalid_1's crps: 0.0130778\n",
      "[300]\ttraining's crps: 0.010079\tvalid_1's crps: 0.0129502\n",
      "[400]\ttraining's crps: 0.00956821\tvalid_1's crps: 0.0128904\n",
      "[500]\ttraining's crps: 0.00921047\tvalid_1's crps: 0.0128521\n",
      "[600]\ttraining's crps: 0.00894678\tvalid_1's crps: 0.0128295\n",
      "[700]\ttraining's crps: 0.00875029\tvalid_1's crps: 0.0128173\n",
      "[800]\ttraining's crps: 0.00860307\tvalid_1's crps: 0.0128082\n",
      "[900]\ttraining's crps: 0.00850348\tvalid_1's crps: 0.012802\n",
      "Early stopping, best iteration is:\n",
      "[950]\ttraining's crps: 0.0084672\tvalid_1's crps: 0.0127997\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\ttraining's crps: 0.0124035\tvalid_1's crps: 0.0132933\n",
      "[200]\ttraining's crps: 0.0109254\tvalid_1's crps: 0.0130025\n",
      "[300]\ttraining's crps: 0.0101274\tvalid_1's crps: 0.0128798\n",
      "[400]\ttraining's crps: 0.00962543\tvalid_1's crps: 0.0128184\n",
      "[500]\ttraining's crps: 0.00928935\tvalid_1's crps: 0.0127803\n",
      "[600]\ttraining's crps: 0.00903848\tvalid_1's crps: 0.0127582\n",
      "Early stopping, best iteration is:\n",
      "[659]\ttraining's crps: 0.0089112\tvalid_1's crps: 0.0127486\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\ttraining's crps: 0.0124585\tvalid_1's crps: 0.013186\n",
      "[200]\ttraining's crps: 0.0110099\tvalid_1's crps: 0.0129184\n",
      "[300]\ttraining's crps: 0.0102257\tvalid_1's crps: 0.0128069\n",
      "[400]\ttraining's crps: 0.00972056\tvalid_1's crps: 0.0127545\n",
      "[500]\ttraining's crps: 0.00937099\tvalid_1's crps: 0.0127232\n",
      "[600]\ttraining's crps: 0.00910588\tvalid_1's crps: 0.0127044\n",
      "[700]\ttraining's crps: 0.00891345\tvalid_1's crps: 0.0126944\n",
      "Early stopping, best iteration is:\n",
      "[713]\ttraining's crps: 0.00889404\tvalid_1's crps: 0.0126934\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\ttraining's crps: 0.0124359\tvalid_1's crps: 0.0131652\n",
      "[200]\ttraining's crps: 0.0109467\tvalid_1's crps: 0.0128953\n",
      "[300]\ttraining's crps: 0.0101558\tvalid_1's crps: 0.0127846\n",
      "[400]\ttraining's crps: 0.0096463\tvalid_1's crps: 0.0127283\n",
      "[500]\ttraining's crps: 0.00929751\tvalid_1's crps: 0.0126956\n",
      "[600]\ttraining's crps: 0.00903721\tvalid_1's crps: 0.0126759\n",
      "[700]\ttraining's crps: 0.00883177\tvalid_1's crps: 0.0126614\n",
      "Early stopping, best iteration is:\n",
      "[761]\ttraining's crps: 0.00873455\tvalid_1's crps: 0.0126551\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\ttraining's crps: 0.012341\tvalid_1's crps: 0.013634\n",
      "[200]\ttraining's crps: 0.0108633\tvalid_1's crps: 0.0133398\n",
      "[300]\ttraining's crps: 0.0100782\tvalid_1's crps: 0.0132194\n",
      "[400]\ttraining's crps: 0.0095661\tvalid_1's crps: 0.0131564\n",
      "[500]\ttraining's crps: 0.00920964\tvalid_1's crps: 0.013119\n",
      "[600]\ttraining's crps: 0.00894627\tvalid_1's crps: 0.0130957\n",
      "[700]\ttraining's crps: 0.00874778\tvalid_1's crps: 0.0130827\n",
      "Early stopping, best iteration is:\n",
      "[787]\ttraining's crps: 0.00861508\tvalid_1's crps: 0.0130767\n"
     ]
    }
   ],
   "source": [
    "# drop 'max' and correct speed\n",
    "print(np.mean([0.012911,0.0128706,0.012782,0.0127382,0.0131847]))\n",
    "import lightgbm as lgb\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "        tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "        vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "        dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "        dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "        model = lgb.train(params, dtrain,\n",
    "                              num_boost_round=100000,\n",
    "                              valid_sets=[dtrain,dvalid],\n",
    "                              early_stopping_rounds=5,\n",
    "                              verbose_eval=100,\n",
    "                              feval=crps_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012891320000000001\n",
      "0.012818759999999998\n",
      "0.01279516\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([0.0129045,0.0128677,0.0127771,0.0127333,0.013174]))\n",
    "# 2 closest player\n",
    "print(np.mean([0.0128452,0.012791,0.0126835,0.0126629,0.0131112]))\n",
    "# all defense palyer\n",
    "print(np.mean([0.012802,0.0127486,0.0126934,0.0126551,0.0130767]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned_GameWeather\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's crps: 0.0119353\tvalid_1's crps: 0.0129037\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[729]\ttraining's crps: 0.0119323\tvalid_1's crps: 0.0128636\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[762]\ttraining's crps: 0.0119639\tvalid_1's crps: 0.0127822\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[701]\ttraining's crps: 0.0119739\tvalid_1's crps: 0.0127376\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[712]\ttraining's crps: 0.0118623\tvalid_1's crps: 0.0131771\n",
      "Humidity\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[714]\ttraining's crps: 0.0119134\tvalid_1's crps: 0.0129048\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[763]\ttraining's crps: 0.0119049\tvalid_1's crps: 0.0128708\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[762]\ttraining's crps: 0.0119431\tvalid_1's crps: 0.0127873\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[743]\ttraining's crps: 0.011952\tvalid_1's crps: 0.0127365\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[714]\ttraining's crps: 0.0118318\tvalid_1's crps: 0.0131751\n",
      "Temperature\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[711]\ttraining's crps: 0.0119119\tvalid_1's crps: 0.0129074\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[787]\ttraining's crps: 0.0119062\tvalid_1's crps: 0.0128651\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's crps: 0.0119354\tvalid_1's crps: 0.0127865\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[747]\ttraining's crps: 0.0119494\tvalid_1's crps: 0.0127369\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[710]\ttraining's crps: 0.0118337\tvalid_1's crps: 0.0131818\n",
      "Week\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's crps: 0.0119304\tvalid_1's crps: 0.012904\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[788]\ttraining's crps: 0.0119207\tvalid_1's crps: 0.0128633\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's crps: 0.0119553\tvalid_1's crps: 0.0127819\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[668]\ttraining's crps: 0.01197\tvalid_1's crps: 0.0127413\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[698]\ttraining's crps: 0.0118515\tvalid_1's crps: 0.0131798\n",
      "WindDirection\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's crps: 0.011926\tvalid_1's crps: 0.0129012\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[728]\ttraining's crps: 0.0119225\tvalid_1's crps: 0.0128647\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[747]\ttraining's crps: 0.0119527\tvalid_1's crps: 0.0127809\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[668]\ttraining's crps: 0.0119646\tvalid_1's crps: 0.0127346\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[708]\ttraining's crps: 0.0118523\tvalid_1's crps: 0.013177\n",
      "Cleaned_WindSpeed\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[710]\ttraining's crps: 0.0119135\tvalid_1's crps: 0.0129045\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[719]\ttraining's crps: 0.0119091\tvalid_1's crps: 0.0128711\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's crps: 0.0119376\tvalid_1's crps: 0.0127873\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[703]\ttraining's crps: 0.0119508\tvalid_1's crps: 0.0127351\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's crps: 0.0118335\tvalid_1's crps: 0.0131795\n",
      "Location\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[716]\ttraining's crps: 0.0119176\tvalid_1's crps: 0.0129077\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[790]\ttraining's crps: 0.0119097\tvalid_1's crps: 0.0128665\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's crps: 0.0119478\tvalid_1's crps: 0.0127794\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[666]\ttraining's crps: 0.0119617\tvalid_1's crps: 0.0127374\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[703]\ttraining's crps: 0.0118424\tvalid_1's crps: 0.0131804\n",
      "StadiumType\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's crps: 0.0119316\tvalid_1's crps: 0.0129068\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[719]\ttraining's crps: 0.0119247\tvalid_1's crps: 0.0128669\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[750]\ttraining's crps: 0.0119599\tvalid_1's crps: 0.0127829\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[717]\ttraining's crps: 0.0119723\tvalid_1's crps: 0.0127406\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's crps: 0.0118546\tvalid_1's crps: 0.0131787\n",
      "PlayDirection\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[711]\ttraining's crps: 0.0119366\tvalid_1's crps: 0.0129052\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[741]\ttraining's crps: 0.0119317\tvalid_1's crps: 0.0128645\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[753]\ttraining's crps: 0.0119635\tvalid_1's crps: 0.012782\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[682]\ttraining's crps: 0.0119737\tvalid_1's crps: 0.012738\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's crps: 0.011863\tvalid_1's crps: 0.0131766\n"
     ]
    }
   ],
   "source": [
    "for i in game.drop('PlayId',axis = 1).columns.tolist():\n",
    "    train_x = rusher.merge(game[['PlayId',i]],how = 'left',  on ='PlayId').drop('PlayId',axis = 1).values\n",
    "    print(i)\n",
    "    for k in range(1):\n",
    "        kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "        for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "            tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "            vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "            dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "            dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "            model = lgb.train(params, dtrain,\n",
    "                                  num_boost_round=100000,\n",
    "                                  valid_sets=[dtrain,dvalid],\n",
    "                                  early_stopping_rounds=5,\n",
    "                                  verbose_eval=1000,\n",
    "                                  feval=crps_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171,)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0128798"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rusher only  0.0129224 0.0128887, 0.0127877, 0.0127507, 0.01318\n",
    "np.mean([0.0129342,0.0128689,0.0127562,0.0126962,0.0131435])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's mape: 0.0328486\tvalid_1's mape: 0.0326991\n",
      "[20]\ttraining's mape: 0.0322112\tvalid_1's mape: 0.0321865\n",
      "[30]\ttraining's mape: 0.0316222\tvalid_1's mape: 0.0316953\n",
      "[40]\ttraining's mape: 0.0313034\tvalid_1's mape: 0.0314854\n",
      "[50]\ttraining's mape: 0.0309792\tvalid_1's mape: 0.0312592\n",
      "[60]\ttraining's mape: 0.0307363\tvalid_1's mape: 0.0311146\n",
      "[70]\ttraining's mape: 0.0304999\tvalid_1's mape: 0.0309864\n",
      "[80]\ttraining's mape: 0.0303047\tvalid_1's mape: 0.0309035\n",
      "[90]\ttraining's mape: 0.0301353\tvalid_1's mape: 0.0308187\n",
      "[100]\ttraining's mape: 0.0299895\tvalid_1's mape: 0.0307476\n",
      "[110]\ttraining's mape: 0.0298492\tvalid_1's mape: 0.0306947\n",
      "[120]\ttraining's mape: 0.0297274\tvalid_1's mape: 0.0306554\n",
      "[130]\ttraining's mape: 0.0296239\tvalid_1's mape: 0.0306352\n",
      "[140]\ttraining's mape: 0.0295154\tvalid_1's mape: 0.0306009\n",
      "[150]\ttraining's mape: 0.0294099\tvalid_1's mape: 0.0305521\n",
      "[160]\ttraining's mape: 0.0293131\tvalid_1's mape: 0.0305211\n",
      "[170]\ttraining's mape: 0.0292312\tvalid_1's mape: 0.0304916\n",
      "[180]\ttraining's mape: 0.0291518\tvalid_1's mape: 0.0304656\n",
      "[190]\ttraining's mape: 0.0290724\tvalid_1's mape: 0.0304547\n",
      "[200]\ttraining's mape: 0.028983\tvalid_1's mape: 0.0304268\n",
      "[210]\ttraining's mape: 0.0289149\tvalid_1's mape: 0.0304126\n",
      "[220]\ttraining's mape: 0.0288462\tvalid_1's mape: 0.0304008\n",
      "[230]\ttraining's mape: 0.0287791\tvalid_1's mape: 0.0303849\n",
      "[240]\ttraining's mape: 0.0287173\tvalid_1's mape: 0.0303705\n",
      "[250]\ttraining's mape: 0.0286522\tvalid_1's mape: 0.0303573\n",
      "[260]\ttraining's mape: 0.028595\tvalid_1's mape: 0.0303507\n",
      "[270]\ttraining's mape: 0.0285413\tvalid_1's mape: 0.0303433\n",
      "[280]\ttraining's mape: 0.0284919\tvalid_1's mape: 0.030332\n",
      "[290]\ttraining's mape: 0.0284393\tvalid_1's mape: 0.0303207\n",
      "[300]\ttraining's mape: 0.0283967\tvalid_1's mape: 0.0303174\n",
      "[310]\ttraining's mape: 0.0283517\tvalid_1's mape: 0.0303105\n",
      "[320]\ttraining's mape: 0.0283095\tvalid_1's mape: 0.030304\n",
      "[330]\ttraining's mape: 0.0282604\tvalid_1's mape: 0.0302973\n",
      "[340]\ttraining's mape: 0.0282149\tvalid_1's mape: 0.0302984\n",
      "[350]\ttraining's mape: 0.0281797\tvalid_1's mape: 0.0302921\n",
      "[360]\ttraining's mape: 0.0281402\tvalid_1's mape: 0.0302908\n",
      "[370]\ttraining's mape: 0.0281056\tvalid_1's mape: 0.0302813\n",
      "[380]\ttraining's mape: 0.0280715\tvalid_1's mape: 0.0302751\n",
      "[390]\ttraining's mape: 0.0280311\tvalid_1's mape: 0.0302744\n",
      "[400]\ttraining's mape: 0.0279857\tvalid_1's mape: 0.0302662\n",
      "[410]\ttraining's mape: 0.0279445\tvalid_1's mape: 0.0302529\n",
      "[420]\ttraining's mape: 0.0279085\tvalid_1's mape: 0.0302505\n",
      "[430]\ttraining's mape: 0.0278823\tvalid_1's mape: 0.0302489\n",
      "[440]\ttraining's mape: 0.0278456\tvalid_1's mape: 0.0302408\n",
      "[450]\ttraining's mape: 0.0278174\tvalid_1's mape: 0.0302392\n",
      "[460]\ttraining's mape: 0.0277901\tvalid_1's mape: 0.0302323\n",
      "[470]\ttraining's mape: 0.0277584\tvalid_1's mape: 0.030228\n",
      "[480]\ttraining's mape: 0.0277214\tvalid_1's mape: 0.0302197\n",
      "[490]\ttraining's mape: 0.0276872\tvalid_1's mape: 0.0302142\n",
      "[500]\ttraining's mape: 0.0276556\tvalid_1's mape: 0.0302079\n",
      "[510]\ttraining's mape: 0.0276246\tvalid_1's mape: 0.030202\n",
      "[520]\ttraining's mape: 0.027592\tvalid_1's mape: 0.0301975\n",
      "[530]\ttraining's mape: 0.0275687\tvalid_1's mape: 0.0301964\n",
      "[540]\ttraining's mape: 0.027549\tvalid_1's mape: 0.0301958\n",
      "[550]\ttraining's mape: 0.0275191\tvalid_1's mape: 0.0301916\n",
      "[560]\ttraining's mape: 0.0275019\tvalid_1's mape: 0.0301909\n",
      "[570]\ttraining's mape: 0.0274908\tvalid_1's mape: 0.0301881\n",
      "[580]\ttraining's mape: 0.0274642\tvalid_1's mape: 0.0301894\n",
      "[590]\ttraining's mape: 0.0274346\tvalid_1's mape: 0.0301815\n",
      "[600]\ttraining's mape: 0.0274111\tvalid_1's mape: 0.030182\n",
      "[10]\ttraining's mape: 0.0327585\tvalid_1's mape: 0.0330486\n",
      "[20]\ttraining's mape: 0.032104\tvalid_1's mape: 0.0325269\n",
      "[30]\ttraining's mape: 0.0314806\tvalid_1's mape: 0.0320773\n",
      "[40]\ttraining's mape: 0.0311556\tvalid_1's mape: 0.0318579\n",
      "[50]\ttraining's mape: 0.0308252\tvalid_1's mape: 0.0316532\n",
      "[60]\ttraining's mape: 0.0305824\tvalid_1's mape: 0.0315078\n",
      "[70]\ttraining's mape: 0.0303484\tvalid_1's mape: 0.0313881\n",
      "[80]\ttraining's mape: 0.0301652\tvalid_1's mape: 0.0313057\n",
      "[90]\ttraining's mape: 0.0299965\tvalid_1's mape: 0.0312371\n",
      "[100]\ttraining's mape: 0.0298429\tvalid_1's mape: 0.0311637\n",
      "[110]\ttraining's mape: 0.0297048\tvalid_1's mape: 0.0311086\n",
      "[120]\ttraining's mape: 0.029576\tvalid_1's mape: 0.0310783\n",
      "[130]\ttraining's mape: 0.0294695\tvalid_1's mape: 0.0310651\n",
      "[140]\ttraining's mape: 0.0293626\tvalid_1's mape: 0.0310321\n",
      "[150]\ttraining's mape: 0.0292559\tvalid_1's mape: 0.0310065\n",
      "[160]\ttraining's mape: 0.0291595\tvalid_1's mape: 0.0309892\n",
      "[170]\ttraining's mape: 0.0290712\tvalid_1's mape: 0.0309602\n",
      "[180]\ttraining's mape: 0.0289849\tvalid_1's mape: 0.0309419\n",
      "[190]\ttraining's mape: 0.0288937\tvalid_1's mape: 0.0309287\n",
      "[200]\ttraining's mape: 0.0288135\tvalid_1's mape: 0.0309185\n",
      "[210]\ttraining's mape: 0.0287371\tvalid_1's mape: 0.030911\n",
      "[220]\ttraining's mape: 0.0286687\tvalid_1's mape: 0.0308988\n",
      "[230]\ttraining's mape: 0.028599\tvalid_1's mape: 0.0308877\n",
      "[240]\ttraining's mape: 0.0285303\tvalid_1's mape: 0.0308766\n",
      "[250]\ttraining's mape: 0.0284691\tvalid_1's mape: 0.0308721\n",
      "[260]\ttraining's mape: 0.0284061\tvalid_1's mape: 0.030862\n",
      "[270]\ttraining's mape: 0.0283487\tvalid_1's mape: 0.0308633\n",
      "[280]\ttraining's mape: 0.028291\tvalid_1's mape: 0.0308532\n",
      "[290]\ttraining's mape: 0.0282393\tvalid_1's mape: 0.030849\n",
      "[300]\ttraining's mape: 0.0281948\tvalid_1's mape: 0.0308446\n",
      "[310]\ttraining's mape: 0.0281528\tvalid_1's mape: 0.0308383\n",
      "[320]\ttraining's mape: 0.0281047\tvalid_1's mape: 0.0308293\n",
      "[330]\ttraining's mape: 0.0280664\tvalid_1's mape: 0.0308222\n",
      "[340]\ttraining's mape: 0.028027\tvalid_1's mape: 0.0308207\n",
      "[350]\ttraining's mape: 0.027991\tvalid_1's mape: 0.0308194\n",
      "[360]\ttraining's mape: 0.0279498\tvalid_1's mape: 0.0308151\n",
      "[370]\ttraining's mape: 0.0279101\tvalid_1's mape: 0.0308133\n",
      "[380]\ttraining's mape: 0.0278764\tvalid_1's mape: 0.0308068\n",
      "[390]\ttraining's mape: 0.0278371\tvalid_1's mape: 0.0308043\n",
      "[400]\ttraining's mape: 0.0278034\tvalid_1's mape: 0.0307995\n",
      "[410]\ttraining's mape: 0.0277652\tvalid_1's mape: 0.0307945\n",
      "[420]\ttraining's mape: 0.0277154\tvalid_1's mape: 0.0307851\n",
      "[430]\ttraining's mape: 0.027679\tvalid_1's mape: 0.0307873\n",
      "[440]\ttraining's mape: 0.0276486\tvalid_1's mape: 0.0307842\n",
      "[450]\ttraining's mape: 0.0276245\tvalid_1's mape: 0.0307815\n",
      "[460]\ttraining's mape: 0.0275896\tvalid_1's mape: 0.0307815\n",
      "[470]\ttraining's mape: 0.0275493\tvalid_1's mape: 0.0307745\n",
      "[480]\ttraining's mape: 0.0275183\tvalid_1's mape: 0.0307672\n",
      "[490]\ttraining's mape: 0.0274831\tvalid_1's mape: 0.0307657\n",
      "[500]\ttraining's mape: 0.027456\tvalid_1's mape: 0.0307659\n",
      "[510]\ttraining's mape: 0.0274264\tvalid_1's mape: 0.0307693\n",
      "[520]\ttraining's mape: 0.0274022\tvalid_1's mape: 0.0307622\n",
      "[530]\ttraining's mape: 0.0273753\tvalid_1's mape: 0.0307588\n",
      "[540]\ttraining's mape: 0.0273507\tvalid_1's mape: 0.0307559\n",
      "[550]\ttraining's mape: 0.0273238\tvalid_1's mape: 0.0307526\n",
      "[560]\ttraining's mape: 0.0272961\tvalid_1's mape: 0.0307506\n",
      "[570]\ttraining's mape: 0.0272687\tvalid_1's mape: 0.0307475\n",
      "[580]\ttraining's mape: 0.0272379\tvalid_1's mape: 0.0307447\n",
      "[590]\ttraining's mape: 0.0272185\tvalid_1's mape: 0.0307417\n",
      "[600]\ttraining's mape: 0.0271978\tvalid_1's mape: 0.0307405\n",
      "[10]\ttraining's mape: 0.0328767\tvalid_1's mape: 0.0326718\n",
      "[20]\ttraining's mape: 0.0321983\tvalid_1's mape: 0.0321656\n",
      "[30]\ttraining's mape: 0.0316017\tvalid_1's mape: 0.0316803\n",
      "[40]\ttraining's mape: 0.0312843\tvalid_1's mape: 0.0314898\n",
      "[50]\ttraining's mape: 0.0309731\tvalid_1's mape: 0.0312901\n",
      "[60]\ttraining's mape: 0.0307106\tvalid_1's mape: 0.0311551\n",
      "[70]\ttraining's mape: 0.0304644\tvalid_1's mape: 0.0310224\n",
      "[80]\ttraining's mape: 0.0302653\tvalid_1's mape: 0.0309218\n",
      "[90]\ttraining's mape: 0.0300996\tvalid_1's mape: 0.0308382\n",
      "[100]\ttraining's mape: 0.0299433\tvalid_1's mape: 0.0307643\n",
      "[110]\ttraining's mape: 0.0298057\tvalid_1's mape: 0.030717\n",
      "[120]\ttraining's mape: 0.0296932\tvalid_1's mape: 0.0306907\n",
      "[130]\ttraining's mape: 0.0295904\tvalid_1's mape: 0.0306656\n",
      "[140]\ttraining's mape: 0.0294972\tvalid_1's mape: 0.0306359\n",
      "[150]\ttraining's mape: 0.0293913\tvalid_1's mape: 0.0306122\n",
      "[160]\ttraining's mape: 0.029303\tvalid_1's mape: 0.0305953\n",
      "[170]\ttraining's mape: 0.029216\tvalid_1's mape: 0.0305718\n",
      "[180]\ttraining's mape: 0.0291302\tvalid_1's mape: 0.0305537\n",
      "[190]\ttraining's mape: 0.0290466\tvalid_1's mape: 0.0305401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's mape: 0.0289745\tvalid_1's mape: 0.0305268\n",
      "[210]\ttraining's mape: 0.028901\tvalid_1's mape: 0.0305082\n",
      "[220]\ttraining's mape: 0.0288383\tvalid_1's mape: 0.0304982\n",
      "[230]\ttraining's mape: 0.0287689\tvalid_1's mape: 0.0304893\n",
      "[240]\ttraining's mape: 0.0287117\tvalid_1's mape: 0.0304799\n",
      "[250]\ttraining's mape: 0.0286542\tvalid_1's mape: 0.0304695\n",
      "[260]\ttraining's mape: 0.0285891\tvalid_1's mape: 0.030462\n",
      "[270]\ttraining's mape: 0.0285343\tvalid_1's mape: 0.0304557\n",
      "[280]\ttraining's mape: 0.0284826\tvalid_1's mape: 0.0304513\n",
      "[290]\ttraining's mape: 0.0284358\tvalid_1's mape: 0.0304468\n",
      "[300]\ttraining's mape: 0.0283821\tvalid_1's mape: 0.030445\n",
      "[310]\ttraining's mape: 0.0283241\tvalid_1's mape: 0.0304388\n",
      "[320]\ttraining's mape: 0.0282671\tvalid_1's mape: 0.0304319\n",
      "[330]\ttraining's mape: 0.0282258\tvalid_1's mape: 0.0304256\n",
      "[340]\ttraining's mape: 0.0281894\tvalid_1's mape: 0.0304164\n",
      "[350]\ttraining's mape: 0.0281489\tvalid_1's mape: 0.0304113\n",
      "[360]\ttraining's mape: 0.0280977\tvalid_1's mape: 0.0304097\n",
      "[370]\ttraining's mape: 0.0280435\tvalid_1's mape: 0.0304067\n",
      "[380]\ttraining's mape: 0.0279978\tvalid_1's mape: 0.0303996\n",
      "[390]\ttraining's mape: 0.0279534\tvalid_1's mape: 0.0304003\n",
      "[400]\ttraining's mape: 0.0279059\tvalid_1's mape: 0.030397\n",
      "[410]\ttraining's mape: 0.0278688\tvalid_1's mape: 0.0303919\n",
      "[420]\ttraining's mape: 0.027832\tvalid_1's mape: 0.030386\n",
      "[430]\ttraining's mape: 0.0278021\tvalid_1's mape: 0.0303851\n",
      "[440]\ttraining's mape: 0.0277769\tvalid_1's mape: 0.0303832\n",
      "[450]\ttraining's mape: 0.0277487\tvalid_1's mape: 0.0303791\n",
      "[460]\ttraining's mape: 0.0277242\tvalid_1's mape: 0.0303765\n",
      "[470]\ttraining's mape: 0.0276965\tvalid_1's mape: 0.0303772\n",
      "[480]\ttraining's mape: 0.0276679\tvalid_1's mape: 0.0303758\n",
      "[490]\ttraining's mape: 0.0276291\tvalid_1's mape: 0.0303707\n",
      "[500]\ttraining's mape: 0.0275892\tvalid_1's mape: 0.0303717\n",
      "[510]\ttraining's mape: 0.027557\tvalid_1's mape: 0.0303674\n",
      "[520]\ttraining's mape: 0.0275281\tvalid_1's mape: 0.0303611\n",
      "[530]\ttraining's mape: 0.0274964\tvalid_1's mape: 0.0303645\n",
      "[540]\ttraining's mape: 0.0274767\tvalid_1's mape: 0.0303655\n",
      "[550]\ttraining's mape: 0.0274496\tvalid_1's mape: 0.0303658\n",
      "[560]\ttraining's mape: 0.0274189\tvalid_1's mape: 0.0303665\n",
      "[570]\ttraining's mape: 0.0273958\tvalid_1's mape: 0.0303671\n",
      "[580]\ttraining's mape: 0.0273738\tvalid_1's mape: 0.0303647\n",
      "[590]\ttraining's mape: 0.0273447\tvalid_1's mape: 0.0303582\n",
      "[600]\ttraining's mape: 0.0273143\tvalid_1's mape: 0.0303549\n",
      "[10]\ttraining's mape: 0.0328544\tvalid_1's mape: 0.0327235\n",
      "[20]\ttraining's mape: 0.0322015\tvalid_1's mape: 0.032209\n",
      "[30]\ttraining's mape: 0.0315992\tvalid_1's mape: 0.0317591\n",
      "[40]\ttraining's mape: 0.0313015\tvalid_1's mape: 0.0315908\n",
      "[50]\ttraining's mape: 0.0309842\tvalid_1's mape: 0.0313717\n",
      "[60]\ttraining's mape: 0.0307365\tvalid_1's mape: 0.0312468\n",
      "[70]\ttraining's mape: 0.0304983\tvalid_1's mape: 0.0311134\n",
      "[80]\ttraining's mape: 0.0303105\tvalid_1's mape: 0.0310212\n",
      "[90]\ttraining's mape: 0.030142\tvalid_1's mape: 0.030942\n",
      "[100]\ttraining's mape: 0.0299746\tvalid_1's mape: 0.0308639\n",
      "[110]\ttraining's mape: 0.0298294\tvalid_1's mape: 0.0308038\n",
      "[120]\ttraining's mape: 0.029706\tvalid_1's mape: 0.0307604\n",
      "[130]\ttraining's mape: 0.0296027\tvalid_1's mape: 0.0307165\n",
      "[140]\ttraining's mape: 0.0294969\tvalid_1's mape: 0.0306761\n",
      "[150]\ttraining's mape: 0.0293887\tvalid_1's mape: 0.0306585\n",
      "[160]\ttraining's mape: 0.0292982\tvalid_1's mape: 0.0306409\n",
      "[170]\ttraining's mape: 0.0292112\tvalid_1's mape: 0.0306276\n",
      "[180]\ttraining's mape: 0.0291213\tvalid_1's mape: 0.0306105\n",
      "[190]\ttraining's mape: 0.0290374\tvalid_1's mape: 0.0305929\n",
      "[200]\ttraining's mape: 0.0289693\tvalid_1's mape: 0.0305765\n",
      "[210]\ttraining's mape: 0.0289025\tvalid_1's mape: 0.0305707\n",
      "[220]\ttraining's mape: 0.028837\tvalid_1's mape: 0.0305504\n",
      "[230]\ttraining's mape: 0.0287697\tvalid_1's mape: 0.0305506\n",
      "[240]\ttraining's mape: 0.0287078\tvalid_1's mape: 0.030543\n",
      "[250]\ttraining's mape: 0.0286519\tvalid_1's mape: 0.0305303\n",
      "[260]\ttraining's mape: 0.0285934\tvalid_1's mape: 0.0305253\n",
      "[270]\ttraining's mape: 0.0285454\tvalid_1's mape: 0.0305248\n",
      "[280]\ttraining's mape: 0.0284853\tvalid_1's mape: 0.0305163\n",
      "[290]\ttraining's mape: 0.0284267\tvalid_1's mape: 0.0305087\n",
      "[300]\ttraining's mape: 0.0283776\tvalid_1's mape: 0.0304993\n",
      "[310]\ttraining's mape: 0.028328\tvalid_1's mape: 0.030495\n",
      "[320]\ttraining's mape: 0.028268\tvalid_1's mape: 0.0304911\n",
      "[330]\ttraining's mape: 0.0282146\tvalid_1's mape: 0.0304842\n",
      "[340]\ttraining's mape: 0.0281646\tvalid_1's mape: 0.0304798\n",
      "[350]\ttraining's mape: 0.0281179\tvalid_1's mape: 0.0304774\n",
      "[360]\ttraining's mape: 0.0280774\tvalid_1's mape: 0.0304707\n",
      "[370]\ttraining's mape: 0.0280321\tvalid_1's mape: 0.0304658\n",
      "[380]\ttraining's mape: 0.0279943\tvalid_1's mape: 0.0304592\n",
      "[390]\ttraining's mape: 0.0279633\tvalid_1's mape: 0.0304545\n",
      "[400]\ttraining's mape: 0.027934\tvalid_1's mape: 0.0304502\n",
      "[410]\ttraining's mape: 0.0279015\tvalid_1's mape: 0.0304469\n",
      "[420]\ttraining's mape: 0.027876\tvalid_1's mape: 0.0304409\n",
      "[430]\ttraining's mape: 0.0278421\tvalid_1's mape: 0.0304386\n",
      "[440]\ttraining's mape: 0.0278075\tvalid_1's mape: 0.0304341\n",
      "[450]\ttraining's mape: 0.0277678\tvalid_1's mape: 0.0304262\n",
      "[460]\ttraining's mape: 0.0277304\tvalid_1's mape: 0.0304238\n",
      "[470]\ttraining's mape: 0.0276963\tvalid_1's mape: 0.0304197\n",
      "[480]\ttraining's mape: 0.0276638\tvalid_1's mape: 0.0304156\n",
      "[490]\ttraining's mape: 0.0276339\tvalid_1's mape: 0.0304164\n",
      "[500]\ttraining's mape: 0.0276055\tvalid_1's mape: 0.0304147\n",
      "[510]\ttraining's mape: 0.0275775\tvalid_1's mape: 0.0304121\n",
      "[520]\ttraining's mape: 0.0275463\tvalid_1's mape: 0.0304101\n",
      "[530]\ttraining's mape: 0.0275273\tvalid_1's mape: 0.0304071\n",
      "[540]\ttraining's mape: 0.0275113\tvalid_1's mape: 0.0304055\n",
      "[550]\ttraining's mape: 0.0274791\tvalid_1's mape: 0.0304007\n",
      "[560]\ttraining's mape: 0.0274505\tvalid_1's mape: 0.0303984\n",
      "[570]\ttraining's mape: 0.0274295\tvalid_1's mape: 0.030395\n",
      "[580]\ttraining's mape: 0.0274053\tvalid_1's mape: 0.0303942\n",
      "[590]\ttraining's mape: 0.0273869\tvalid_1's mape: 0.0303938\n",
      "[600]\ttraining's mape: 0.0273663\tvalid_1's mape: 0.0303917\n",
      "[10]\ttraining's mape: 0.0326421\tvalid_1's mape: 0.033535\n",
      "[20]\ttraining's mape: 0.0320168\tvalid_1's mape: 0.0329866\n",
      "[30]\ttraining's mape: 0.0314322\tvalid_1's mape: 0.0324567\n",
      "[40]\ttraining's mape: 0.0311207\tvalid_1's mape: 0.03222\n",
      "[50]\ttraining's mape: 0.030805\tvalid_1's mape: 0.0319604\n",
      "[60]\ttraining's mape: 0.0305374\tvalid_1's mape: 0.0317901\n",
      "[70]\ttraining's mape: 0.0302953\tvalid_1's mape: 0.0316459\n",
      "[80]\ttraining's mape: 0.0301074\tvalid_1's mape: 0.0315477\n",
      "[90]\ttraining's mape: 0.0299508\tvalid_1's mape: 0.0314731\n",
      "[100]\ttraining's mape: 0.0297972\tvalid_1's mape: 0.0313728\n",
      "[110]\ttraining's mape: 0.0296598\tvalid_1's mape: 0.0313095\n",
      "[120]\ttraining's mape: 0.0295408\tvalid_1's mape: 0.0312599\n",
      "[130]\ttraining's mape: 0.0294241\tvalid_1's mape: 0.0312194\n",
      "[140]\ttraining's mape: 0.0293203\tvalid_1's mape: 0.0311818\n",
      "[150]\ttraining's mape: 0.029214\tvalid_1's mape: 0.0311553\n",
      "[160]\ttraining's mape: 0.0291257\tvalid_1's mape: 0.0311258\n",
      "[170]\ttraining's mape: 0.0290454\tvalid_1's mape: 0.0311025\n",
      "[180]\ttraining's mape: 0.0289651\tvalid_1's mape: 0.0310725\n",
      "[190]\ttraining's mape: 0.0288874\tvalid_1's mape: 0.0310639\n",
      "[200]\ttraining's mape: 0.02881\tvalid_1's mape: 0.0310447\n",
      "[210]\ttraining's mape: 0.0287371\tvalid_1's mape: 0.031028\n",
      "[220]\ttraining's mape: 0.0286764\tvalid_1's mape: 0.0310097\n",
      "[230]\ttraining's mape: 0.0286179\tvalid_1's mape: 0.0310011\n",
      "[240]\ttraining's mape: 0.0285645\tvalid_1's mape: 0.0309919\n",
      "[250]\ttraining's mape: 0.0285113\tvalid_1's mape: 0.0309827\n",
      "[260]\ttraining's mape: 0.0284588\tvalid_1's mape: 0.0309735\n",
      "[270]\ttraining's mape: 0.0284015\tvalid_1's mape: 0.0309719\n",
      "[280]\ttraining's mape: 0.0283442\tvalid_1's mape: 0.030959\n",
      "[290]\ttraining's mape: 0.0282985\tvalid_1's mape: 0.0309536\n",
      "[300]\ttraining's mape: 0.0282379\tvalid_1's mape: 0.0309449\n",
      "[310]\ttraining's mape: 0.0281851\tvalid_1's mape: 0.0309379\n",
      "[320]\ttraining's mape: 0.0281308\tvalid_1's mape: 0.030925\n",
      "[330]\ttraining's mape: 0.028088\tvalid_1's mape: 0.030917\n",
      "[340]\ttraining's mape: 0.0280406\tvalid_1's mape: 0.0309028\n",
      "[350]\ttraining's mape: 0.0279887\tvalid_1's mape: 0.0308927\n",
      "[360]\ttraining's mape: 0.0279384\tvalid_1's mape: 0.0308839\n",
      "[370]\ttraining's mape: 0.0278923\tvalid_1's mape: 0.0308772\n",
      "[380]\ttraining's mape: 0.0278477\tvalid_1's mape: 0.0308684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[390]\ttraining's mape: 0.027807\tvalid_1's mape: 0.0308634\n",
      "[400]\ttraining's mape: 0.0277738\tvalid_1's mape: 0.030855\n",
      "[410]\ttraining's mape: 0.0277367\tvalid_1's mape: 0.0308502\n",
      "[420]\ttraining's mape: 0.0277042\tvalid_1's mape: 0.0308438\n",
      "[430]\ttraining's mape: 0.0276799\tvalid_1's mape: 0.0308383\n",
      "[440]\ttraining's mape: 0.0276571\tvalid_1's mape: 0.0308373\n",
      "[450]\ttraining's mape: 0.0276296\tvalid_1's mape: 0.0308302\n",
      "[460]\ttraining's mape: 0.0276099\tvalid_1's mape: 0.030827\n",
      "[470]\ttraining's mape: 0.0275784\tvalid_1's mape: 0.0308211\n",
      "[480]\ttraining's mape: 0.0275427\tvalid_1's mape: 0.0308151\n",
      "[490]\ttraining's mape: 0.0275099\tvalid_1's mape: 0.0308124\n",
      "[500]\ttraining's mape: 0.0274814\tvalid_1's mape: 0.0308074\n",
      "[510]\ttraining's mape: 0.0274509\tvalid_1's mape: 0.0307977\n",
      "[520]\ttraining's mape: 0.0274259\tvalid_1's mape: 0.0307935\n",
      "[530]\ttraining's mape: 0.0274059\tvalid_1's mape: 0.0307889\n",
      "[540]\ttraining's mape: 0.02738\tvalid_1's mape: 0.0307844\n",
      "[550]\ttraining's mape: 0.0273561\tvalid_1's mape: 0.0307808\n",
      "[560]\ttraining's mape: 0.02733\tvalid_1's mape: 0.030779\n",
      "[570]\ttraining's mape: 0.0273006\tvalid_1's mape: 0.0307726\n",
      "[580]\ttraining's mape: 0.0272829\tvalid_1's mape: 0.0307707\n",
      "[590]\ttraining's mape: 0.0272716\tvalid_1's mape: 0.0307704\n",
      "[600]\ttraining's mape: 0.0272607\tvalid_1's mape: 0.0307713\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth':5, 'lambda_l1': 1, 'lambda_l2': 1,\n",
    " 'num_leaves': 30, 'feature_fraction': 0.4,\n",
    " 'subsample': 0.4, 'min_child_samples': 20,\n",
    " 'learning_rate': 0.05,\n",
    " 'num_iterations': 600, 'random_state': 42,\n",
    " 'objective': 'mape'}\n",
    "\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "        tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "        vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "        dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "        dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "        model = lgb.train(params, dtrain,\n",
    "                              num_boost_round=100000,\n",
    "                              valid_sets=[dtrain,dvalid],\n",
    "                              verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAdam(keras.optimizers.Optimizer):\n",
    "    \"\"\"RAdam optimizer.\n",
    "    # Arguments\n",
    "        learning_rate: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Weight decay for each param.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n",
    "        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n",
    "        min_lr: float >= 0. Minimum learning rate after warmup.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n",
    "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
    "        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n",
    "                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n",
    "        learning_rate = kwargs.pop('lr', learning_rate)\n",
    "        super(RAdam, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n",
    "            self.total_steps = K.variable(total_steps, name='total_steps')\n",
    "            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n",
    "            self.min_lr = K.variable(min_lr, name='min_lr')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.initial_weight_decay = weight_decay\n",
    "        self.initial_total_steps = total_steps\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "        if self.initial_total_steps > 0:\n",
    "            warmup_steps = self.total_steps * self.warmup_proportion\n",
    "            decay_steps = K.maximum(self.total_steps - warmup_steps, 1)\n",
    "            decay_rate = (self.min_lr - lr) / decay_steps\n",
    "            lr = K.switch(\n",
    "                t <= warmup_steps,\n",
    "                lr * (t / warmup_steps),\n",
    "                lr + decay_rate * K.minimum(t - warmup_steps, decay_steps),\n",
    "            )\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        else:\n",
    "            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n",
    "\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        beta_1_t = K.pow(self.beta_1, t)\n",
    "        beta_2_t = K.pow(self.beta_2, t)\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "\n",
    "            m_corr_t = m_t / (1.0 - beta_1_t)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t))\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t))\n",
    "\n",
    "            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                         (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                         sma_inf / sma_t)\n",
    "\n",
    "            p_t = K.switch(sma_t >= 5, r_t * m_corr_t / (v_corr_t + self.epsilon), m_corr_t)\n",
    "\n",
    "            if self.initial_weight_decay > 0:\n",
    "                p_t += self.weight_decay * p\n",
    "\n",
    "            p_t = p - lr * p_t\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self.learning_rate\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'learning_rate': float(K.get_value(self.learning_rate)),\n",
    "            'beta_1': float(K.get_value(self.beta_1)),\n",
    "            'beta_2': float(K.get_value(self.beta_2)),\n",
    "            'decay': float(K.get_value(self.decay)),\n",
    "            'weight_decay': float(K.get_value(self.weight_decay)),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': float(K.get_value(self.total_steps)),\n",
    "            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n",
    "            'min_lr': float(K.get_value(self.min_lr)),\n",
    "        }\n",
    "        base_config = super(RAdam, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - K.cumsum(y_pred, axis=1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    x = keras.layers.Input(shape=[X_train.shape[1]])\n",
    "    fc1 = keras.layers.Dense(units=50, input_shape=[X_train.shape[1]])(x)\n",
    "    act1 = keras.layers.PReLU()(fc1)\n",
    "    bn1 = keras.layers.BatchNormalization()(act1)\n",
    "    dp1 = keras.layers.Dropout(0.25)(bn1)\n",
    "    gn1 = keras.layers.GaussianNoise(0.15)(dp1)\n",
    "    concat1 = keras.layers.Concatenate()([x, gn1])\n",
    "    fc2 = keras.layers.Dense(units=50)(concat1)\n",
    "    act2 = keras.layers.PReLU()(fc2)\n",
    "    bn2 = keras.layers.BatchNormalization()(act2)\n",
    "    dp2 = keras.layers.Dropout(0.25)(bn2)\n",
    "    gn2 = keras.layers.GaussianNoise(0.15)(dp2)\n",
    "    concat2 = keras.layers.Concatenate()([concat1, gn2])\n",
    "    fc3 = keras.layers.Dense(units=50)(concat2)\n",
    "    act3 = keras.layers.PReLU()(fc3)\n",
    "    bn3 = keras.layers.BatchNormalization()(act3)\n",
    "    dp3 = keras.layers.Dropout(0.25)(bn3)\n",
    "    gn3 = keras.layers.GaussianNoise(0.15)(dp3)\n",
    "    concat3 = keras.layers.Concatenate([concat2, gn3])\n",
    "    output = keras.layers.Dense(units=199, activation='softmax')(concat2)\n",
    "    model = keras.models.Model(inputs=[x], outputs=[output])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val):\n",
    "    model = get_model()\n",
    "    model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-7), loss=crps)\n",
    "    er = EarlyStopping(patience=20, min_delta=1e-4, restore_best_weights=True, monitor='val_loss')\n",
    "    model.fit(X_train, y_train, epochs=200, callbacks=[er], validation_data=[X_val, y_val], batch_size=batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18536 samples, validate on 4635 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10688/18536 [================>.............] - ETA: 6:50 - loss: 0.086 - ETA: 3:48 - loss: 0.086 - ETA: 2:49 - loss: 0.086 - ETA: 2:19 - loss: 0.086 - ETA: 2:01 - loss: 0.087 - ETA: 1:50 - loss: 0.087 - ETA: 1:43 - loss: 0.087 - ETA: 1:37 - loss: 0.087 - ETA: 1:33 - loss: 0.087 - ETA: 1:29 - loss: 0.087 - ETA: 1:26 - loss: 0.088 - ETA: 1:24 - loss: 0.088 - ETA: 1:21 - loss: 0.088 - ETA: 1:19 - loss: 0.088 - ETA: 1:17 - loss: 0.088 - ETA: 1:15 - loss: 0.088 - ETA: 1:14 - loss: 0.088 - ETA: 1:12 - loss: 0.087 - ETA: 1:11 - loss: 0.088 - ETA: 1:09 - loss: 0.088 - ETA: 1:08 - loss: 0.088 - ETA: 1:07 - loss: 0.088 - ETA: 1:06 - loss: 0.087 - ETA: 1:06 - loss: 0.087 - ETA: 1:05 - loss: 0.087 - ETA: 1:04 - loss: 0.087 - ETA: 1:04 - loss: 0.087 - ETA: 1:03 - loss: 0.087 - ETA: 1:03 - loss: 0.087 - ETA: 1:02 - loss: 0.087 - ETA: 1:02 - loss: 0.087 - ETA: 1:01 - loss: 0.087 - ETA: 1:01 - loss: 0.087 - ETA: 1:00 - loss: 0.087 - ETA: 1:00 - loss: 0.087 - ETA: 59s - loss: 0.087 - ETA: 59s - loss: 0.08 - ETA: 59s - loss: 0.08 - ETA: 58s - loss: 0.08 - ETA: 58s - loss: 0.08 - ETA: 57s - loss: 0.08 - ETA: 57s - loss: 0.08 - ETA: 57s - loss: 0.08 - ETA: 57s - loss: 0.08 - ETA: 56s - loss: 0.08 - ETA: 56s - loss: 0.08 - ETA: 56s - loss: 0.08 - ETA: 55s - loss: 0.08 - ETA: 55s - loss: 0.08 - ETA: 55s - loss: 0.08 - ETA: 55s - loss: 0.08 - ETA: 54s - loss: 0.08 - ETA: 54s - loss: 0.08 - ETA: 54s - loss: 0.08 - ETA: 54s - loss: 0.08 - ETA: 53s - loss: 0.08 - ETA: 53s - loss: 0.08 - ETA: 53s - loss: 0.08 - ETA: 53s - loss: 0.08 - ETA: 53s - loss: 0.08 - ETA: 52s - loss: 0.08 - ETA: 52s - loss: 0.08 - ETA: 52s - loss: 0.08 - ETA: 52s - loss: 0.08 - ETA: 52s - loss: 0.08 - ETA: 52s - loss: 0.08 - ETA: 51s - loss: 0.08 - ETA: 51s - loss: 0.08 - ETA: 51s - loss: 0.08 - ETA: 51s - loss: 0.08 - ETA: 51s - loss: 0.08 - ETA: 51s - loss: 0.08 - ETA: 50s - loss: 0.08 - ETA: 50s - loss: 0.08 - ETA: 50s - loss: 0.08 - ETA: 50s - loss: 0.08 - ETA: 50s - loss: 0.08 - ETA: 49s - loss: 0.08 - ETA: 49s - loss: 0.08 - ETA: 49s - loss: 0.08 - ETA: 49s - loss: 0.08 - ETA: 49s - loss: 0.08 - ETA: 49s - loss: 0.08 - ETA: 49s - loss: 0.08 - ETA: 48s - loss: 0.08 - ETA: 48s - loss: 0.08 - ETA: 48s - loss: 0.08 - ETA: 48s - loss: 0.08 - ETA: 48s - loss: 0.08 - ETA: 48s - loss: 0.08 - ETA: 47s - loss: 0.08 - ETA: 47s - loss: 0.08 - ETA: 47s - loss: 0.08 - ETA: 47s - loss: 0.08 - ETA: 47s - loss: 0.08 - ETA: 47s - loss: 0.08 - ETA: 47s - loss: 0.08 - ETA: 46s - loss: 0.08 - ETA: 46s - loss: 0.08 - ETA: 46s - loss: 0.08 - ETA: 46s - loss: 0.08 - ETA: 46s - loss: 0.08 - ETA: 46s - loss: 0.08 - ETA: 46s - loss: 0.08 - ETA: 45s - loss: 0.08 - ETA: 45s - loss: 0.08 - ETA: 45s - loss: 0.08 - ETA: 45s - loss: 0.08 - ETA: 45s - loss: 0.08 - ETA: 45s - loss: 0.08 - ETA: 45s - loss: 0.08 - ETA: 45s - loss: 0.08 - ETA: 44s - loss: 0.08 - ETA: 44s - loss: 0.08 - ETA: 44s - loss: 0.08 - ETA: 44s - loss: 0.08 - ETA: 44s - loss: 0.08 - ETA: 44s - loss: 0.08 - ETA: 44s - loss: 0.08 - ETA: 44s - loss: 0.08 - ETA: 43s - loss: 0.08 - ETA: 43s - loss: 0.08 - ETA: 43s - loss: 0.08 - ETA: 43s - loss: 0.08 - ETA: 43s - loss: 0.08 - ETA: 43s - loss: 0.08 - ETA: 43s - loss: 0.08 - ETA: 43s - loss: 0.08 - ETA: 43s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 42s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 40s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 39s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 38s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 37s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 36s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 34s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 33s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 32s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 31s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 29s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 28s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 27s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 26s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 25s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 23s - loss: 0.08 - ETA: 23s - loss: 0.08 - ETA: 23s - loss: 0.08 - ETA: 23s - loss: 0.08 - ETA: 23s - loss: 0.08 - ETA: 23s - loss: 0.08 - ETA: 23s - loss: 0.08 - ETA: 23s - loss: 0.0872\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10816/18536 [================>.............] - ETA: 23s - loss: 0.08 - ETA: 23s - loss: 0.08 - ETA: 22s - loss: 0.08 - ETA: 22s - loss: 0.0872"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-303-55562073c5c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mx_vl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvl_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvl_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_vl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-296-fba178e4016b>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarmup_proportion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcrps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "X_train = train_x\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "y_train = np.zeros(shape=(X_train.shape[0], 199))\n",
    "for i,yard in enumerate(train_y.reset_index(drop=True).Yards):\n",
    "    y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "models = []\n",
    "\n",
    "for tr_idx, vl_idx in rkf.split(X_train, y_train):\n",
    "    \n",
    "    x_tr, y_tr = X_train[tr_idx], y_train[tr_idx]\n",
    "    x_vl, y_vl = X_train[vl_idx], y_train[vl_idx]\n",
    "    \n",
    "    model = train_model(x_tr, y_tr, x_vl, y_vl)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "0.012558720296237821\n",
      "Fold : 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-309-fb8135b42577>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mX_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mscore_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrps1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "y = np.zeros((train_y.shape[0], 199))\n",
    "def crps1(y_true, y_pred):\n",
    "    y_true = np.clip(np.cumsum(y_true, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    return ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * y_true.shape[0]) \n",
    "for idx, target in enumerate(train_y.reset_index(drop=True).Yards):\n",
    "    y[idx][99 + target] = 1\n",
    "models = []\n",
    "kf = KFold(n_splits=5, random_state=42)\n",
    "score = []\n",
    "for i, (tdx, vdx) in enumerate(kf.split(X_train, y)):\n",
    "    print(f'Fold : {i}')\n",
    "    X_tra, X_val, y_tra, y_val = X_train[tdx], X_train[vdx], y[tdx], y[vdx]\n",
    "    model = RandomForestRegressor(bootstrap=False, max_features=0.5, min_samples_leaf=15, min_samples_split=7, n_estimators=100, n_jobs=-1, random_state=42)\n",
    "    model.fit(X_tra, y_tra)\n",
    "    score_ = crps1(y_val, model.predict(X_val))\n",
    "    print(score_)\n",
    "    score.append(score_)\n",
    "    models.append(model)\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
