{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import datetime, tqdm\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "pd.set_option('max_columns', 100)\n",
    "#from kaggle.competitions import nflrush\n",
    "from sklearn.model_selection import KFold, RepeatedKFold,GroupKFold\n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense,Dropout, PReLU, BatchNormalization, ELU, GaussianNoise, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import keras.backend as K\n",
    "#note： \n",
    "#1. As a result it might not be worthwhile to use features related to game clock/quarter of the game。\n",
    "#2. There is no relationships between number of rushes before and running yards gained。\n",
    "#3. rushing success larger depends on defender in box, or defender that are close to offensive lineman and attempt \n",
    "#   to counter the blocking.\n",
    "#4. highly drafted player has the same average rushing yards as the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\38980\\OneDrive\\Desktop\\study\\kaggle\\NFL\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team abbreviations correct\n",
    "def data_clean(df):\n",
    "#correct name   \n",
    "    df.loc[df['PossessionTeam'] == 'ARZ', 'PossessionTeam'] = 'ARI'\n",
    "    df.loc[df['PossessionTeam'] == 'BLT', 'PossessionTeam'] = 'BAL'\n",
    "    df.loc[df['PossessionTeam'] == 'CLV', 'PossessionTeam'] = 'CLE'\n",
    "    df.loc[df['PossessionTeam'] == 'HST', 'PossessionTeam'] = 'HOU'\n",
    "    df.loc[df['FieldPosition'] == 'ARZ', 'FieldPosition'] = 'ARI'\n",
    "    df.loc[df['FieldPosition'] == 'BLT', 'FieldPosition'] = 'BAL'\n",
    "    df.loc[df['FieldPosition'] == 'CLV', 'FieldPosition'] = 'CLE'\n",
    "    df.loc[df['FieldPosition'] == 'HST', 'FieldPosition'] = 'HOU'\n",
    "\n",
    "# fill null\n",
    "    df = df.fillna(df.median())\n",
    "\n",
    "# offense time and defence time\n",
    "    df['TeamOnOffense'] = \"home\"\n",
    "    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    df['IsOnOffense'] = df.Team == df.TeamOnOffense # Is player on offense?\n",
    "    \n",
    "#time\n",
    "    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    seconds_in_year = 60*60*24*365.25\n",
    "    df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "    df['GameClock'] = df['GameClock'].apply(lambda x: float(x.split(\":\")[0]) + float(x.split(\":\")[1])/60)\n",
    "    df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "#player height\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "\n",
    "#weather\n",
    "    def map_weather(txt):\n",
    "        ans = 1\n",
    "        if pd.isna(txt):\n",
    "            return 0\n",
    "        if 'partly' in txt:\n",
    "            ans*=0.5\n",
    "        if 'climate controlled' in txt or 'indoor' in txt:\n",
    "            return ans*3\n",
    "        if 'sunny' in txt or 'sun' in txt:\n",
    "            return ans*2\n",
    "        if 'clear' in txt:\n",
    "            return ans\n",
    "        if 'cloudy' in txt:\n",
    "            return -ans\n",
    "        if 'rain' in txt or 'rainy' in txt:\n",
    "            return -2*ans\n",
    "        if 'snow' in txt:\n",
    "            return -3*ans\n",
    "        return 0\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['Cleaned_GameWeather'].apply(map_weather)\n",
    "\n",
    "#diff Score    \n",
    "    df[\"DiffScoreBeforePlay_ob\"] = (df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"])\n",
    "    df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]] = - df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]]\n",
    "#Turf\n",
    "    def agrupar_gramado(Turf):\n",
    "        if Turf == 'Artifical':\n",
    "            return 'Artificial'\n",
    "\n",
    "        elif Turf in ('FieldTurf', 'Field turf'):\n",
    "            return 'Field Turf'\n",
    "\n",
    "        elif Turf in ('FieldTurf360', 'FieldTurf 360'):\n",
    "            return 'Field Turf 360'\n",
    "\n",
    "        elif Turf in ('Natural', 'Natural grass', 'Naturall Grass', 'grass', 'natural grass', 'SISGrass', 'Natural Grass'):\n",
    "            return \"Grass\"\n",
    "\n",
    "        elif Turf == \"UBU Sports Speed S5-M\":\n",
    "            return \"UBU Speed Series-S5-M\"\n",
    "\n",
    "        else:\n",
    "            return Turf\n",
    "        df['Turf'] = df['Turf'].apply(agrupar_gramado)\n",
    "\n",
    "#left to right\n",
    "    df['New_X'] = df['X']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_X'] = 120 - df.loc[df['PlayDirection'] == 'left','X']\n",
    "    df['New_Y'] = df['Y']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_Y'] = 160/3 - df.loc[df['PlayDirection'] == 'left','Y']\n",
    "    df['Orientation_std'] = df['Orientation']\n",
    "    df.loc[df['Season'] == 2017, 'Orientation_std'] = df.loc[df['Season'] == 2017, 'Orientation_std'] + 90\n",
    "    #df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std'] = 360 - df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Orientation_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Orientation_std'], 360)\n",
    "    df['Dir_std'] = df['Dir']\n",
    "    #df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = 360 - df.loc[df['PlayDirection'] == 'left', 'Dir_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Dir_std'], 360)\n",
    "    df['YardLine_std'] = 100 - df['YardLine']\n",
    "    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine_std'\n",
    "         ] = df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine']\n",
    "    df[\"Orientation_sin\"] = df[\"Orientation_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Orientation_cos\"] = df[\"Orientation_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_sin\"] = df[\"Dir_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_cos\"] = df[\"Dir_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "\n",
    "#distance and S\n",
    "    #distance to yardline\n",
    "    df['Dis_YardLine'] = df['New_X'] - df['YardLine_std'] - 10\n",
    "    #distance to rusher\n",
    "    def Distance(x1,x2,y1,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "    def Degree(x1,x2,y1,y2):\n",
    "        try:\n",
    "            tan = (y1-y2)/(x1-x2)\n",
    "        except:\n",
    "            tan = 0\n",
    "        degree = 90 - math.atan(tan)/(2*np.pi)*360\n",
    "        return degree\n",
    "    df['IsRusher'] = (df['NflId'] == df['NflIdRusher'])\n",
    "    Rusher =df.loc[df['IsRusher'],['PlayId','X','Y','Dir_std','S']].rename(columns={\"X\":\"Rusher_X\",\"Y\":\"Rusher_Y\",'PossessionTeam':'Offense_Team','Dir_std':'Rusher_Dir_std','S':'Rusher_Speed'})\n",
    "    df = df.merge(Rusher,how = 'left',on = 'PlayId')\n",
    "    df['Distance_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Distance(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Degree(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_Diff'] = df['Degree_to_Rusher'] - df['Rusher_Dir_std']\n",
    "    df['Speed_Ratio'] =  df['Rusher_Speed']/df['S']\n",
    "    #back_direction\n",
    "    def back_direction(orientation):\n",
    "        if orientation > 180.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df['back_oriented_down_field'] = df['Orientation_std'].apply(lambda x: back_direction(x))\n",
    "\n",
    "# Stadium and location clean\n",
    "    def agrupar_local(Location):\n",
    "        if Location == \"Arlington, Texas\":\n",
    "            return \"Arlington, TX\"\n",
    "        elif Location in (\"Baltimore, Maryland\",\"Baltimore, Md.\"):\n",
    "            return \"Baltimore, MD\"\n",
    "        elif Location == \"Charlotte, North Carolina\":\n",
    "            return \"Charlotte, NC\"\n",
    "        elif Location == \"Chicago. IL\":\n",
    "            return \"Chicago, IL\"\n",
    "        elif Location == \"Cincinnati, Ohio\":\n",
    "            return \"Cincinnati, OH\"\n",
    "        elif Location in (\"Cleveland\",\"Cleveland Ohio\",\"Cleveland, Ohio\",\"Cleveland,Ohio\"):\n",
    "            return \"Cleveland, OH\"\n",
    "        elif Location == \"Detroit\":\n",
    "            return \"Detroit, MI\"\n",
    "        elif Location == \"E. Rutherford, NJ\" or Location == \"East Rutherford, N.J.\":\n",
    "            return \"East Rutherford, NJ\"\n",
    "        elif Location == \"Foxborough, Ma\":\n",
    "            return \"Foxborough, MA\"\n",
    "        elif Location == \"Houston, Texas\":\n",
    "            return \"Houston, TX\"\n",
    "        elif Location in (\"Jacksonville Florida\",\"Jacksonville, Fl\",\"Jacksonville, Florida\"):\n",
    "            return \"Jacksonville, FL\"\n",
    "        elif Location == \"London\":\n",
    "            return \"London, England\"\n",
    "        elif Location == \"Los Angeles, Calif.\":\n",
    "            return \"Los Angeles, CA\"\n",
    "        elif Location == \"Miami Gardens, Fla.\":\n",
    "            return \"Miami Gardens, FLA\"\n",
    "        elif Location in (\"New Orleans\",\"New Orleans, La.\"):\n",
    "            return \"New Orleans, LA\"\n",
    "        elif Location == \"Orchard Park NY\":\n",
    "            return \"Orchard Park, NY\"\n",
    "        elif Location == \"Philadelphia, Pa.\":\n",
    "            return \"Philadelphia, PA\"\n",
    "        elif Location == \"Pittsburgh\":\n",
    "            return \"Pittsburgh, PA\"\n",
    "        elif Location == \"Seattle\":\n",
    "            return \"Seattle, WA\"\n",
    "        else:\n",
    "            return Location\n",
    "\n",
    "    df['Location'] = df['Location'].apply(agrupar_local)\n",
    "\n",
    "# stadium types\n",
    "    def agrupar_tipo_estadio(StadiumType):\n",
    "        outdoor       = ['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', 'Outside', 'Outddors', 'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n",
    "        indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', 'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n",
    "        indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "        dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "        dome_open     = ['Domed, Open', 'Domed, open']\n",
    "\n",
    "        if StadiumType in outdoor:\n",
    "            return 'outdoor'\n",
    "        elif StadiumType in indoor_closed:\n",
    "            return 'indoor_closed'\n",
    "        elif StadiumType in indoor_open:\n",
    "            return 'indoor_open'\n",
    "        elif StadiumType in dome_closed:\n",
    "            return 'dome_closed'\n",
    "        elif StadiumType in dome_open:\n",
    "            return 'dome_open'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    df['StadiumType'] = df['StadiumType'].apply(agrupar_tipo_estadio)\n",
    "\n",
    "# wind \n",
    "    def give_me_WindSpeed(x):\n",
    "            x = str(x)\n",
    "            x = x.replace('mph', '').strip()\n",
    "            if '-' in x:\n",
    "                x = (int(x.split('-')[0]) + int(x.split('-')[1])) / 2\n",
    "            elif 'gusts up to' in x:\n",
    "                x = (int(x.split()[0]) + int(x.split()[-1])) / 2\n",
    "            elif 'clam' in x:\n",
    "                x = 0\n",
    "            try:\n",
    "                return float(x)\n",
    "            except:\n",
    "                return -99\n",
    "    df['Cleaned_WindSpeed'] = df['WindSpeed'].apply(give_me_WindSpeed)\n",
    "\n",
    "# wind direction\n",
    "    def agrupa_wind_direction(WindDirection):\n",
    "        wd = str(WindDirection).upper()\n",
    "\n",
    "        if wd == 'N' or 'FROM N' in wd:\n",
    "            return 'north'\n",
    "        if wd == 'S' or 'FROM S' in wd:\n",
    "            return 'south'\n",
    "        if wd == 'W' or 'FROM W' in wd:\n",
    "            return 'west'\n",
    "        if wd == 'E' or 'FROM E' in wd:\n",
    "            return 'east'\n",
    "\n",
    "        if 'FROM SW' in wd or 'FROM SSW' in wd or 'FROM WSW' in wd:\n",
    "            return 'south west'\n",
    "        if 'FROM SE' in wd or 'FROM SSE' in wd or 'FROM ESE' in wd:\n",
    "            return 'south east'\n",
    "        if 'FROM NW' in wd or 'FROM NNW' in wd or 'FROM WNW' in wd:\n",
    "            return 'north west'\n",
    "        if 'FROM NE' in wd or 'FROM NNE' in wd or 'FROM ENE' in wd:\n",
    "            return 'north east'\n",
    "\n",
    "        if 'NW' in wd or 'NORTHWEST' in wd:\n",
    "            return 'north west'\n",
    "        if 'NE' in wd or 'NORTH EAST' in wd:\n",
    "            return 'north east'\n",
    "        if 'SW' in wd or 'SOUTHWEST' in wd:\n",
    "            return 'south west'\n",
    "        if 'SE' in wd or 'SOUTHEAST' in wd:\n",
    "            return 'south east'\n",
    "\n",
    "        return 'unknown'\n",
    "    \n",
    "    df['WindDirection'] = df['WindDirection'].apply(agrupa_wind_direction)\n",
    "\n",
    "# speed\n",
    "    df.loc[df['Season'] == 2017, 'S'] = (df.loc[df['Season'] == 2017, 'S'] - 2.4355) / 1.2930 * 1.4551 + 2.7570\n",
    "    df['Horizontal Speed'] = df['S']*df[\"Dir_sin\"]\n",
    "    df['Vertical Speed'] = df['S']*df[\"Dir_cos\"]\n",
    "# momentum\n",
    "    df['momentum'] = df['S']*df['PlayerWeight']\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:116: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "train = data_clean(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    df1 = df.loc[df['IsRusher']]\n",
    "    df2 = df.loc[df['IsOnOffense'] & (~df['IsRusher'])]\n",
    "    df3 = df.loc[~df['IsOnOffense']]\n",
    "\n",
    "# max yards\n",
    "    df1['Max_Yards'] = df1['YardLine']\n",
    "    df1.loc[(df1.FieldPosition.fillna('') == df1.PossessionTeam)&(df1.PlayDirection =='left'),  'Max_Yards'] \\\n",
    "    = 100 - df1.loc[(df1.FieldPosition.fillna('') == df1.PossessionTeam)&(df1.PlayDirection =='left'),  'Max_Yards']\n",
    "    df1.loc[(df1.FieldPosition.fillna('') != df1.PossessionTeam)&(df1.PlayDirection =='right'),  'Max_Yards'] \\\n",
    "    = 100 - df1.loc[(df1.FieldPosition.fillna('') != df1.PossessionTeam)&(df1.PlayDirection =='right'),  'Max_Yards']\n",
    "# min_time_to_tacke\n",
    "    df3['Min_Time_Tacke'] = df3['Distance_to_Rusher']/df3['S']\n",
    "    df3.loc[df3['Min_Time_Tacke'] == np.inf, 'Min_Time_Tacke'] = 20\n",
    "# defence_X_Y_spread\n",
    "    Defence_X_Y_std = df3[[\"PlayId\",'New_X','New_Y']].groupby(\"PlayId\").std().rename(columns={'New_X':'Defense_X_std','New_Y':'Defense_Y_std'}) \\\n",
    "    .reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed2_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed2_std'}).reset_index()\n",
    "\n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_Y_Removed2_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(4).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed4_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(2).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed4_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_Y_Removed4_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(4).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Defence_X_Y_std, how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "\n",
    "#distance to QB\n",
    "    dis_QB = df2.loc[df2[\"Position\"] =='QB',['PlayId','Distance_to_Rusher']].groupby(['PlayId']).mean().rename(columns={'Distance_to_Rusher':'dis_to_QB'})\n",
    "    df1 = df1.merge(dis_QB,how = 'left', on='PlayId')\n",
    "#defence min,max,mean,std distance to rusher\n",
    "    stat = df3.groupby(['GameId','PlayId']).agg({'Distance_to_Rusher':['min','max','mean','std']})\n",
    "    stat.columns = stat.columns.droplevel()\n",
    "    df1 = df1.merge(stat,how = 'left', on='PlayId')\n",
    "\n",
    "# offense_X_Y_spread\n",
    "    df2 = df2.sort_values(['PlayId','New_X'])\n",
    "    Offense_X_Removed2_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed2_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed2_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_X_Removed4_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed4_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed4_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Offense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    \n",
    "# nearest offenders to defender\n",
    "    dis_to_closest_offender = pd.DataFrame()\n",
    "    for playid in df3['PlayId'].unique():\n",
    "        offense = df2.loc[df2['PlayId'] == playid]\n",
    "        defence = df3.loc[df3['PlayId'] == playid]\n",
    "        ary = scipy.spatial.distance.cdist(defence[['New_X','New_Y']], offense[['New_X','New_Y']], metric='euclidean')\n",
    "        ary.sort(axis=1)\n",
    "        ary = pd.DataFrame(data = ary)\n",
    "        ary['PlayId'] = playid\n",
    "        ary.reset_index(drop=True, inplace=True)\n",
    "        ary = pd.concat([ary, defence[['NflId']].reset_index(drop=True)], axis=1)\n",
    "        dis_to_closest_offender = dis_to_closest_offender.append(ary)\n",
    "    df3 = df3.merge(dis_to_closest_offender,how = 'left',on = ['PlayId','NflId'])\n",
    "\n",
    "# personnel_features\n",
    "    def defense_formation(l):\n",
    "        dl = 0\n",
    "        lb = 0\n",
    "        db = 0\n",
    "        other = 0\n",
    "\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            if sub_string[1] == 'DL':\n",
    "                dl += int(sub_string[0])\n",
    "            elif sub_string[1] in ['LB','OL']:\n",
    "                lb += int(sub_string[0])\n",
    "            else:\n",
    "                db += int(sub_string[0])\n",
    "\n",
    "        counts = (dl,lb,db,other)\n",
    "\n",
    "        return counts\n",
    "    def offense_formation(l):\n",
    "        qb = 0\n",
    "        rb = 0\n",
    "        wr = 0\n",
    "        te = 0\n",
    "        ol = 0\n",
    "\n",
    "        sub_total = 0\n",
    "        qb_listed = False\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            pos = sub_string[1]\n",
    "            cnt = int(sub_string[0])\n",
    "\n",
    "            if pos == 'QB':\n",
    "                qb += cnt\n",
    "                sub_total += cnt\n",
    "                qb_listed = True\n",
    "            # Assuming LB is a line backer lined up as full back\n",
    "            elif pos in ['RB','LB']:\n",
    "                rb += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DB is a defensive back and lined up as WR\n",
    "            elif pos in ['WR','DB']:\n",
    "                wr += cnt\n",
    "                sub_total += cnt\n",
    "            elif pos == 'TE':\n",
    "                te += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DL is a defensive lineman lined up as an additional line man\n",
    "            else:\n",
    "                ol += cnt\n",
    "                sub_total += cnt\n",
    "\n",
    "        # If not all 11 players were noted at given positions we need to make some assumptions\n",
    "        # I will assume if a QB is not listed then there was 1 QB on the play\n",
    "        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n",
    "        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n",
    "        if sub_total < 11:\n",
    "            diff = 11 - sub_total\n",
    "            if not qb_listed:\n",
    "                qb += 1\n",
    "                diff -= 1\n",
    "            ol += diff\n",
    "\n",
    "        counts = (qb,rb,wr,te,ol)\n",
    "\n",
    "        return counts\n",
    "    def split_personnel(s):\n",
    "        splits = s.split(',')\n",
    "        for i in range(len(splits)):\n",
    "            splits[i] = splits[i].strip()\n",
    "\n",
    "        return splits    \n",
    "    def personnel_features(df):\n",
    "        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n",
    "        personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n",
    "\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n",
    "        personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n",
    "        personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n",
    "        personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n",
    "\n",
    "        # Let's create some features to specify if the OL is covered\n",
    "        personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n",
    "        personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n",
    "        # Let's create a feature to specify if the defense is preventing the run\n",
    "        # Let's just assume 7 or more DL and LB is run prevention\n",
    "        personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n",
    "\n",
    "        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n",
    "        \n",
    "        return personnel\n",
    "    \n",
    "    personnel = personnel_features(df1)   \n",
    "    df1 = df1.merge(personnel,how = 'left',  on ='PlayId')\n",
    "    \n",
    "#select useful columns    \n",
    "    rusher = df1[['PlayId','TimeDelta','Team','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y', \\\n",
    "                 'Orientation_std','Dir_std','Dis_YardLine','Horizontal Speed','Vertical Speed','S','A','Dis','Position',\\\n",
    "                 'Quarter','GameClock','Down','Distance','OffenseFormation',\\\n",
    "                  'DefendersInTheBox','HomeScoreBeforePlay','VisitorScoreBeforePlay',\\\n",
    "                 'Offense_X_Removed2_std','Offense_Y_Removed2_std','Offense_X_Removed4_std','Offense_Y_Removed4_std',\\\n",
    "                 'Defense_X_std','Defense_Y_std','Defense_X_Removed2_std','Offense_Y_Removed2_std','Defense_X_Removed4_std',\\\n",
    "                 'Defense_Y_Removed4_std',\\\n",
    "                  'num_DL','num_LB','num_DB','num_QB','num_RB','num_WR','num_TE','num_OL','OL_diff','OL_TE_diff','run_def',\\\n",
    "                 'min','max','std','mean','dis_to_QB','Max_Yards']]\n",
    "    rusher = rusher.sort_values('PlayId')\n",
    "    game = df1[['PlayId','Cleaned_GameWeather','Humidity','Temperature', \\\n",
    "              'Week','WindDirection','Cleaned_WindSpeed','Location','StadiumType','PlayDirection']]\n",
    "    game = game.sort_values('PlayId')\n",
    "    offender = df2[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std','back_oriented_down_field',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff']]\n",
    "    offender = offender.sort_values(['PlayId','Distance_to_Rusher'])\n",
    "    defender = df3[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std','back_oriented_down_field',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff','Min_Time_Tacke','Speed_Ratio']+list(range(2))] #list(range(2)) two closest offenders\n",
    "    defender = defender.sort_values(['PlayId','Distance_to_Rusher'])\n",
    "\n",
    "    \n",
    "    return rusher, game, offender, defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "rusher, game, offender, defender = split_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove some columns\n",
    "rusher = rusher.drop('max',axis = 1)\n",
    "game = game.drop(['Humidity'], axis = 1)\n",
    "\n",
    "offender = offender.drop(['back_oriented_down_field'],axis = 1)\n",
    "offender = offender.sort_values(['PlayId','Distance_to_Rusher']).groupby('PlayId').head(2)\n",
    "defender = defender.sort_values(['PlayId','Distance_to_Rusher']).drop(['New_Y','back_oriented_down_field','Position'],axis = 1).groupby('PlayId').head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACE', 'Arlington, TX', 'Atlanta, GA', 'Baltimore, MD', 'C', 'CB',\n",
       "       'Carson, CA', 'Charlotte, NC', 'Chicago, IL', 'Cincinnati, OH',\n",
       "       'Cleveland, OH', 'DE', 'DT', 'Denver, CO', 'Detroit, MI', 'EMPTY',\n",
       "       'East Rutherford, NJ', 'FB', 'Foxborough, MA', 'G', 'Glendale, AZ',\n",
       "       'Green Bay, WI', 'HB', 'Houston, TX', 'I_FORM',\n",
       "       'Indianapolis, Ind.', 'JUMBO', 'Jacksonville, FL',\n",
       "       'Kansas City,  MO', 'Kansas City, MO', 'Landover, MD',\n",
       "       'London, England', 'Los Angeles, CA', 'Mexico City',\n",
       "       'Miami Gardens, FLA', 'Minneapolis, MN', 'NT', 'Nashville, TN',\n",
       "       'New Orleans, LA', 'OG', 'OLB', 'OT', 'Oakland, CA',\n",
       "       'Orchard Park, NY', 'PISTOL', 'Philadelphia, PA', 'Pittsburgh, PA',\n",
       "       'QB', 'RB', 'SHOTGUN', 'SINGLEBACK', 'Santa Clara, CA',\n",
       "       'Seattle, WA', 'T', 'TE', 'Tampa, FL', 'WILDCAT', 'WR', 'away',\n",
       "       'dome_closed', 'dome_open', 'east', 'home', 'indoor_closed',\n",
       "       'indoor_open', 'left', 'nan', 'north', 'north east', 'north west',\n",
       "       'outdoor', 'right', 'south', 'south east', 'south west', 'unknown',\n",
       "       'west'], dtype=object)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding fit\n",
    "le = preprocessing.LabelEncoder()\n",
    "categories =[]\n",
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = rusher[i].astype(str)\n",
    "    categories.append(rusher[i].unique())\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = game[i].astype(str)\n",
    "    categories.append(game[i].unique())\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = offender[i].astype(str)\n",
    "    categories.append(offender[i].unique())\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = defender[i].astype(str)\n",
    "    categories.append(defender[i].unique())\n",
    "categories = np.hstack(categories)\n",
    "le.fit(categories)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding transform\n",
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = le.transform(rusher[i])\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = le.transform(game[i])\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = le.transform(offender[i])\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = le.transform(defender[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape offender\n",
    "offender_players = [offender.drop('PlayId',axis = 1).iloc[np.arange(k, len(offender), 2)].reset_index(drop = True) for k in range(2)]\n",
    "offender_players = np.hstack([t.values for t in offender_players])\n",
    "offender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 90)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape defender\n",
    "defender_players = [defender.drop('PlayId',axis = 1).iloc[np.arange(k, len(defender), 5)].reset_index(drop = True) for k in range(5)]\n",
    "defender_players = np.hstack([t.values for t in defender_players])\n",
    "defender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_y =train.loc[train['IsRusher'],['Yards','PlayId']].sort_values('PlayId').drop('PlayId',axis = 1)\n",
    "train_x = np.hstack([rusher.drop('PlayId',axis = 1).values,defender_players,offender_players])\n",
    "train_y99 =(train_y + 99).reset_index(drop=True).Yards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def crps_eval(y_pred, dataset, is_higher_better=False):\n",
    "    labels = dataset.get_label()\n",
    "    labels = labels.astype('int')\n",
    "    y_true = np.zeros((len(labels),199))\n",
    "    for i, v in enumerate(labels):\n",
    "        y_true[i, v:] = 1\n",
    "    y_pred = y_pred.reshape(-1, 199, order='F')\n",
    "    y_pred = np.clip(y_pred.cumsum(axis=1), 0, 1)\n",
    "    return 'crps', np.mean((y_pred - y_true)**2), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "params = {'max_depth':5, 'lambda_l1': 1.2, 'lambda_l2': 1.2,\n",
    " 'num_leaves': 32, 'feature_fraction': 0.4,\n",
    " 'subsample': 0.4, 'min_child_samples': 15,\n",
    " 'learning_rate': 0.02,\n",
    " 'num_iterations': 1000, 'random_state': 42,\n",
    " 'objective': 'multiclass',\n",
    " 'min_gain_to_split':0.9,\n",
    " 'num_class':199,\n",
    " 'metric':'None'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 7 rounds\n",
      "[100]\ttraining's crps: 0.0126837\tvalid_1's crps: 0.0133622\n",
      "[200]\ttraining's crps: 0.0115451\tvalid_1's crps: 0.0130624\n",
      "[300]\ttraining's crps: 0.0108678\tvalid_1's crps: 0.012931\n",
      "[400]\ttraining's crps: 0.0104331\tvalid_1's crps: 0.0128705\n",
      "[500]\ttraining's crps: 0.0101361\tvalid_1's crps: 0.012836\n",
      "[600]\ttraining's crps: 0.00990675\tvalid_1's crps: 0.0128169\n",
      "[700]\ttraining's crps: 0.00974295\tvalid_1's crps: 0.0128032\n",
      "[800]\ttraining's crps: 0.00962582\tvalid_1's crps: 0.0127954\n",
      "[900]\ttraining's crps: 0.00955819\tvalid_1's crps: 0.0127895\n",
      "Early stopping, best iteration is:\n",
      "[992]\ttraining's crps: 0.00952965\tvalid_1's crps: 0.0127868\n",
      "Training until validation scores don't improve for 7 rounds\n",
      "[100]\ttraining's crps: 0.0127112\tvalid_1's crps: 0.013276\n",
      "[200]\ttraining's crps: 0.0115912\tvalid_1's crps: 0.012978\n",
      "[300]\ttraining's crps: 0.010922\tvalid_1's crps: 0.0128523\n",
      "[400]\ttraining's crps: 0.0105043\tvalid_1's crps: 0.0127904\n",
      "[500]\ttraining's crps: 0.0102156\tvalid_1's crps: 0.0127552\n",
      "[600]\ttraining's crps: 0.00999264\tvalid_1's crps: 0.0127346\n",
      "[700]\ttraining's crps: 0.00982628\tvalid_1's crps: 0.0127188\n",
      "[800]\ttraining's crps: 0.00971189\tvalid_1's crps: 0.0127102\n",
      "Early stopping, best iteration is:\n",
      "[883]\ttraining's crps: 0.00964821\tvalid_1's crps: 0.0127041\n",
      "Training until validation scores don't improve for 7 rounds\n",
      "[100]\ttraining's crps: 0.0127575\tvalid_1's crps: 0.0131508\n",
      "[200]\ttraining's crps: 0.0116688\tvalid_1's crps: 0.0128639\n",
      "[300]\ttraining's crps: 0.0110257\tvalid_1's crps: 0.0127438\n",
      "[400]\ttraining's crps: 0.0106121\tvalid_1's crps: 0.0126888\n",
      "[500]\ttraining's crps: 0.0103111\tvalid_1's crps: 0.0126588\n",
      "[600]\ttraining's crps: 0.010089\tvalid_1's crps: 0.0126398\n",
      "[700]\ttraining's crps: 0.0099277\tvalid_1's crps: 0.0126275\n",
      "[800]\ttraining's crps: 0.00980561\tvalid_1's crps: 0.0126194\n",
      "[900]\ttraining's crps: 0.0097313\tvalid_1's crps: 0.0126144\n",
      "Early stopping, best iteration is:\n",
      "[901]\ttraining's crps: 0.00973068\tvalid_1's crps: 0.0126144\n",
      "Training until validation scores don't improve for 7 rounds\n",
      "[100]\ttraining's crps: 0.0127523\tvalid_1's crps: 0.013145\n",
      "[200]\ttraining's crps: 0.011637\tvalid_1's crps: 0.0128553\n",
      "[300]\ttraining's crps: 0.0109508\tvalid_1's crps: 0.0127376\n",
      "[400]\ttraining's crps: 0.0105153\tvalid_1's crps: 0.0126823\n",
      "[500]\ttraining's crps: 0.0102213\tvalid_1's crps: 0.0126501\n",
      "[600]\ttraining's crps: 0.00999568\tvalid_1's crps: 0.0126286\n",
      "[700]\ttraining's crps: 0.00981494\tvalid_1's crps: 0.0126145\n",
      "[800]\ttraining's crps: 0.00969229\tvalid_1's crps: 0.0126055\n",
      "[900]\ttraining's crps: 0.00961828\tvalid_1's crps: 0.0125993\n",
      "[1000]\ttraining's crps: 0.00958384\tvalid_1's crps: 0.0125952\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's crps: 0.00958384\tvalid_1's crps: 0.0125952\n",
      "Training until validation scores don't improve for 7 rounds\n",
      "[100]\ttraining's crps: 0.012629\tvalid_1's crps: 0.0136103\n",
      "[200]\ttraining's crps: 0.0114988\tvalid_1's crps: 0.0133155\n",
      "[300]\ttraining's crps: 0.0108338\tvalid_1's crps: 0.0131919\n",
      "[400]\ttraining's crps: 0.0104023\tvalid_1's crps: 0.0131302\n",
      "[500]\ttraining's crps: 0.0101049\tvalid_1's crps: 0.0130954\n",
      "[600]\ttraining's crps: 0.00988229\tvalid_1's crps: 0.013074\n",
      "[700]\ttraining's crps: 0.00972164\tvalid_1's crps: 0.0130595\n",
      "[800]\ttraining's crps: 0.00960158\tvalid_1's crps: 0.0130513\n",
      "Early stopping, best iteration is:\n",
      "[850]\ttraining's crps: 0.00955961\tvalid_1's crps: 0.0130483\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "        tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "        vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "        dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "        dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "        model = lgb.train(params, dtrain,\n",
    "                              num_boost_round=100000,\n",
    "                              valid_sets=[dtrain,dvalid],\n",
    "                              early_stopping_rounds=7,\n",
    "                              verbose_eval=100,\n",
    "                              feval=crps_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012891320000000001\n",
      "0.01277846\n",
      "0.01278668\n",
      "0.012749759999999999\n"
     ]
    }
   ],
   "source": [
    "#CV score\n",
    "# for leave out one feature importance compare\n",
    "print(np.mean([0.0129045,0.0128677,0.0127771,0.0127333,0.013174]))\n",
    "\n",
    "# 5 closest defense palyer drop 'New_Y','back_oriented_down_field',max\n",
    "print(np.mean([0.0128208, 0.0127364, 0.0126515, 0.0126222,0.0130614]))\n",
    "\n",
    "# all defense palyer\n",
    "print(np.mean([0.012802,0.0127486,0.0126934,0.0126226,0.0130668]))\n",
    "\n",
    "# 5 closest defender + 2 closest offender l1,l2 = 1.2\n",
    "print(np.mean([0.0127868,0.0127041,0.0126144,0.0125952,0.0130483]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "params_dic = {'max_depth':[5], 'lambda_l1': [0.8,1,1.2], 'lambda_l2': [0.8,1,1.2],\n",
    " 'num_leaves': [32], 'feature_fraction': [0.4,0.45],\n",
    " 'subsample': [0.45], 'min_child_samples': [15],\n",
    " 'learning_rate': [0.02],\n",
    " 'num_iterations': [1000], 'random_state': [42],\n",
    " 'objective': ['multiclass'],\n",
    " 'min_gain_to_split':[1,1.2,1.4],\n",
    " 'num_class':[199],\n",
    " 'metric':['None']}\n",
    "\n",
    "for params in list(ParameterGrid(params_dic)):\n",
    "    kfold = KFold(5, random_state = 42, shuffle = True)\n",
    "    print(params)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "        tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "        vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "        dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "        dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "        model = lgb.train(params, dtrain,\n",
    "                              num_boost_round=100000,\n",
    "                              valid_sets=[dtrain,dvalid],\n",
    "                              early_stopping_rounds=7,\n",
    "                              verbose_eval=1000,\n",
    "                              feval=crps_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[741]\ttraining's crps: 0.0114998\tvalid_1's crps: 0.0128315\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[761]\ttraining's crps: 0.0115215\tvalid_1's crps: 0.0127737\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttraining's crps: 0.0115573\tvalid_1's crps: 0.0127044\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-dcb42932161c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m                                 \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                 \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                                 feval=crps_eval)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_train\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   2104\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2105\u001b[0m         \"\"\"\n\u001b[1;32m-> 2106\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   2607\u001b[0m                 \u001b[0mcur_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2608\u001b[0m             \u001b[0mfeval_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2609\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2610\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2611\u001b[0m                     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_higher_better\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#add one feature out test for game features\n",
    "#[0.0128264, 0.0127599, 0.0126589, 0.0126459,0.0130807]\n",
    "import lightgbm as lgb\n",
    "train_y =train.loc[train['IsRusher'],['Yards','PlayId']].sort_values('PlayId').drop('PlayId',axis = 1)\n",
    "train_y99 =(train_y + 99).reset_index(drop=True).Yards\n",
    "offender_players = [offender.iloc[np.arange(k, len(offender), 1)].reset_index(drop = True) for k in range(1)]\n",
    "offender_players = np.hstack([t.values for t in offender_players])\n",
    "train_x = np.hstack([rusher.drop('PlayId',axis = 1).values,offender_players])\n",
    "\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "        tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "        vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "        dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "        dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "        model = lgb.train(params, dtrain,\n",
    "                                num_boost_round=100000,\n",
    "                                valid_sets=[dtrain,dvalid],\n",
    "                                early_stopping_rounds=5,\n",
    "                                verbose_eval=1000,\n",
    "                                feval=crps_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.012911,0.0128706,0.012782,0.0127382,0.0131847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171,)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[0.0128264, 0.0127599, 0.0126589, 0.0126459,0.0130807]\n",
    "#drop new y, orientation_std(maybe),Dir(maybe),back_oriented_down_field(maybe),Vertical Speed(maybe),S(maybe),Dis(maybe),\n",
    "#Position(maybe),0(maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0128798"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rusher only  0.0129224 0.0128887, 0.0127877, 0.0127507, 0.01318\n",
    "np.mean([0.0129342,0.0128689,0.0127562,0.0126962,0.0131435])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's mape: 0.0328486\tvalid_1's mape: 0.0326991\n",
      "[20]\ttraining's mape: 0.0322112\tvalid_1's mape: 0.0321865\n",
      "[30]\ttraining's mape: 0.0316222\tvalid_1's mape: 0.0316953\n",
      "[40]\ttraining's mape: 0.0313034\tvalid_1's mape: 0.0314854\n",
      "[50]\ttraining's mape: 0.0309792\tvalid_1's mape: 0.0312592\n",
      "[60]\ttraining's mape: 0.0307363\tvalid_1's mape: 0.0311146\n",
      "[70]\ttraining's mape: 0.0304999\tvalid_1's mape: 0.0309864\n",
      "[80]\ttraining's mape: 0.0303047\tvalid_1's mape: 0.0309035\n",
      "[90]\ttraining's mape: 0.0301353\tvalid_1's mape: 0.0308187\n",
      "[100]\ttraining's mape: 0.0299895\tvalid_1's mape: 0.0307476\n",
      "[110]\ttraining's mape: 0.0298492\tvalid_1's mape: 0.0306947\n",
      "[120]\ttraining's mape: 0.0297274\tvalid_1's mape: 0.0306554\n",
      "[130]\ttraining's mape: 0.0296239\tvalid_1's mape: 0.0306352\n",
      "[140]\ttraining's mape: 0.0295154\tvalid_1's mape: 0.0306009\n",
      "[150]\ttraining's mape: 0.0294099\tvalid_1's mape: 0.0305521\n",
      "[160]\ttraining's mape: 0.0293131\tvalid_1's mape: 0.0305211\n",
      "[170]\ttraining's mape: 0.0292312\tvalid_1's mape: 0.0304916\n",
      "[180]\ttraining's mape: 0.0291518\tvalid_1's mape: 0.0304656\n",
      "[190]\ttraining's mape: 0.0290724\tvalid_1's mape: 0.0304547\n",
      "[200]\ttraining's mape: 0.028983\tvalid_1's mape: 0.0304268\n",
      "[210]\ttraining's mape: 0.0289149\tvalid_1's mape: 0.0304126\n",
      "[220]\ttraining's mape: 0.0288462\tvalid_1's mape: 0.0304008\n",
      "[230]\ttraining's mape: 0.0287791\tvalid_1's mape: 0.0303849\n",
      "[240]\ttraining's mape: 0.0287173\tvalid_1's mape: 0.0303705\n",
      "[250]\ttraining's mape: 0.0286522\tvalid_1's mape: 0.0303573\n",
      "[260]\ttraining's mape: 0.028595\tvalid_1's mape: 0.0303507\n",
      "[270]\ttraining's mape: 0.0285413\tvalid_1's mape: 0.0303433\n",
      "[280]\ttraining's mape: 0.0284919\tvalid_1's mape: 0.030332\n",
      "[290]\ttraining's mape: 0.0284393\tvalid_1's mape: 0.0303207\n",
      "[300]\ttraining's mape: 0.0283967\tvalid_1's mape: 0.0303174\n",
      "[310]\ttraining's mape: 0.0283517\tvalid_1's mape: 0.0303105\n",
      "[320]\ttraining's mape: 0.0283095\tvalid_1's mape: 0.030304\n",
      "[330]\ttraining's mape: 0.0282604\tvalid_1's mape: 0.0302973\n",
      "[340]\ttraining's mape: 0.0282149\tvalid_1's mape: 0.0302984\n",
      "[350]\ttraining's mape: 0.0281797\tvalid_1's mape: 0.0302921\n",
      "[360]\ttraining's mape: 0.0281402\tvalid_1's mape: 0.0302908\n",
      "[370]\ttraining's mape: 0.0281056\tvalid_1's mape: 0.0302813\n",
      "[380]\ttraining's mape: 0.0280715\tvalid_1's mape: 0.0302751\n",
      "[390]\ttraining's mape: 0.0280311\tvalid_1's mape: 0.0302744\n",
      "[400]\ttraining's mape: 0.0279857\tvalid_1's mape: 0.0302662\n",
      "[410]\ttraining's mape: 0.0279445\tvalid_1's mape: 0.0302529\n",
      "[420]\ttraining's mape: 0.0279085\tvalid_1's mape: 0.0302505\n",
      "[430]\ttraining's mape: 0.0278823\tvalid_1's mape: 0.0302489\n",
      "[440]\ttraining's mape: 0.0278456\tvalid_1's mape: 0.0302408\n",
      "[450]\ttraining's mape: 0.0278174\tvalid_1's mape: 0.0302392\n",
      "[460]\ttraining's mape: 0.0277901\tvalid_1's mape: 0.0302323\n",
      "[470]\ttraining's mape: 0.0277584\tvalid_1's mape: 0.030228\n",
      "[480]\ttraining's mape: 0.0277214\tvalid_1's mape: 0.0302197\n",
      "[490]\ttraining's mape: 0.0276872\tvalid_1's mape: 0.0302142\n",
      "[500]\ttraining's mape: 0.0276556\tvalid_1's mape: 0.0302079\n",
      "[510]\ttraining's mape: 0.0276246\tvalid_1's mape: 0.030202\n",
      "[520]\ttraining's mape: 0.027592\tvalid_1's mape: 0.0301975\n",
      "[530]\ttraining's mape: 0.0275687\tvalid_1's mape: 0.0301964\n",
      "[540]\ttraining's mape: 0.027549\tvalid_1's mape: 0.0301958\n",
      "[550]\ttraining's mape: 0.0275191\tvalid_1's mape: 0.0301916\n",
      "[560]\ttraining's mape: 0.0275019\tvalid_1's mape: 0.0301909\n",
      "[570]\ttraining's mape: 0.0274908\tvalid_1's mape: 0.0301881\n",
      "[580]\ttraining's mape: 0.0274642\tvalid_1's mape: 0.0301894\n",
      "[590]\ttraining's mape: 0.0274346\tvalid_1's mape: 0.0301815\n",
      "[600]\ttraining's mape: 0.0274111\tvalid_1's mape: 0.030182\n",
      "[10]\ttraining's mape: 0.0327585\tvalid_1's mape: 0.0330486\n",
      "[20]\ttraining's mape: 0.032104\tvalid_1's mape: 0.0325269\n",
      "[30]\ttraining's mape: 0.0314806\tvalid_1's mape: 0.0320773\n",
      "[40]\ttraining's mape: 0.0311556\tvalid_1's mape: 0.0318579\n",
      "[50]\ttraining's mape: 0.0308252\tvalid_1's mape: 0.0316532\n",
      "[60]\ttraining's mape: 0.0305824\tvalid_1's mape: 0.0315078\n",
      "[70]\ttraining's mape: 0.0303484\tvalid_1's mape: 0.0313881\n",
      "[80]\ttraining's mape: 0.0301652\tvalid_1's mape: 0.0313057\n",
      "[90]\ttraining's mape: 0.0299965\tvalid_1's mape: 0.0312371\n",
      "[100]\ttraining's mape: 0.0298429\tvalid_1's mape: 0.0311637\n",
      "[110]\ttraining's mape: 0.0297048\tvalid_1's mape: 0.0311086\n",
      "[120]\ttraining's mape: 0.029576\tvalid_1's mape: 0.0310783\n",
      "[130]\ttraining's mape: 0.0294695\tvalid_1's mape: 0.0310651\n",
      "[140]\ttraining's mape: 0.0293626\tvalid_1's mape: 0.0310321\n",
      "[150]\ttraining's mape: 0.0292559\tvalid_1's mape: 0.0310065\n",
      "[160]\ttraining's mape: 0.0291595\tvalid_1's mape: 0.0309892\n",
      "[170]\ttraining's mape: 0.0290712\tvalid_1's mape: 0.0309602\n",
      "[180]\ttraining's mape: 0.0289849\tvalid_1's mape: 0.0309419\n",
      "[190]\ttraining's mape: 0.0288937\tvalid_1's mape: 0.0309287\n",
      "[200]\ttraining's mape: 0.0288135\tvalid_1's mape: 0.0309185\n",
      "[210]\ttraining's mape: 0.0287371\tvalid_1's mape: 0.030911\n",
      "[220]\ttraining's mape: 0.0286687\tvalid_1's mape: 0.0308988\n",
      "[230]\ttraining's mape: 0.028599\tvalid_1's mape: 0.0308877\n",
      "[240]\ttraining's mape: 0.0285303\tvalid_1's mape: 0.0308766\n",
      "[250]\ttraining's mape: 0.0284691\tvalid_1's mape: 0.0308721\n",
      "[260]\ttraining's mape: 0.0284061\tvalid_1's mape: 0.030862\n",
      "[270]\ttraining's mape: 0.0283487\tvalid_1's mape: 0.0308633\n",
      "[280]\ttraining's mape: 0.028291\tvalid_1's mape: 0.0308532\n",
      "[290]\ttraining's mape: 0.0282393\tvalid_1's mape: 0.030849\n",
      "[300]\ttraining's mape: 0.0281948\tvalid_1's mape: 0.0308446\n",
      "[310]\ttraining's mape: 0.0281528\tvalid_1's mape: 0.0308383\n",
      "[320]\ttraining's mape: 0.0281047\tvalid_1's mape: 0.0308293\n",
      "[330]\ttraining's mape: 0.0280664\tvalid_1's mape: 0.0308222\n",
      "[340]\ttraining's mape: 0.028027\tvalid_1's mape: 0.0308207\n",
      "[350]\ttraining's mape: 0.027991\tvalid_1's mape: 0.0308194\n",
      "[360]\ttraining's mape: 0.0279498\tvalid_1's mape: 0.0308151\n",
      "[370]\ttraining's mape: 0.0279101\tvalid_1's mape: 0.0308133\n",
      "[380]\ttraining's mape: 0.0278764\tvalid_1's mape: 0.0308068\n",
      "[390]\ttraining's mape: 0.0278371\tvalid_1's mape: 0.0308043\n",
      "[400]\ttraining's mape: 0.0278034\tvalid_1's mape: 0.0307995\n",
      "[410]\ttraining's mape: 0.0277652\tvalid_1's mape: 0.0307945\n",
      "[420]\ttraining's mape: 0.0277154\tvalid_1's mape: 0.0307851\n",
      "[430]\ttraining's mape: 0.027679\tvalid_1's mape: 0.0307873\n",
      "[440]\ttraining's mape: 0.0276486\tvalid_1's mape: 0.0307842\n",
      "[450]\ttraining's mape: 0.0276245\tvalid_1's mape: 0.0307815\n",
      "[460]\ttraining's mape: 0.0275896\tvalid_1's mape: 0.0307815\n",
      "[470]\ttraining's mape: 0.0275493\tvalid_1's mape: 0.0307745\n",
      "[480]\ttraining's mape: 0.0275183\tvalid_1's mape: 0.0307672\n",
      "[490]\ttraining's mape: 0.0274831\tvalid_1's mape: 0.0307657\n",
      "[500]\ttraining's mape: 0.027456\tvalid_1's mape: 0.0307659\n",
      "[510]\ttraining's mape: 0.0274264\tvalid_1's mape: 0.0307693\n",
      "[520]\ttraining's mape: 0.0274022\tvalid_1's mape: 0.0307622\n",
      "[530]\ttraining's mape: 0.0273753\tvalid_1's mape: 0.0307588\n",
      "[540]\ttraining's mape: 0.0273507\tvalid_1's mape: 0.0307559\n",
      "[550]\ttraining's mape: 0.0273238\tvalid_1's mape: 0.0307526\n",
      "[560]\ttraining's mape: 0.0272961\tvalid_1's mape: 0.0307506\n",
      "[570]\ttraining's mape: 0.0272687\tvalid_1's mape: 0.0307475\n",
      "[580]\ttraining's mape: 0.0272379\tvalid_1's mape: 0.0307447\n",
      "[590]\ttraining's mape: 0.0272185\tvalid_1's mape: 0.0307417\n",
      "[600]\ttraining's mape: 0.0271978\tvalid_1's mape: 0.0307405\n",
      "[10]\ttraining's mape: 0.0328767\tvalid_1's mape: 0.0326718\n",
      "[20]\ttraining's mape: 0.0321983\tvalid_1's mape: 0.0321656\n",
      "[30]\ttraining's mape: 0.0316017\tvalid_1's mape: 0.0316803\n",
      "[40]\ttraining's mape: 0.0312843\tvalid_1's mape: 0.0314898\n",
      "[50]\ttraining's mape: 0.0309731\tvalid_1's mape: 0.0312901\n",
      "[60]\ttraining's mape: 0.0307106\tvalid_1's mape: 0.0311551\n",
      "[70]\ttraining's mape: 0.0304644\tvalid_1's mape: 0.0310224\n",
      "[80]\ttraining's mape: 0.0302653\tvalid_1's mape: 0.0309218\n",
      "[90]\ttraining's mape: 0.0300996\tvalid_1's mape: 0.0308382\n",
      "[100]\ttraining's mape: 0.0299433\tvalid_1's mape: 0.0307643\n",
      "[110]\ttraining's mape: 0.0298057\tvalid_1's mape: 0.030717\n",
      "[120]\ttraining's mape: 0.0296932\tvalid_1's mape: 0.0306907\n",
      "[130]\ttraining's mape: 0.0295904\tvalid_1's mape: 0.0306656\n",
      "[140]\ttraining's mape: 0.0294972\tvalid_1's mape: 0.0306359\n",
      "[150]\ttraining's mape: 0.0293913\tvalid_1's mape: 0.0306122\n",
      "[160]\ttraining's mape: 0.029303\tvalid_1's mape: 0.0305953\n",
      "[170]\ttraining's mape: 0.029216\tvalid_1's mape: 0.0305718\n",
      "[180]\ttraining's mape: 0.0291302\tvalid_1's mape: 0.0305537\n",
      "[190]\ttraining's mape: 0.0290466\tvalid_1's mape: 0.0305401\n",
      "[200]\ttraining's mape: 0.0289745\tvalid_1's mape: 0.0305268\n",
      "[210]\ttraining's mape: 0.028901\tvalid_1's mape: 0.0305082\n",
      "[220]\ttraining's mape: 0.0288383\tvalid_1's mape: 0.0304982\n",
      "[230]\ttraining's mape: 0.0287689\tvalid_1's mape: 0.0304893\n",
      "[240]\ttraining's mape: 0.0287117\tvalid_1's mape: 0.0304799\n",
      "[250]\ttraining's mape: 0.0286542\tvalid_1's mape: 0.0304695\n",
      "[260]\ttraining's mape: 0.0285891\tvalid_1's mape: 0.030462\n",
      "[270]\ttraining's mape: 0.0285343\tvalid_1's mape: 0.0304557\n",
      "[280]\ttraining's mape: 0.0284826\tvalid_1's mape: 0.0304513\n",
      "[290]\ttraining's mape: 0.0284358\tvalid_1's mape: 0.0304468\n",
      "[300]\ttraining's mape: 0.0283821\tvalid_1's mape: 0.030445\n",
      "[310]\ttraining's mape: 0.0283241\tvalid_1's mape: 0.0304388\n",
      "[320]\ttraining's mape: 0.0282671\tvalid_1's mape: 0.0304319\n",
      "[330]\ttraining's mape: 0.0282258\tvalid_1's mape: 0.0304256\n",
      "[340]\ttraining's mape: 0.0281894\tvalid_1's mape: 0.0304164\n",
      "[350]\ttraining's mape: 0.0281489\tvalid_1's mape: 0.0304113\n",
      "[360]\ttraining's mape: 0.0280977\tvalid_1's mape: 0.0304097\n",
      "[370]\ttraining's mape: 0.0280435\tvalid_1's mape: 0.0304067\n",
      "[380]\ttraining's mape: 0.0279978\tvalid_1's mape: 0.0303996\n",
      "[390]\ttraining's mape: 0.0279534\tvalid_1's mape: 0.0304003\n",
      "[400]\ttraining's mape: 0.0279059\tvalid_1's mape: 0.030397\n",
      "[410]\ttraining's mape: 0.0278688\tvalid_1's mape: 0.0303919\n",
      "[420]\ttraining's mape: 0.027832\tvalid_1's mape: 0.030386\n",
      "[430]\ttraining's mape: 0.0278021\tvalid_1's mape: 0.0303851\n",
      "[440]\ttraining's mape: 0.0277769\tvalid_1's mape: 0.0303832\n",
      "[450]\ttraining's mape: 0.0277487\tvalid_1's mape: 0.0303791\n",
      "[460]\ttraining's mape: 0.0277242\tvalid_1's mape: 0.0303765\n",
      "[470]\ttraining's mape: 0.0276965\tvalid_1's mape: 0.0303772\n",
      "[480]\ttraining's mape: 0.0276679\tvalid_1's mape: 0.0303758\n",
      "[490]\ttraining's mape: 0.0276291\tvalid_1's mape: 0.0303707\n",
      "[500]\ttraining's mape: 0.0275892\tvalid_1's mape: 0.0303717\n",
      "[510]\ttraining's mape: 0.027557\tvalid_1's mape: 0.0303674\n",
      "[520]\ttraining's mape: 0.0275281\tvalid_1's mape: 0.0303611\n",
      "[530]\ttraining's mape: 0.0274964\tvalid_1's mape: 0.0303645\n",
      "[540]\ttraining's mape: 0.0274767\tvalid_1's mape: 0.0303655\n",
      "[550]\ttraining's mape: 0.0274496\tvalid_1's mape: 0.0303658\n",
      "[560]\ttraining's mape: 0.0274189\tvalid_1's mape: 0.0303665\n",
      "[570]\ttraining's mape: 0.0273958\tvalid_1's mape: 0.0303671\n",
      "[580]\ttraining's mape: 0.0273738\tvalid_1's mape: 0.0303647\n",
      "[590]\ttraining's mape: 0.0273447\tvalid_1's mape: 0.0303582\n",
      "[600]\ttraining's mape: 0.0273143\tvalid_1's mape: 0.0303549\n",
      "[10]\ttraining's mape: 0.0328544\tvalid_1's mape: 0.0327235\n",
      "[20]\ttraining's mape: 0.0322015\tvalid_1's mape: 0.032209\n",
      "[30]\ttraining's mape: 0.0315992\tvalid_1's mape: 0.0317591\n",
      "[40]\ttraining's mape: 0.0313015\tvalid_1's mape: 0.0315908\n",
      "[50]\ttraining's mape: 0.0309842\tvalid_1's mape: 0.0313717\n",
      "[60]\ttraining's mape: 0.0307365\tvalid_1's mape: 0.0312468\n",
      "[70]\ttraining's mape: 0.0304983\tvalid_1's mape: 0.0311134\n",
      "[80]\ttraining's mape: 0.0303105\tvalid_1's mape: 0.0310212\n",
      "[90]\ttraining's mape: 0.030142\tvalid_1's mape: 0.030942\n",
      "[100]\ttraining's mape: 0.0299746\tvalid_1's mape: 0.0308639\n",
      "[110]\ttraining's mape: 0.0298294\tvalid_1's mape: 0.0308038\n",
      "[120]\ttraining's mape: 0.029706\tvalid_1's mape: 0.0307604\n",
      "[130]\ttraining's mape: 0.0296027\tvalid_1's mape: 0.0307165\n",
      "[140]\ttraining's mape: 0.0294969\tvalid_1's mape: 0.0306761\n",
      "[150]\ttraining's mape: 0.0293887\tvalid_1's mape: 0.0306585\n",
      "[160]\ttraining's mape: 0.0292982\tvalid_1's mape: 0.0306409\n",
      "[170]\ttraining's mape: 0.0292112\tvalid_1's mape: 0.0306276\n",
      "[180]\ttraining's mape: 0.0291213\tvalid_1's mape: 0.0306105\n",
      "[190]\ttraining's mape: 0.0290374\tvalid_1's mape: 0.0305929\n",
      "[200]\ttraining's mape: 0.0289693\tvalid_1's mape: 0.0305765\n",
      "[210]\ttraining's mape: 0.0289025\tvalid_1's mape: 0.0305707\n",
      "[220]\ttraining's mape: 0.028837\tvalid_1's mape: 0.0305504\n",
      "[230]\ttraining's mape: 0.0287697\tvalid_1's mape: 0.0305506\n",
      "[240]\ttraining's mape: 0.0287078\tvalid_1's mape: 0.030543\n",
      "[250]\ttraining's mape: 0.0286519\tvalid_1's mape: 0.0305303\n",
      "[260]\ttraining's mape: 0.0285934\tvalid_1's mape: 0.0305253\n",
      "[270]\ttraining's mape: 0.0285454\tvalid_1's mape: 0.0305248\n",
      "[280]\ttraining's mape: 0.0284853\tvalid_1's mape: 0.0305163\n",
      "[290]\ttraining's mape: 0.0284267\tvalid_1's mape: 0.0305087\n",
      "[300]\ttraining's mape: 0.0283776\tvalid_1's mape: 0.0304993\n",
      "[310]\ttraining's mape: 0.028328\tvalid_1's mape: 0.030495\n",
      "[320]\ttraining's mape: 0.028268\tvalid_1's mape: 0.0304911\n",
      "[330]\ttraining's mape: 0.0282146\tvalid_1's mape: 0.0304842\n",
      "[340]\ttraining's mape: 0.0281646\tvalid_1's mape: 0.0304798\n",
      "[350]\ttraining's mape: 0.0281179\tvalid_1's mape: 0.0304774\n",
      "[360]\ttraining's mape: 0.0280774\tvalid_1's mape: 0.0304707\n",
      "[370]\ttraining's mape: 0.0280321\tvalid_1's mape: 0.0304658\n",
      "[380]\ttraining's mape: 0.0279943\tvalid_1's mape: 0.0304592\n",
      "[390]\ttraining's mape: 0.0279633\tvalid_1's mape: 0.0304545\n",
      "[400]\ttraining's mape: 0.027934\tvalid_1's mape: 0.0304502\n",
      "[410]\ttraining's mape: 0.0279015\tvalid_1's mape: 0.0304469\n",
      "[420]\ttraining's mape: 0.027876\tvalid_1's mape: 0.0304409\n",
      "[430]\ttraining's mape: 0.0278421\tvalid_1's mape: 0.0304386\n",
      "[440]\ttraining's mape: 0.0278075\tvalid_1's mape: 0.0304341\n",
      "[450]\ttraining's mape: 0.0277678\tvalid_1's mape: 0.0304262\n",
      "[460]\ttraining's mape: 0.0277304\tvalid_1's mape: 0.0304238\n",
      "[470]\ttraining's mape: 0.0276963\tvalid_1's mape: 0.0304197\n",
      "[480]\ttraining's mape: 0.0276638\tvalid_1's mape: 0.0304156\n",
      "[490]\ttraining's mape: 0.0276339\tvalid_1's mape: 0.0304164\n",
      "[500]\ttraining's mape: 0.0276055\tvalid_1's mape: 0.0304147\n",
      "[510]\ttraining's mape: 0.0275775\tvalid_1's mape: 0.0304121\n",
      "[520]\ttraining's mape: 0.0275463\tvalid_1's mape: 0.0304101\n",
      "[530]\ttraining's mape: 0.0275273\tvalid_1's mape: 0.0304071\n",
      "[540]\ttraining's mape: 0.0275113\tvalid_1's mape: 0.0304055\n",
      "[550]\ttraining's mape: 0.0274791\tvalid_1's mape: 0.0304007\n",
      "[560]\ttraining's mape: 0.0274505\tvalid_1's mape: 0.0303984\n",
      "[570]\ttraining's mape: 0.0274295\tvalid_1's mape: 0.030395\n",
      "[580]\ttraining's mape: 0.0274053\tvalid_1's mape: 0.0303942\n",
      "[590]\ttraining's mape: 0.0273869\tvalid_1's mape: 0.0303938\n",
      "[600]\ttraining's mape: 0.0273663\tvalid_1's mape: 0.0303917\n",
      "[10]\ttraining's mape: 0.0326421\tvalid_1's mape: 0.033535\n",
      "[20]\ttraining's mape: 0.0320168\tvalid_1's mape: 0.0329866\n",
      "[30]\ttraining's mape: 0.0314322\tvalid_1's mape: 0.0324567\n",
      "[40]\ttraining's mape: 0.0311207\tvalid_1's mape: 0.03222\n",
      "[50]\ttraining's mape: 0.030805\tvalid_1's mape: 0.0319604\n",
      "[60]\ttraining's mape: 0.0305374\tvalid_1's mape: 0.0317901\n",
      "[70]\ttraining's mape: 0.0302953\tvalid_1's mape: 0.0316459\n",
      "[80]\ttraining's mape: 0.0301074\tvalid_1's mape: 0.0315477\n",
      "[90]\ttraining's mape: 0.0299508\tvalid_1's mape: 0.0314731\n",
      "[100]\ttraining's mape: 0.0297972\tvalid_1's mape: 0.0313728\n",
      "[110]\ttraining's mape: 0.0296598\tvalid_1's mape: 0.0313095\n",
      "[120]\ttraining's mape: 0.0295408\tvalid_1's mape: 0.0312599\n",
      "[130]\ttraining's mape: 0.0294241\tvalid_1's mape: 0.0312194\n",
      "[140]\ttraining's mape: 0.0293203\tvalid_1's mape: 0.0311818\n",
      "[150]\ttraining's mape: 0.029214\tvalid_1's mape: 0.0311553\n",
      "[160]\ttraining's mape: 0.0291257\tvalid_1's mape: 0.0311258\n",
      "[170]\ttraining's mape: 0.0290454\tvalid_1's mape: 0.0311025\n",
      "[180]\ttraining's mape: 0.0289651\tvalid_1's mape: 0.0310725\n",
      "[190]\ttraining's mape: 0.0288874\tvalid_1's mape: 0.0310639\n",
      "[200]\ttraining's mape: 0.02881\tvalid_1's mape: 0.0310447\n",
      "[210]\ttraining's mape: 0.0287371\tvalid_1's mape: 0.031028\n",
      "[220]\ttraining's mape: 0.0286764\tvalid_1's mape: 0.0310097\n",
      "[230]\ttraining's mape: 0.0286179\tvalid_1's mape: 0.0310011\n",
      "[240]\ttraining's mape: 0.0285645\tvalid_1's mape: 0.0309919\n",
      "[250]\ttraining's mape: 0.0285113\tvalid_1's mape: 0.0309827\n",
      "[260]\ttraining's mape: 0.0284588\tvalid_1's mape: 0.0309735\n",
      "[270]\ttraining's mape: 0.0284015\tvalid_1's mape: 0.0309719\n",
      "[280]\ttraining's mape: 0.0283442\tvalid_1's mape: 0.030959\n",
      "[290]\ttraining's mape: 0.0282985\tvalid_1's mape: 0.0309536\n",
      "[300]\ttraining's mape: 0.0282379\tvalid_1's mape: 0.0309449\n",
      "[310]\ttraining's mape: 0.0281851\tvalid_1's mape: 0.0309379\n",
      "[320]\ttraining's mape: 0.0281308\tvalid_1's mape: 0.030925\n",
      "[330]\ttraining's mape: 0.028088\tvalid_1's mape: 0.030917\n",
      "[340]\ttraining's mape: 0.0280406\tvalid_1's mape: 0.0309028\n",
      "[350]\ttraining's mape: 0.0279887\tvalid_1's mape: 0.0308927\n",
      "[360]\ttraining's mape: 0.0279384\tvalid_1's mape: 0.0308839\n",
      "[370]\ttraining's mape: 0.0278923\tvalid_1's mape: 0.0308772\n",
      "[380]\ttraining's mape: 0.0278477\tvalid_1's mape: 0.0308684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[390]\ttraining's mape: 0.027807\tvalid_1's mape: 0.0308634\n",
      "[400]\ttraining's mape: 0.0277738\tvalid_1's mape: 0.030855\n",
      "[410]\ttraining's mape: 0.0277367\tvalid_1's mape: 0.0308502\n",
      "[420]\ttraining's mape: 0.0277042\tvalid_1's mape: 0.0308438\n",
      "[430]\ttraining's mape: 0.0276799\tvalid_1's mape: 0.0308383\n",
      "[440]\ttraining's mape: 0.0276571\tvalid_1's mape: 0.0308373\n",
      "[450]\ttraining's mape: 0.0276296\tvalid_1's mape: 0.0308302\n",
      "[460]\ttraining's mape: 0.0276099\tvalid_1's mape: 0.030827\n",
      "[470]\ttraining's mape: 0.0275784\tvalid_1's mape: 0.0308211\n",
      "[480]\ttraining's mape: 0.0275427\tvalid_1's mape: 0.0308151\n",
      "[490]\ttraining's mape: 0.0275099\tvalid_1's mape: 0.0308124\n",
      "[500]\ttraining's mape: 0.0274814\tvalid_1's mape: 0.0308074\n",
      "[510]\ttraining's mape: 0.0274509\tvalid_1's mape: 0.0307977\n",
      "[520]\ttraining's mape: 0.0274259\tvalid_1's mape: 0.0307935\n",
      "[530]\ttraining's mape: 0.0274059\tvalid_1's mape: 0.0307889\n",
      "[540]\ttraining's mape: 0.02738\tvalid_1's mape: 0.0307844\n",
      "[550]\ttraining's mape: 0.0273561\tvalid_1's mape: 0.0307808\n",
      "[560]\ttraining's mape: 0.02733\tvalid_1's mape: 0.030779\n",
      "[570]\ttraining's mape: 0.0273006\tvalid_1's mape: 0.0307726\n",
      "[580]\ttraining's mape: 0.0272829\tvalid_1's mape: 0.0307707\n",
      "[590]\ttraining's mape: 0.0272716\tvalid_1's mape: 0.0307704\n",
      "[600]\ttraining's mape: 0.0272607\tvalid_1's mape: 0.0307713\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth':5, 'lambda_l1': 1, 'lambda_l2': 1,\n",
    " 'num_leaves': 30, 'feature_fraction': 0.4,\n",
    " 'subsample': 0.4, 'min_child_samples': 20,\n",
    " 'learning_rate': 0.05,\n",
    " 'num_iterations': 600, 'random_state': 42,\n",
    " 'objective': 'mape'}\n",
    "\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "        tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "        vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "        dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "        dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "        model = lgb.train(params, dtrain,\n",
    "                              num_boost_round=100000,\n",
    "                              valid_sets=[dtrain,dvalid],\n",
    "                              verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "0.012558720296237821\n",
      "Fold : 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-309-fb8135b42577>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mX_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mscore_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrps1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "y = np.zeros((train_y.shape[0], 199))\n",
    "def crps1(y_true, y_pred):\n",
    "    y_true = np.clip(np.cumsum(y_true, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    return ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * y_true.shape[0]) \n",
    "for idx, target in enumerate(train_y.reset_index(drop=True).Yards):\n",
    "    y[idx][99 + target] = 1\n",
    "models = []\n",
    "kf = KFold(n_splits=5, random_state=42)\n",
    "score = []\n",
    "for i, (tdx, vdx) in enumerate(kf.split(X_train, y)):\n",
    "    print(f'Fold : {i}')\n",
    "    X_tra, X_val, y_tra, y_val = X_train[tdx], X_train[vdx], y[tdx], y[vdx]\n",
    "    model = RandomForestRegressor(bootstrap=False, max_features=0.5, min_samples_leaf=15, min_samples_split=7, n_estimators=100, n_jobs=-1, random_state=42)\n",
    "    model.fit(X_tra, y_tra)\n",
    "    score_ = crps1(y_val, model.predict(X_val))\n",
    "    print(score_)\n",
    "    score.append(score_)\n",
    "    models.append(model)\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
