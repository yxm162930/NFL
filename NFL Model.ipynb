{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import datetime, tqdm\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "pd.set_option('max_columns', 100)\n",
    "#from kaggle.competitions import nflrush\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense,Dropout, PReLU, BatchNormalization, ELU, GaussianNoise, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "import gc\n",
    "import os\n",
    "#note： \n",
    "#1. As a result it might not be worthwhile to use features related to game clock/quarter of the game。\n",
    "#2. There is no relationships between number of rushes before and running yards gained。\n",
    "#3. rushing success larger depends on defender in box, or defender that are close to offensive lineman and attempt \n",
    "#   to counter the blocking.\n",
    "#4. highly drafted player has the same average rushing yards as the rest\n",
    "#ARI: Arizona Cardinals\n",
    "#ATL: Atlanta Falcons\n",
    "#BAL: Baltimore Ravens\n",
    "#BUF: Buffalo Bills\n",
    "#CAR: Carolina Panthers\n",
    "#CHI: Chicago Bears\n",
    "#CIN: Cincinnati Bengals\n",
    "#CLE: Cleveland Browns\n",
    "#DAL: Dallas Cowboys\n",
    "#DEN: Denver Broncos\n",
    "#DET: Detroit Lions\n",
    "#GB: Green Bay Packers\n",
    "#HOU: Houston Texans\n",
    "#IND: Indianapolis Colts\n",
    "#JAX: Jacksonville Jaguars\n",
    "#KC: Kansas City Chiefs\n",
    "#MIA: Miami Dolphins\n",
    "#MIN: Minnesota Vikings\n",
    "#NE: New England Patriots\n",
    "#NO: New Orleans Saints\n",
    "#NYG: New York Giants\n",
    "#NYJ: New York Jets\n",
    "#OAK: Oakland Raiders\n",
    "#PHI: Philadelphia Eagles\n",
    "#PIT: Pittsburgh Steelers\n",
    "#SD: San Diego Chargers\n",
    "#SEA: Seattle Seahawks\n",
    "#SF: San Francisco 49ers\n",
    "#STL: Saint Louis Rams\n",
    "#TB: Tampa Bay Buccaneers\n",
    "#TEN Tennessee Titans\n",
    "#WAS: Washington Redskins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\38980\\OneDrive\\Desktop\\study\\kaggle\\NFL\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team abbreviations correct\n",
    "def data_clean(df):\n",
    "#correct name   \n",
    "    df.loc[df['PossessionTeam'] == 'ARZ', 'PossessionTeam'] = 'ARI'\n",
    "    df.loc[df['PossessionTeam'] == 'BLT', 'PossessionTeam'] = 'BAL'\n",
    "    df.loc[df['PossessionTeam'] == 'CLV', 'PossessionTeam'] = 'CLE'\n",
    "    df.loc[df['PossessionTeam'] == 'HST', 'PossessionTeam'] = 'HOU'\n",
    "    df.loc[df['FieldPosition'] == 'ARZ', 'FieldPosition'] = 'ARI'\n",
    "    df.loc[df['FieldPosition'] == 'BLT', 'FieldPosition'] = 'BAL'\n",
    "    df.loc[df['FieldPosition'] == 'CLV', 'FieldPosition'] = 'CLE'\n",
    "    df.loc[df['FieldPosition'] == 'HST', 'FieldPosition'] = 'HOU'\n",
    "\n",
    "# fill null\n",
    "    df = df.fillna(df.median())\n",
    "\n",
    "# offense time and defence time\n",
    "    df['TeamOnOffense'] = \"home\"\n",
    "    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    df['IsOnOffense'] = df.Team == df.TeamOnOffense # Is player on offense?\n",
    "    \n",
    "#time\n",
    "    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    seconds_in_year = 60*60*24*365.25\n",
    "    df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "    df['GameClock'] = df['GameClock'].apply(lambda x: float(x.split(\":\")[0]) + float(x.split(\":\")[1])/60)\n",
    "    df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "#player height\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "\n",
    "#weather\n",
    "    def map_weather(txt):\n",
    "        ans = 1\n",
    "        if pd.isna(txt):\n",
    "            return 0\n",
    "        if 'partly' in txt:\n",
    "            ans*=0.5\n",
    "        if 'climate controlled' in txt or 'indoor' in txt:\n",
    "            return ans*3\n",
    "        if 'sunny' in txt or 'sun' in txt:\n",
    "            return ans*2\n",
    "        if 'clear' in txt:\n",
    "            return ans\n",
    "        if 'cloudy' in txt:\n",
    "            return -ans\n",
    "        if 'rain' in txt or 'rainy' in txt:\n",
    "            return -2*ans\n",
    "        if 'snow' in txt:\n",
    "            return -3*ans\n",
    "        return 0\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['Cleaned_GameWeather'].apply(map_weather)\n",
    "\n",
    "#diff Score    \n",
    "    df[\"DiffScoreBeforePlay_ob\"] = (df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"])\n",
    "    df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]] = - df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]]\n",
    "#Turf\n",
    "    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n",
    "    df['Cleaned_Turf'] = df['Turf'].map(Turf)\n",
    "\n",
    "#left to right\n",
    "    df['New_X'] = df['X']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_X'] = 120 - df.loc[df['PlayDirection'] == 'left','X']\n",
    "    df['New_Y'] = df['Y']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_Y'] = 160/3 - df.loc[df['PlayDirection'] == 'left','Y']\n",
    "    df['Orientation_std'] = df['Orientation']\n",
    "    df.loc[df['Season'] == 2017, 'Orientation_std'] = df.loc[df['Season'] == 2017, 'Orientation_std'] + 90\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Orientation_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Orientation_std'], 360)\n",
    "    df['Dir_std'] = df['Dir']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Dir_std'], 360)\n",
    "    df['YardLine_std'] = 100 - df['YardLine']\n",
    "    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine_std'\n",
    "         ] = df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine']\n",
    "    df[\"Orientation_sin\"] = df[\"Orientation_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Orientation_cos\"] = df[\"Orientation_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_sin\"] = df[\"Dir_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_cos\"] = df[\"Dir_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "\n",
    "#distance\n",
    "    #distance to yardline\n",
    "    df['Dis_YardLine'] = df['New_X'] - df['YardLine_std'] - 10\n",
    "    #distance to rusher\n",
    "    def Distance(x1,x2,y1,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "    def Degree(x1,x2,y1,y2):\n",
    "        try:\n",
    "            tan = (y1-y2)/(x1-x2)\n",
    "        except:\n",
    "            tan = 0\n",
    "        degree = 90 - math.atan(tan)/(2*np.pi)*360\n",
    "        return degree\n",
    "    df['IsRusher'] = (df['NflId'] == df['NflIdRusher'])\n",
    "    Rusher =df.loc[df['IsRusher'],['PlayId','X','Y','Dir_std']].rename(columns={\"X\":\"Rusher_X\",\"Y\":\"Rusher_Y\",'PossessionTeam':'Offense_Team','Dir_std':'Rusher_Dir_std'})\n",
    "    df = df.merge(Rusher,how = 'left',on = 'PlayId')\n",
    "    df['Distance_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Distance(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Degree(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_Diff'] = abs(df['Degree_to_Rusher'] - df['Rusher_Dir_std'])\n",
    "    #back_direction\n",
    "    def back_direction(orientation):\n",
    "        if orientation > 180.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df['back_oriented_down_field'] = df['Orientation_std'].apply(lambda x: back_direction(x))\n",
    "\n",
    "# Stadium clean\n",
    "    map_stad = {'Broncos Stadium at Mile High': 'Broncos Stadium At Mile High', 'CenturyField': 'CenturyLink Field', 'CenturyLink': 'CenturyLink Field', 'Everbank Field': 'EverBank Field', 'FirstEnergy': 'First Energy Stadium', 'FirstEnergy Stadium': 'First Energy Stadium', 'FirstEnergyStadium': 'First Energy Stadium', 'Lambeau field': 'Lambeau Field', 'Los Angeles Memorial Coliesum': 'Los Angeles Memorial Coliseum', 'M & T Bank Stadium': 'M&T Bank Stadium', 'M&T Stadium': 'M&T Bank Stadium', 'Mercedes-Benz Dome': 'Mercedes-Benz Superdome', 'MetLife': 'MetLife Stadium', 'Metlife Stadium': 'MetLife Stadium', 'NRG': 'NRG Stadium', 'Oakland Alameda-County Coliseum': 'Oakland-Alameda County Coliseum', 'Paul Brown Stdium': 'Paul Brown Stadium', 'Twickenham': 'Twickenham Stadium'}\n",
    "    \n",
    "    for stad in df['Stadium'].unique():\n",
    "        if stad in map_stad.keys():\n",
    "            pass\n",
    "        else:\n",
    "            map_stad[stad]=stad\n",
    "\n",
    "    df['Stadium'] = df['Stadium'].map(map_stad)\n",
    "\n",
    "# wind \n",
    "    def give_me_WindSpeed(x):\n",
    "            x = str(x)\n",
    "            x = x.replace('mph', '').strip()\n",
    "            if '-' in x:\n",
    "                x = (int(x.split('-')[0]) + int(x.split('-')[1])) / 2\n",
    "            elif 'gusts up to' in x:\n",
    "                x = (int(x.split()[0]) + int(x.split()[-1])) / 2\n",
    "            elif 'clam' in x:\n",
    "                x = 0\n",
    "            try:\n",
    "                return float(x)\n",
    "            except:\n",
    "                return -99\n",
    "    df['Cleaned_WindSpeed'] = df['WindSpeed'].apply(give_me_WindSpeed)\n",
    "\n",
    "    \n",
    "# speed\n",
    "    df['Horizontal Speed'] = df['S']*df[\"Dir_sin\"]\n",
    "    df['Vertical Speed'] = df['S']*df[\"Dir_cos\"]\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "train = data_clean(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    df1 = df.loc[df['IsRusher']]\n",
    "    df2 = df.loc[df['IsOnOffense'] & (~df['IsRusher'])]\n",
    "    df3 = df.loc[~df['IsOnOffense']]\n",
    "\n",
    "# handoff times\n",
    "    df1 = df1.sort_values(['GameId','PlayId','Quarter','GameClock'])\n",
    "    df1['# of Handoff Play'] = 1\n",
    "    df1['# of Handoff Play'] = df1[['GameId','PlayId','# of Handoff Play']].groupby(['GameId','PlayId']).cumsum()\n",
    "# min_time_to_tacke\n",
    "    df3['Min_Time_Tacke'] = df3['Distance_to_Rusher']/df3['S']\n",
    "    df3.loc[df3['Min_Time_Tacke'] == np.inf, 'Min_Time_Tacke'] = 20\n",
    "# defence_X_Y_spread\n",
    "    Defence_X_Y_std = df3[[\"PlayId\",'New_X','New_Y']].groupby(\"PlayId\").std().rename(columns={'New_X':'Defense_X_std','New_Y':'Defense_Y_std'}) \\\n",
    "    .reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed2_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(1).index, df3.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed2_std'}).reset_index()\n",
    "\n",
    "    df3 = df3.sort_values(['PlayId','New_Y'])\n",
    "    Defense_Y_Removed2_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(1).index, df3.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed4_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(2).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed4_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_Y'])\n",
    "    Defense_Y_Removed4_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(2).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Defence_X_Y_std, how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "\n",
    "# offense_X_Y_spread\n",
    "    df2 = df2.sort_values(['PlayId','New_X'])\n",
    "    Offense_X_Removed2_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed2_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed2_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_X_Removed4_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed4_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed4_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Offense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    \n",
    "# nearest offenders to defender\n",
    "    dis_to_closest_offender = pd.DataFrame()\n",
    "    for playid in df3['PlayId'].unique():\n",
    "        offense = df2.loc[df2['PlayId'] == playid]\n",
    "        defence = df3.loc[df3['PlayId'] == playid]\n",
    "        ary = scipy.spatial.distance.cdist(defence[['New_X','New_Y']], offense[['New_X','New_Y']], metric='euclidean')\n",
    "        ary.sort(axis=1)\n",
    "        ary = pd.DataFrame(data = ary)\n",
    "        ary['PlayId'] = playid\n",
    "        ary.reset_index(drop=True, inplace=True)\n",
    "        ary = pd.concat([ary, defence[['NflId']].reset_index(drop=True)], axis=1)\n",
    "        dis_to_closest_offender = dis_to_closest_offender.append(ary)\n",
    "    df3 = df3.merge(dis_to_closest_offender,how = 'left',on = ['PlayId','NflId'])\n",
    "\n",
    "# personnel_features\n",
    "    def defense_formation(l):\n",
    "        dl = 0\n",
    "        lb = 0\n",
    "        db = 0\n",
    "        other = 0\n",
    "\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            if sub_string[1] == 'DL':\n",
    "                dl += int(sub_string[0])\n",
    "            elif sub_string[1] in ['LB','OL']:\n",
    "                lb += int(sub_string[0])\n",
    "            else:\n",
    "                db += int(sub_string[0])\n",
    "\n",
    "        counts = (dl,lb,db,other)\n",
    "\n",
    "        return counts\n",
    "    def offense_formation(l):\n",
    "        qb = 0\n",
    "        rb = 0\n",
    "        wr = 0\n",
    "        te = 0\n",
    "        ol = 0\n",
    "\n",
    "        sub_total = 0\n",
    "        qb_listed = False\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            pos = sub_string[1]\n",
    "            cnt = int(sub_string[0])\n",
    "\n",
    "            if pos == 'QB':\n",
    "                qb += cnt\n",
    "                sub_total += cnt\n",
    "                qb_listed = True\n",
    "            # Assuming LB is a line backer lined up as full back\n",
    "            elif pos in ['RB','LB']:\n",
    "                rb += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DB is a defensive back and lined up as WR\n",
    "            elif pos in ['WR','DB']:\n",
    "                wr += cnt\n",
    "                sub_total += cnt\n",
    "            elif pos == 'TE':\n",
    "                te += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DL is a defensive lineman lined up as an additional line man\n",
    "            else:\n",
    "                ol += cnt\n",
    "                sub_total += cnt\n",
    "\n",
    "        # If not all 11 players were noted at given positions we need to make some assumptions\n",
    "        # I will assume if a QB is not listed then there was 1 QB on the play\n",
    "        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n",
    "        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n",
    "        if sub_total < 11:\n",
    "            diff = 11 - sub_total\n",
    "            if not qb_listed:\n",
    "                qb += 1\n",
    "                diff -= 1\n",
    "            ol += diff\n",
    "\n",
    "        counts = (qb,rb,wr,te,ol)\n",
    "\n",
    "        return counts\n",
    "    def split_personnel(s):\n",
    "        splits = s.split(',')\n",
    "        for i in range(len(splits)):\n",
    "            splits[i] = splits[i].strip()\n",
    "\n",
    "        return splits    \n",
    "    def personnel_features(df):\n",
    "        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n",
    "        personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n",
    "\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n",
    "        personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n",
    "        personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n",
    "        personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n",
    "\n",
    "        # Let's create some features to specify if the OL is covered\n",
    "        personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n",
    "        personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n",
    "        # Let's create a feature to specify if the defense is preventing the run\n",
    "        # Let's just assume 7 or more DL and LB is run prevention\n",
    "        personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n",
    "\n",
    "        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n",
    "        \n",
    "        return personnel\n",
    "    \n",
    "    personnel = personnel_features(df1)   \n",
    "    df1 = df1.merge(personnel,how = 'left',  on ='PlayId')\n",
    "    \n",
    "#select useful columns    \n",
    "    rusher = df1[['PlayId','TimeDelta','Team','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y', \\\n",
    "                 'Orientation_std','Dir_std','Dis_YardLine','Horizontal Speed','Vertical Speed','S','A','Dis','Position',\\\n",
    "                 '# of Handoff Play','Quarter','GameClock','Down','Distance','OffenseFormation',\\\n",
    "                  'DefendersInTheBox','HomeScoreBeforePlay','VisitorScoreBeforePlay',\\\n",
    "                 'Offense_X_Removed2_std','Offense_Y_Removed2_std','Offense_X_Removed4_std','Offense_Y_Removed4_std',\\\n",
    "                 'Defense_X_std','Defense_Y_std','Defense_X_Removed2_std','Offense_Y_Removed2_std','Defense_X_Removed4_std',\\\n",
    "                 'Defense_Y_Removed4_std','num_DL','num_LB','num_DB','num_QB','num_RB','num_WR','num_TE','num_OL','OL_diff','OL_TE_diff',\\\n",
    "                 'run_def']]\n",
    "    rusher = rusher.sort_values('PlayId')\n",
    "    game = df1[['PlayId','Cleaned_GameWeather','Humidity','Temperature', \\\n",
    "              'Week']]\n",
    "    game = game.sort_values('PlayId')\n",
    "    offender = df2[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std','back_oriented_down_field',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff']]\n",
    "    offender = offender.sort_values(['PlayId','New_Y'])\n",
    "    defender = df3[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std','back_oriented_down_field',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff','Min_Time_Tacke']+list(range(2))]\n",
    "    defender = defender.sort_values(['PlayId','New_Y'])\n",
    "    \n",
    "    y = df1[['PlayId','Yards']].sort_values('PlayId').drop('PlayId',axis = 1)\n",
    "#get_dummy\n",
    "    def encoding_cat(df):\n",
    "        for cat in df.dtypes[df.dtypes=='object'].index.tolist():\n",
    "            a = pd.get_dummies(df[cat])\n",
    "            df = df.drop(cat,axis = 1)\n",
    "            df = pd.concat([df,a],axis = 1)\n",
    "        return df\n",
    "    rusher = encoding_cat(rusher)\n",
    "    game = encoding_cat(game)\n",
    "    offender = encoding_cat(offender)\n",
    "    defender = encoding_cat(defender)\n",
    "    \n",
    "    return rusher, game, offender, defender, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "rusher, game, offender, defender, y = split_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayId</th>\n",
       "      <th>PlayerAge</th>\n",
       "      <th>PlayerHeight</th>\n",
       "      <th>PlayerWeight</th>\n",
       "      <th>New_X</th>\n",
       "      <th>New_Y</th>\n",
       "      <th>Orientation_std</th>\n",
       "      <th>Dir_std</th>\n",
       "      <th>back_oriented_down_field</th>\n",
       "      <th>Horizontal Speed</th>\n",
       "      <th>Vertical Speed</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>Dis</th>\n",
       "      <th>Distance_to_Rusher</th>\n",
       "      <th>Degree_to_Rusher</th>\n",
       "      <th>Degree_Diff</th>\n",
       "      <th>Min_Time_Tacke</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>C</th>\n",
       "      <th>CB</th>\n",
       "      <th>DB</th>\n",
       "      <th>DE</th>\n",
       "      <th>DL</th>\n",
       "      <th>DT</th>\n",
       "      <th>FB</th>\n",
       "      <th>FS</th>\n",
       "      <th>G</th>\n",
       "      <th>ILB</th>\n",
       "      <th>LB</th>\n",
       "      <th>MLB</th>\n",
       "      <th>NT</th>\n",
       "      <th>OLB</th>\n",
       "      <th>OT</th>\n",
       "      <th>S</th>\n",
       "      <th>SAF</th>\n",
       "      <th>SS</th>\n",
       "      <th>WR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>24.662644</td>\n",
       "      <td>72</td>\n",
       "      <td>197</td>\n",
       "      <td>46.65</td>\n",
       "      <td>14.503333</td>\n",
       "      <td>345.47</td>\n",
       "      <td>10.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855705</td>\n",
       "      <td>4.468811</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.902020</td>\n",
       "      <td>146.951875</td>\n",
       "      <td>81.211875</td>\n",
       "      <td>2.176268</td>\n",
       "      <td>3.663441</td>\n",
       "      <td>5.799078</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>30.061685</td>\n",
       "      <td>72</td>\n",
       "      <td>206</td>\n",
       "      <td>50.68</td>\n",
       "      <td>17.913333</td>\n",
       "      <td>282.63</td>\n",
       "      <td>344.31</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.492187</td>\n",
       "      <td>1.752185</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10.622476</td>\n",
       "      <td>117.409349</td>\n",
       "      <td>51.669349</td>\n",
       "      <td>5.836525</td>\n",
       "      <td>5.890306</td>\n",
       "      <td>6.356886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>28.692760</td>\n",
       "      <td>72</td>\n",
       "      <td>212</td>\n",
       "      <td>46.09</td>\n",
       "      <td>18.493333</td>\n",
       "      <td>351.99</td>\n",
       "      <td>357.18</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.083145</td>\n",
       "      <td>1.687953</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.480872</td>\n",
       "      <td>131.684932</td>\n",
       "      <td>65.944932</td>\n",
       "      <td>3.834835</td>\n",
       "      <td>1.847647</td>\n",
       "      <td>2.866234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>28.629790</td>\n",
       "      <td>75</td>\n",
       "      <td>270</td>\n",
       "      <td>46.00</td>\n",
       "      <td>20.133333</td>\n",
       "      <td>273.01</td>\n",
       "      <td>22.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471395</td>\n",
       "      <td>1.125250</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.448982</td>\n",
       "      <td>119.340570</td>\n",
       "      <td>53.600570</td>\n",
       "      <td>4.466378</td>\n",
       "      <td>0.780064</td>\n",
       "      <td>1.449966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>28.457305</td>\n",
       "      <td>75</td>\n",
       "      <td>288</td>\n",
       "      <td>45.33</td>\n",
       "      <td>20.693333</td>\n",
       "      <td>297.61</td>\n",
       "      <td>18.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134657</td>\n",
       "      <td>0.397828</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.593310</td>\n",
       "      <td>117.346055</td>\n",
       "      <td>51.606055</td>\n",
       "      <td>10.936453</td>\n",
       "      <td>0.580517</td>\n",
       "      <td>0.763217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>23.184204</td>\n",
       "      <td>78</td>\n",
       "      <td>308</td>\n",
       "      <td>45.85</td>\n",
       "      <td>24.433333</td>\n",
       "      <td>252.58</td>\n",
       "      <td>94.14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718121</td>\n",
       "      <td>-0.051980</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.880256</td>\n",
       "      <td>70.488329</td>\n",
       "      <td>4.748329</td>\n",
       "      <td>6.778134</td>\n",
       "      <td>0.483011</td>\n",
       "      <td>0.608112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>34.795430</td>\n",
       "      <td>75</td>\n",
       "      <td>245</td>\n",
       "      <td>48.54</td>\n",
       "      <td>25.633333</td>\n",
       "      <td>269.77</td>\n",
       "      <td>285.64</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.404449</td>\n",
       "      <td>0.113229</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.02</td>\n",
       "      <td>7.820038</td>\n",
       "      <td>68.783638</td>\n",
       "      <td>3.043638</td>\n",
       "      <td>18.619139</td>\n",
       "      <td>3.213612</td>\n",
       "      <td>3.427944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>27.512746</td>\n",
       "      <td>74</td>\n",
       "      <td>208</td>\n",
       "      <td>63.37</td>\n",
       "      <td>26.433333</td>\n",
       "      <td>254.70</td>\n",
       "      <td>235.31</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.213783</td>\n",
       "      <td>-0.147975</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.28</td>\n",
       "      <td>22.415872</td>\n",
       "      <td>80.680549</td>\n",
       "      <td>14.940549</td>\n",
       "      <td>86.214891</td>\n",
       "      <td>18.018529</td>\n",
       "      <td>18.086760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>26.475101</td>\n",
       "      <td>74</td>\n",
       "      <td>252</td>\n",
       "      <td>44.94</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>218.34</td>\n",
       "      <td>275.01</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.006141</td>\n",
       "      <td>0.088203</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>7.500467</td>\n",
       "      <td>29.470106</td>\n",
       "      <td>36.269894</td>\n",
       "      <td>7.426205</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>4.495698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>26.431295</td>\n",
       "      <td>72</td>\n",
       "      <td>193</td>\n",
       "      <td>46.63</td>\n",
       "      <td>34.603333</td>\n",
       "      <td>238.52</td>\n",
       "      <td>90.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>-0.000866</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.13</td>\n",
       "      <td>12.968593</td>\n",
       "      <td>24.509770</td>\n",
       "      <td>41.230230</td>\n",
       "      <td>10.458543</td>\n",
       "      <td>1.407302</td>\n",
       "      <td>2.715032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>25.311514</td>\n",
       "      <td>71</td>\n",
       "      <td>190</td>\n",
       "      <td>45.89</td>\n",
       "      <td>36.693333</td>\n",
       "      <td>267.23</td>\n",
       "      <td>142.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0.674341</td>\n",
       "      <td>-0.881683</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.644511</td>\n",
       "      <td>18.472065</td>\n",
       "      <td>47.267935</td>\n",
       "      <td>13.193253</td>\n",
       "      <td>1.941778</td>\n",
       "      <td>2.617365</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>28.692761</td>\n",
       "      <td>72</td>\n",
       "      <td>212</td>\n",
       "      <td>54.27</td>\n",
       "      <td>19.453333</td>\n",
       "      <td>340.30</td>\n",
       "      <td>345.70</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.377908</td>\n",
       "      <td>1.482594</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8.583356</td>\n",
       "      <td>141.527841</td>\n",
       "      <td>9.327841</td>\n",
       "      <td>5.610037</td>\n",
       "      <td>2.497759</td>\n",
       "      <td>3.619351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>28.629790</td>\n",
       "      <td>75</td>\n",
       "      <td>270</td>\n",
       "      <td>53.98</td>\n",
       "      <td>21.833333</td>\n",
       "      <td>304.96</td>\n",
       "      <td>38.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453937</td>\n",
       "      <td>0.571700</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.13</td>\n",
       "      <td>6.658686</td>\n",
       "      <td>130.675959</td>\n",
       "      <td>1.524041</td>\n",
       "      <td>9.121488</td>\n",
       "      <td>0.736817</td>\n",
       "      <td>1.221884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>28.457306</td>\n",
       "      <td>75</td>\n",
       "      <td>288</td>\n",
       "      <td>53.96</td>\n",
       "      <td>23.243333</td>\n",
       "      <td>264.01</td>\n",
       "      <td>74.78</td>\n",
       "      <td>1</td>\n",
       "      <td>1.157910</td>\n",
       "      <td>0.315031</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.821151</td>\n",
       "      <td>120.221013</td>\n",
       "      <td>11.978987</td>\n",
       "      <td>4.850959</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.593970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>27.512747</td>\n",
       "      <td>74</td>\n",
       "      <td>208</td>\n",
       "      <td>71.95</td>\n",
       "      <td>25.653333</td>\n",
       "      <td>271.87</td>\n",
       "      <td>214.54</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.606670</td>\n",
       "      <td>-0.881392</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>23.025872</td>\n",
       "      <td>91.294037</td>\n",
       "      <td>40.905963</td>\n",
       "      <td>21.519507</td>\n",
       "      <td>18.326803</td>\n",
       "      <td>18.517241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>23.184205</td>\n",
       "      <td>78</td>\n",
       "      <td>308</td>\n",
       "      <td>53.20</td>\n",
       "      <td>25.783333</td>\n",
       "      <td>276.88</td>\n",
       "      <td>205.26</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.512072</td>\n",
       "      <td>-1.085257</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.13</td>\n",
       "      <td>4.287773</td>\n",
       "      <td>95.218625</td>\n",
       "      <td>36.981375</td>\n",
       "      <td>3.573144</td>\n",
       "      <td>0.603738</td>\n",
       "      <td>1.448102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>34.795430</td>\n",
       "      <td>75</td>\n",
       "      <td>245</td>\n",
       "      <td>56.69</td>\n",
       "      <td>26.143333</td>\n",
       "      <td>264.26</td>\n",
       "      <td>167.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405144</td>\n",
       "      <td>-1.794842</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7.760058</td>\n",
       "      <td>90.221503</td>\n",
       "      <td>41.978497</td>\n",
       "      <td>4.217423</td>\n",
       "      <td>4.009102</td>\n",
       "      <td>4.078946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>30.061686</td>\n",
       "      <td>72</td>\n",
       "      <td>206</td>\n",
       "      <td>59.49</td>\n",
       "      <td>26.823333</td>\n",
       "      <td>247.47</td>\n",
       "      <td>187.72</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.374787</td>\n",
       "      <td>-2.764712</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>10.579986</td>\n",
       "      <td>86.477715</td>\n",
       "      <td>45.722285</td>\n",
       "      <td>3.792110</td>\n",
       "      <td>6.737069</td>\n",
       "      <td>6.822815</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>26.475102</td>\n",
       "      <td>74</td>\n",
       "      <td>252</td>\n",
       "      <td>53.40</td>\n",
       "      <td>29.063333</td>\n",
       "      <td>236.61</td>\n",
       "      <td>184.15</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.085394</td>\n",
       "      <td>-1.176906</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.19</td>\n",
       "      <td>5.322875</td>\n",
       "      <td>57.116021</td>\n",
       "      <td>75.083979</td>\n",
       "      <td>4.510911</td>\n",
       "      <td>1.500966</td>\n",
       "      <td>3.626307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>24.662644</td>\n",
       "      <td>72</td>\n",
       "      <td>197</td>\n",
       "      <td>55.54</td>\n",
       "      <td>33.973333</td>\n",
       "      <td>215.89</td>\n",
       "      <td>322.88</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.303531</td>\n",
       "      <td>1.722326</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.26</td>\n",
       "      <td>10.224094</td>\n",
       "      <td>40.279138</td>\n",
       "      <td>91.920862</td>\n",
       "      <td>4.733377</td>\n",
       "      <td>3.727144</td>\n",
       "      <td>6.175176</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>26.431296</td>\n",
       "      <td>72</td>\n",
       "      <td>193</td>\n",
       "      <td>54.82</td>\n",
       "      <td>36.973333</td>\n",
       "      <td>248.44</td>\n",
       "      <td>51.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1.781122</td>\n",
       "      <td>1.423378</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.34</td>\n",
       "      <td>12.301711</td>\n",
       "      <td>28.606743</td>\n",
       "      <td>103.593257</td>\n",
       "      <td>5.395487</td>\n",
       "      <td>1.751457</td>\n",
       "      <td>5.693505</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20170907000139</td>\n",
       "      <td>25.311515</td>\n",
       "      <td>71</td>\n",
       "      <td>190</td>\n",
       "      <td>54.88</td>\n",
       "      <td>43.903333</td>\n",
       "      <td>274.69</td>\n",
       "      <td>67.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1.897493</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.31</td>\n",
       "      <td>18.701749</td>\n",
       "      <td>18.551207</td>\n",
       "      <td>113.648793</td>\n",
       "      <td>9.122804</td>\n",
       "      <td>1.971243</td>\n",
       "      <td>7.353700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20170907000189</td>\n",
       "      <td>24.662646</td>\n",
       "      <td>72</td>\n",
       "      <td>197</td>\n",
       "      <td>77.73</td>\n",
       "      <td>20.443333</td>\n",
       "      <td>303.12</td>\n",
       "      <td>43.51</td>\n",
       "      <td>1</td>\n",
       "      <td>2.120522</td>\n",
       "      <td>2.233783</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.35</td>\n",
       "      <td>15.189486</td>\n",
       "      <td>155.122113</td>\n",
       "      <td>113.162113</td>\n",
       "      <td>4.931651</td>\n",
       "      <td>1.886054</td>\n",
       "      <td>4.838450</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20170907000189</td>\n",
       "      <td>26.431298</td>\n",
       "      <td>72</td>\n",
       "      <td>193</td>\n",
       "      <td>80.13</td>\n",
       "      <td>22.843333</td>\n",
       "      <td>307.14</td>\n",
       "      <td>27.53</td>\n",
       "      <td>1</td>\n",
       "      <td>2.010626</td>\n",
       "      <td>3.857445</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.45</td>\n",
       "      <td>14.379447</td>\n",
       "      <td>142.317225</td>\n",
       "      <td>100.357225</td>\n",
       "      <td>3.305620</td>\n",
       "      <td>4.180574</td>\n",
       "      <td>5.462838</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20170907000189</td>\n",
       "      <td>28.692762</td>\n",
       "      <td>72</td>\n",
       "      <td>212</td>\n",
       "      <td>75.25</td>\n",
       "      <td>26.803333</td>\n",
       "      <td>342.60</td>\n",
       "      <td>348.16</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.773526</td>\n",
       "      <td>3.689791</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.44</td>\n",
       "      <td>8.387163</td>\n",
       "      <td>152.212824</td>\n",
       "      <td>110.252824</td>\n",
       "      <td>2.224712</td>\n",
       "      <td>1.403887</td>\n",
       "      <td>2.477781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20170907000189</td>\n",
       "      <td>28.629792</td>\n",
       "      <td>75</td>\n",
       "      <td>270</td>\n",
       "      <td>76.61</td>\n",
       "      <td>27.973333</td>\n",
       "      <td>285.91</td>\n",
       "      <td>6.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459042</td>\n",
       "      <td>3.782245</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>8.175292</td>\n",
       "      <td>139.862413</td>\n",
       "      <td>97.902413</td>\n",
       "      <td>2.145746</td>\n",
       "      <td>0.840119</td>\n",
       "      <td>2.493772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20170907000189</td>\n",
       "      <td>28.457307</td>\n",
       "      <td>75</td>\n",
       "      <td>288</td>\n",
       "      <td>75.62</td>\n",
       "      <td>29.913333</td>\n",
       "      <td>302.33</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782260</td>\n",
       "      <td>3.123535</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.34</td>\n",
       "      <td>6.074084</td>\n",
       "      <td>135.200101</td>\n",
       "      <td>93.240101</td>\n",
       "      <td>1.886362</td>\n",
       "      <td>0.443847</td>\n",
       "      <td>1.817058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20170907000189</td>\n",
       "      <td>27.512749</td>\n",
       "      <td>74</td>\n",
       "      <td>208</td>\n",
       "      <td>91.76</td>\n",
       "      <td>30.673333</td>\n",
       "      <td>274.77</td>\n",
       "      <td>346.37</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.935534</td>\n",
       "      <td>3.858196</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.45</td>\n",
       "      <td>20.726285</td>\n",
       "      <td>99.862255</td>\n",
       "      <td>57.902255</td>\n",
       "      <td>5.220727</td>\n",
       "      <td>14.935488</td>\n",
       "      <td>15.503096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20170907000189</td>\n",
       "      <td>30.061688</td>\n",
       "      <td>72</td>\n",
       "      <td>206</td>\n",
       "      <td>79.05</td>\n",
       "      <td>30.873333</td>\n",
       "      <td>289.54</td>\n",
       "      <td>4.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278965</td>\n",
       "      <td>3.308259</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.37</td>\n",
       "      <td>8.406343</td>\n",
       "      <td>113.484978</td>\n",
       "      <td>71.524978</td>\n",
       "      <td>2.532031</td>\n",
       "      <td>2.261526</td>\n",
       "      <td>3.952480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20170907000189</td>\n",
       "      <td>23.184207</td>\n",
       "      <td>78</td>\n",
       "      <td>308</td>\n",
       "      <td>75.35</td>\n",
       "      <td>32.903333</td>\n",
       "      <td>269.93</td>\n",
       "      <td>351.94</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.344917</td>\n",
       "      <td>2.435700</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.221670</td>\n",
       "      <td>108.220359</td>\n",
       "      <td>66.260359</td>\n",
       "      <td>1.716126</td>\n",
       "      <td>0.903383</td>\n",
       "      <td>1.981161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254851</th>\n",
       "      <td>20181230154082</td>\n",
       "      <td>26.313528</td>\n",
       "      <td>76</td>\n",
       "      <td>256</td>\n",
       "      <td>43.17</td>\n",
       "      <td>27.640000</td>\n",
       "      <td>296.37</td>\n",
       "      <td>327.76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.685755</td>\n",
       "      <td>2.672794</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3.595998</td>\n",
       "      <td>115.709954</td>\n",
       "      <td>74.459954</td>\n",
       "      <td>1.137974</td>\n",
       "      <td>1.725399</td>\n",
       "      <td>2.930734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254852</th>\n",
       "      <td>20181230154082</td>\n",
       "      <td>26.948709</td>\n",
       "      <td>77</td>\n",
       "      <td>305</td>\n",
       "      <td>44.65</td>\n",
       "      <td>29.450000</td>\n",
       "      <td>283.44</td>\n",
       "      <td>10.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370777</td>\n",
       "      <td>1.975506</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.726616</td>\n",
       "      <td>86.968099</td>\n",
       "      <td>45.718099</td>\n",
       "      <td>2.351550</td>\n",
       "      <td>0.839345</td>\n",
       "      <td>1.344656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254853</th>\n",
       "      <td>20181230154082</td>\n",
       "      <td>24.273829</td>\n",
       "      <td>73</td>\n",
       "      <td>235</td>\n",
       "      <td>45.51</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>255.19</td>\n",
       "      <td>332.18</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.820112</td>\n",
       "      <td>3.449231</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5.793962</td>\n",
       "      <td>74.380608</td>\n",
       "      <td>33.130608</td>\n",
       "      <td>1.485631</td>\n",
       "      <td>1.719767</td>\n",
       "      <td>2.264906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254854</th>\n",
       "      <td>20181230154082</td>\n",
       "      <td>30.562672</td>\n",
       "      <td>75</td>\n",
       "      <td>335</td>\n",
       "      <td>42.96</td>\n",
       "      <td>32.180000</td>\n",
       "      <td>230.71</td>\n",
       "      <td>330.50</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.048862</td>\n",
       "      <td>1.853858</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.249859</td>\n",
       "      <td>45.476659</td>\n",
       "      <td>4.226659</td>\n",
       "      <td>1.995239</td>\n",
       "      <td>0.796116</td>\n",
       "      <td>0.857030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254855</th>\n",
       "      <td>20181230154082</td>\n",
       "      <td>26.335431</td>\n",
       "      <td>73</td>\n",
       "      <td>211</td>\n",
       "      <td>43.72</td>\n",
       "      <td>33.460000</td>\n",
       "      <td>214.19</td>\n",
       "      <td>341.08</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.551221</td>\n",
       "      <td>1.608153</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.701903</td>\n",
       "      <td>41.658574</td>\n",
       "      <td>0.408574</td>\n",
       "      <td>3.354061</td>\n",
       "      <td>1.141271</td>\n",
       "      <td>2.284426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254856</th>\n",
       "      <td>20181230154082</td>\n",
       "      <td>28.840564</td>\n",
       "      <td>77</td>\n",
       "      <td>265</td>\n",
       "      <td>43.28</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>231.77</td>\n",
       "      <td>317.40</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.502665</td>\n",
       "      <td>1.634136</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7.616305</td>\n",
       "      <td>26.094045</td>\n",
       "      <td>15.155955</td>\n",
       "      <td>3.430768</td>\n",
       "      <td>1.536522</td>\n",
       "      <td>3.108456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254857</th>\n",
       "      <td>20181230154082</td>\n",
       "      <td>22.973350</td>\n",
       "      <td>70</td>\n",
       "      <td>195</td>\n",
       "      <td>43.21</td>\n",
       "      <td>40.100000</td>\n",
       "      <td>287.16</td>\n",
       "      <td>311.24</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.526568</td>\n",
       "      <td>2.214961</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.382812</td>\n",
       "      <td>16.747457</td>\n",
       "      <td>24.502543</td>\n",
       "      <td>3.387742</td>\n",
       "      <td>2.265149</td>\n",
       "      <td>5.056896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254858</th>\n",
       "      <td>20181230154082</td>\n",
       "      <td>28.473692</td>\n",
       "      <td>73</td>\n",
       "      <td>203</td>\n",
       "      <td>45.70</td>\n",
       "      <td>45.670000</td>\n",
       "      <td>290.28</td>\n",
       "      <td>44.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808190</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.10</td>\n",
       "      <td>17.451470</td>\n",
       "      <td>19.307090</td>\n",
       "      <td>21.942910</td>\n",
       "      <td>15.175191</td>\n",
       "      <td>1.527121</td>\n",
       "      <td>6.956903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254859</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>27.063701</td>\n",
       "      <td>73</td>\n",
       "      <td>205</td>\n",
       "      <td>86.59</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>264.54</td>\n",
       "      <td>111.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.858259</td>\n",
       "      <td>-0.331347</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16.725696</td>\n",
       "      <td>161.164236</td>\n",
       "      <td>119.924236</td>\n",
       "      <td>18.180104</td>\n",
       "      <td>2.364762</td>\n",
       "      <td>14.571321</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254860</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>26.516131</td>\n",
       "      <td>73</td>\n",
       "      <td>205</td>\n",
       "      <td>93.53</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>293.31</td>\n",
       "      <td>240.67</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.976430</td>\n",
       "      <td>-0.548620</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.11</td>\n",
       "      <td>13.379256</td>\n",
       "      <td>112.731867</td>\n",
       "      <td>71.491867</td>\n",
       "      <td>11.945765</td>\n",
       "      <td>10.075560</td>\n",
       "      <td>10.163513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254861</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>34.428520</td>\n",
       "      <td>71</td>\n",
       "      <td>206</td>\n",
       "      <td>85.14</td>\n",
       "      <td>20.040000</td>\n",
       "      <td>305.56</td>\n",
       "      <td>339.59</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.189188</td>\n",
       "      <td>3.195924</td>\n",
       "      <td>3.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>5.419096</td>\n",
       "      <td>133.205419</td>\n",
       "      <td>91.965419</td>\n",
       "      <td>1.589178</td>\n",
       "      <td>2.477761</td>\n",
       "      <td>3.747693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254862</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>26.313530</td>\n",
       "      <td>76</td>\n",
       "      <td>256</td>\n",
       "      <td>84.92</td>\n",
       "      <td>22.070000</td>\n",
       "      <td>297.60</td>\n",
       "      <td>348.12</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.592884</td>\n",
       "      <td>2.818313</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.090880</td>\n",
       "      <td>114.246904</td>\n",
       "      <td>73.006904</td>\n",
       "      <td>1.420444</td>\n",
       "      <td>0.882950</td>\n",
       "      <td>1.710117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254863</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>24.851518</td>\n",
       "      <td>75</td>\n",
       "      <td>331</td>\n",
       "      <td>85.80</td>\n",
       "      <td>23.980000</td>\n",
       "      <td>292.04</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233290</td>\n",
       "      <td>2.970854</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.615734</td>\n",
       "      <td>87.143794</td>\n",
       "      <td>45.903794</td>\n",
       "      <td>1.548904</td>\n",
       "      <td>0.921954</td>\n",
       "      <td>1.153126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254864</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>24.273831</td>\n",
       "      <td>73</td>\n",
       "      <td>235</td>\n",
       "      <td>86.04</td>\n",
       "      <td>25.070000</td>\n",
       "      <td>254.97</td>\n",
       "      <td>336.11</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.247345</td>\n",
       "      <td>2.816120</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.026420</td>\n",
       "      <td>74.774874</td>\n",
       "      <td>33.534874</td>\n",
       "      <td>1.631955</td>\n",
       "      <td>1.120893</td>\n",
       "      <td>1.721540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254865</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>30.562674</td>\n",
       "      <td>75</td>\n",
       "      <td>335</td>\n",
       "      <td>84.55</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>207.59</td>\n",
       "      <td>337.68</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.657018</td>\n",
       "      <td>1.600384</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.17</td>\n",
       "      <td>4.188031</td>\n",
       "      <td>53.348996</td>\n",
       "      <td>12.108996</td>\n",
       "      <td>2.420827</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.748131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254866</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>26.335433</td>\n",
       "      <td>73</td>\n",
       "      <td>211</td>\n",
       "      <td>85.90</td>\n",
       "      <td>28.050000</td>\n",
       "      <td>232.45</td>\n",
       "      <td>325.76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.423531</td>\n",
       "      <td>2.091521</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.377625</td>\n",
       "      <td>47.605447</td>\n",
       "      <td>6.365447</td>\n",
       "      <td>2.520800</td>\n",
       "      <td>2.136001</td>\n",
       "      <td>2.586832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254867</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>28.840566</td>\n",
       "      <td>77</td>\n",
       "      <td>265</td>\n",
       "      <td>83.50</td>\n",
       "      <td>30.320000</td>\n",
       "      <td>209.19</td>\n",
       "      <td>304.43</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.886861</td>\n",
       "      <td>1.978896</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>6.964266</td>\n",
       "      <td>19.371581</td>\n",
       "      <td>21.868419</td>\n",
       "      <td>1.989790</td>\n",
       "      <td>1.330038</td>\n",
       "      <td>3.616435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254868</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>22.973352</td>\n",
       "      <td>70</td>\n",
       "      <td>195</td>\n",
       "      <td>87.67</td>\n",
       "      <td>35.920000</td>\n",
       "      <td>292.83</td>\n",
       "      <td>15.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>2.252699</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>13.787650</td>\n",
       "      <td>28.033376</td>\n",
       "      <td>13.206624</td>\n",
       "      <td>5.892158</td>\n",
       "      <td>5.483885</td>\n",
       "      <td>7.178649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254869</th>\n",
       "      <td>20181230154135</td>\n",
       "      <td>28.473694</td>\n",
       "      <td>73</td>\n",
       "      <td>203</td>\n",
       "      <td>86.64</td>\n",
       "      <td>42.070000</td>\n",
       "      <td>278.16</td>\n",
       "      <td>114.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.426724</td>\n",
       "      <td>-0.196994</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.05</td>\n",
       "      <td>19.113474</td>\n",
       "      <td>16.567167</td>\n",
       "      <td>24.672833</td>\n",
       "      <td>40.666967</td>\n",
       "      <td>2.290589</td>\n",
       "      <td>7.272634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254870</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>24.273832</td>\n",
       "      <td>73</td>\n",
       "      <td>235</td>\n",
       "      <td>87.82</td>\n",
       "      <td>21.820000</td>\n",
       "      <td>295.36</td>\n",
       "      <td>40.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.866797</td>\n",
       "      <td>2.219250</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.29</td>\n",
       "      <td>8.354717</td>\n",
       "      <td>122.834119</td>\n",
       "      <td>4.594119</td>\n",
       "      <td>2.880937</td>\n",
       "      <td>1.078703</td>\n",
       "      <td>2.601327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254871</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>22.973353</td>\n",
       "      <td>70</td>\n",
       "      <td>195</td>\n",
       "      <td>87.91</td>\n",
       "      <td>22.380000</td>\n",
       "      <td>338.09</td>\n",
       "      <td>306.72</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.623083</td>\n",
       "      <td>2.702531</td>\n",
       "      <td>4.52</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>8.143279</td>\n",
       "      <td>119.177615</td>\n",
       "      <td>0.937615</td>\n",
       "      <td>1.801610</td>\n",
       "      <td>1.205031</td>\n",
       "      <td>2.147557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254872</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>27.953504</td>\n",
       "      <td>74</td>\n",
       "      <td>236</td>\n",
       "      <td>87.48</td>\n",
       "      <td>23.670000</td>\n",
       "      <td>311.08</td>\n",
       "      <td>16.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317721</td>\n",
       "      <td>1.084414</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.11</td>\n",
       "      <td>7.197555</td>\n",
       "      <td>111.860538</td>\n",
       "      <td>6.379462</td>\n",
       "      <td>6.369518</td>\n",
       "      <td>0.886002</td>\n",
       "      <td>1.800250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254873</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>26.313531</td>\n",
       "      <td>76</td>\n",
       "      <td>256</td>\n",
       "      <td>85.86</td>\n",
       "      <td>24.680000</td>\n",
       "      <td>247.92</td>\n",
       "      <td>316.90</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.318718</td>\n",
       "      <td>1.409213</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.21</td>\n",
       "      <td>5.328461</td>\n",
       "      <td>108.264932</td>\n",
       "      <td>9.975068</td>\n",
       "      <td>2.760861</td>\n",
       "      <td>0.411461</td>\n",
       "      <td>1.028834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254874</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>26.335434</td>\n",
       "      <td>73</td>\n",
       "      <td>211</td>\n",
       "      <td>87.86</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>222.14</td>\n",
       "      <td>76.87</td>\n",
       "      <td>1</td>\n",
       "      <td>1.314707</td>\n",
       "      <td>0.306668</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>7.137654</td>\n",
       "      <td>81.540680</td>\n",
       "      <td>36.699320</td>\n",
       "      <td>5.287151</td>\n",
       "      <td>0.694622</td>\n",
       "      <td>1.121784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254875</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>24.851519</td>\n",
       "      <td>75</td>\n",
       "      <td>331</td>\n",
       "      <td>87.43</td>\n",
       "      <td>27.780000</td>\n",
       "      <td>242.40</td>\n",
       "      <td>13.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.587459</td>\n",
       "      <td>2.357921</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.782463</td>\n",
       "      <td>77.828542</td>\n",
       "      <td>40.411458</td>\n",
       "      <td>2.791137</td>\n",
       "      <td>0.749533</td>\n",
       "      <td>0.899389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254876</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>34.428521</td>\n",
       "      <td>71</td>\n",
       "      <td>206</td>\n",
       "      <td>88.22</td>\n",
       "      <td>28.050000</td>\n",
       "      <td>242.66</td>\n",
       "      <td>114.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979845</td>\n",
       "      <td>-0.454206</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.11</td>\n",
       "      <td>7.612253</td>\n",
       "      <td>77.095648</td>\n",
       "      <td>41.144352</td>\n",
       "      <td>7.048383</td>\n",
       "      <td>1.386218</td>\n",
       "      <td>1.699559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254877</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>30.562676</td>\n",
       "      <td>75</td>\n",
       "      <td>335</td>\n",
       "      <td>86.64</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>234.21</td>\n",
       "      <td>82.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208047</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6.126018</td>\n",
       "      <td>72.422797</td>\n",
       "      <td>45.817203</td>\n",
       "      <td>29.171516</td>\n",
       "      <td>0.948472</td>\n",
       "      <td>1.027035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254878</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>27.063702</td>\n",
       "      <td>73</td>\n",
       "      <td>205</td>\n",
       "      <td>99.14</td>\n",
       "      <td>29.810000</td>\n",
       "      <td>256.20</td>\n",
       "      <td>248.21</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.829245</td>\n",
       "      <td>-0.731275</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.19</td>\n",
       "      <td>18.663526</td>\n",
       "      <td>79.316226</td>\n",
       "      <td>38.923774</td>\n",
       "      <td>9.473871</td>\n",
       "      <td>12.196393</td>\n",
       "      <td>12.656275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254879</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>28.840567</td>\n",
       "      <td>77</td>\n",
       "      <td>265</td>\n",
       "      <td>85.82</td>\n",
       "      <td>30.070000</td>\n",
       "      <td>205.86</td>\n",
       "      <td>247.08</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.188154</td>\n",
       "      <td>-0.502385</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.11</td>\n",
       "      <td>6.248104</td>\n",
       "      <td>53.460228</td>\n",
       "      <td>64.779772</td>\n",
       "      <td>4.843491</td>\n",
       "      <td>1.132299</td>\n",
       "      <td>2.576296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254880</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>28.473695</td>\n",
       "      <td>73</td>\n",
       "      <td>203</td>\n",
       "      <td>90.09</td>\n",
       "      <td>42.830000</td>\n",
       "      <td>175.02</td>\n",
       "      <td>130.60</td>\n",
       "      <td>0</td>\n",
       "      <td>2.361334</td>\n",
       "      <td>-2.023908</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>18.918100</td>\n",
       "      <td>29.410547</td>\n",
       "      <td>88.829453</td>\n",
       "      <td>6.082990</td>\n",
       "      <td>3.113535</td>\n",
       "      <td>14.526644</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254881 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                PlayId  PlayerAge  PlayerHeight  PlayerWeight  New_X  \\\n",
       "0       20170907000118  24.662644            72           197  46.65   \n",
       "1       20170907000118  30.061685            72           206  50.68   \n",
       "2       20170907000118  28.692760            72           212  46.09   \n",
       "3       20170907000118  28.629790            75           270  46.00   \n",
       "4       20170907000118  28.457305            75           288  45.33   \n",
       "5       20170907000118  23.184204            78           308  45.85   \n",
       "6       20170907000118  34.795430            75           245  48.54   \n",
       "7       20170907000118  27.512746            74           208  63.37   \n",
       "8       20170907000118  26.475101            74           252  44.94   \n",
       "9       20170907000118  26.431295            72           193  46.63   \n",
       "10      20170907000118  25.311514            71           190  45.89   \n",
       "11      20170907000139  28.692761            72           212  54.27   \n",
       "12      20170907000139  28.629790            75           270  53.98   \n",
       "13      20170907000139  28.457306            75           288  53.96   \n",
       "14      20170907000139  27.512747            74           208  71.95   \n",
       "15      20170907000139  23.184205            78           308  53.20   \n",
       "16      20170907000139  34.795430            75           245  56.69   \n",
       "17      20170907000139  30.061686            72           206  59.49   \n",
       "18      20170907000139  26.475102            74           252  53.40   \n",
       "19      20170907000139  24.662644            72           197  55.54   \n",
       "20      20170907000139  26.431296            72           193  54.82   \n",
       "21      20170907000139  25.311515            71           190  54.88   \n",
       "22      20170907000189  24.662646            72           197  77.73   \n",
       "23      20170907000189  26.431298            72           193  80.13   \n",
       "24      20170907000189  28.692762            72           212  75.25   \n",
       "25      20170907000189  28.629792            75           270  76.61   \n",
       "26      20170907000189  28.457307            75           288  75.62   \n",
       "27      20170907000189  27.512749            74           208  91.76   \n",
       "28      20170907000189  30.061688            72           206  79.05   \n",
       "29      20170907000189  23.184207            78           308  75.35   \n",
       "...                ...        ...           ...           ...    ...   \n",
       "254851  20181230154082  26.313528            76           256  43.17   \n",
       "254852  20181230154082  26.948709            77           305  44.65   \n",
       "254853  20181230154082  24.273829            73           235  45.51   \n",
       "254854  20181230154082  30.562672            75           335  42.96   \n",
       "254855  20181230154082  26.335431            73           211  43.72   \n",
       "254856  20181230154082  28.840564            77           265  43.28   \n",
       "254857  20181230154082  22.973350            70           195  43.21   \n",
       "254858  20181230154082  28.473692            73           203  45.70   \n",
       "254859  20181230154135  27.063701            73           205  86.59   \n",
       "254860  20181230154135  26.516131            73           205  93.53   \n",
       "254861  20181230154135  34.428520            71           206  85.14   \n",
       "254862  20181230154135  26.313530            76           256  84.92   \n",
       "254863  20181230154135  24.851518            75           331  85.80   \n",
       "254864  20181230154135  24.273831            73           235  86.04   \n",
       "254865  20181230154135  30.562674            75           335  84.55   \n",
       "254866  20181230154135  26.335433            73           211  85.90   \n",
       "254867  20181230154135  28.840566            77           265  83.50   \n",
       "254868  20181230154135  22.973352            70           195  87.67   \n",
       "254869  20181230154135  28.473694            73           203  86.64   \n",
       "254870  20181230154157  24.273832            73           235  87.82   \n",
       "254871  20181230154157  22.973353            70           195  87.91   \n",
       "254872  20181230154157  27.953504            74           236  87.48   \n",
       "254873  20181230154157  26.313531            76           256  85.86   \n",
       "254874  20181230154157  26.335434            73           211  87.86   \n",
       "254875  20181230154157  24.851519            75           331  87.43   \n",
       "254876  20181230154157  34.428521            71           206  88.22   \n",
       "254877  20181230154157  30.562676            75           335  86.64   \n",
       "254878  20181230154157  27.063702            73           205  99.14   \n",
       "254879  20181230154157  28.840567            77           265  85.82   \n",
       "254880  20181230154157  28.473695            73           203  90.09   \n",
       "\n",
       "            New_Y  Orientation_std  Dir_std  back_oriented_down_field  \\\n",
       "0       14.503333           345.47    10.84                         1   \n",
       "1       17.913333           282.63   344.31                         1   \n",
       "2       18.493333           351.99   357.18                         1   \n",
       "3       20.133333           273.01    22.73                         1   \n",
       "4       20.693333           297.61    18.70                         1   \n",
       "5       24.433333           252.58    94.14                         1   \n",
       "6       25.633333           269.77   285.64                         1   \n",
       "7       26.433333           254.70   235.31                         1   \n",
       "8       29.333333           218.34   275.01                         1   \n",
       "9       34.603333           238.52    90.04                         1   \n",
       "10      36.693333           267.23   142.59                         1   \n",
       "11      19.453333           340.30   345.70                         1   \n",
       "12      21.833333           304.96    38.45                         1   \n",
       "13      23.243333           264.01    74.78                         1   \n",
       "14      25.653333           271.87   214.54                         1   \n",
       "15      25.783333           276.88   205.26                         1   \n",
       "16      26.143333           264.26   167.28                         1   \n",
       "17      26.823333           247.47   187.72                         1   \n",
       "18      29.063333           236.61   184.15                         1   \n",
       "19      33.973333           215.89   322.88                         1   \n",
       "20      36.973333           248.44    51.37                         1   \n",
       "21      43.903333           274.69    67.76                         1   \n",
       "22      20.443333           303.12    43.51                         1   \n",
       "23      22.843333           307.14    27.53                         1   \n",
       "24      26.803333           342.60   348.16                         1   \n",
       "25      27.973333           285.91     6.92                         1   \n",
       "26      29.913333           302.33    14.06                         1   \n",
       "27      30.673333           274.77   346.37                         1   \n",
       "28      30.873333           289.54     4.82                         1   \n",
       "29      32.903333           269.93   351.94                         1   \n",
       "...           ...              ...      ...                       ...   \n",
       "254851  27.640000           296.37   327.76                         1   \n",
       "254852  29.450000           283.44    10.63                         1   \n",
       "254853  30.760000           255.19   332.18                         1   \n",
       "254854  32.180000           230.71   330.50                         1   \n",
       "254855  33.460000           214.19   341.08                         1   \n",
       "254856  36.040000           231.77   317.40                         1   \n",
       "254857  40.100000           287.16   311.24                         1   \n",
       "254858  45.670000           290.28    44.65                         1   \n",
       "254859   7.920000           264.54   111.11                         1   \n",
       "254860  18.580000           293.31   240.67                         1   \n",
       "254861  20.040000           305.56   339.59                         1   \n",
       "254862  22.070000           297.60   348.12                         1   \n",
       "254863  23.980000           292.04     4.49                         1   \n",
       "254864  25.070000           254.97   336.11                         1   \n",
       "254865  26.250000           207.59   337.68                         1   \n",
       "254866  28.050000           232.45   325.76                         1   \n",
       "254867  30.320000           209.19   304.43                         1   \n",
       "254868  35.920000           292.83    15.70                         1   \n",
       "254869  42.070000           278.16   114.78                         1   \n",
       "254870  21.820000           295.36    40.07                         1   \n",
       "254871  22.380000           338.09   306.72                         1   \n",
       "254872  23.670000           311.08    16.33                         1   \n",
       "254873  24.680000           247.92   316.90                         1   \n",
       "254874  27.400000           222.14    76.87                         1   \n",
       "254875  27.780000           242.40    13.99                         1   \n",
       "254876  28.050000           242.66   114.87                         1   \n",
       "254877  28.200000           234.21    82.18                         1   \n",
       "254878  29.810000           256.20   248.21                         1   \n",
       "254879  30.070000           205.86   247.08                         1   \n",
       "254880  42.830000           175.02   130.60                         0   \n",
       "\n",
       "        Horizontal Speed  Vertical Speed     S     A   Dis  \\\n",
       "0               0.855705        4.468811  4.55  0.76  0.51   \n",
       "1              -0.492187        1.752185  1.82  2.43  0.16   \n",
       "2              -0.083145        1.687953  1.69  1.13  0.40   \n",
       "3               0.471395        1.125250  1.22  0.59  0.31   \n",
       "4               0.134657        0.397828  0.42  1.35  0.01   \n",
       "5               0.718121       -0.051980  0.72  0.73  0.01   \n",
       "6              -0.404449        0.113229  0.42  0.54  0.02   \n",
       "7              -0.213783       -0.147975  0.26  1.86  0.28   \n",
       "8              -1.006141        0.088203  1.01  0.32  0.18   \n",
       "9               1.240000       -0.000866  1.24  0.74  0.13   \n",
       "10              0.674341       -0.881683  1.11  0.83  0.02   \n",
       "11             -0.377908        1.482594  1.53  2.16  0.20   \n",
       "12              0.453937        0.571700  0.73  0.84  0.13   \n",
       "13              1.157910        0.315031  1.20  1.06  0.01   \n",
       "14             -0.606670       -0.881392  1.07  2.01  0.08   \n",
       "15             -0.512072       -1.085257  1.20  0.55  0.13   \n",
       "16              0.405144       -1.794842  1.84  1.02  0.24   \n",
       "17             -0.374787       -2.764712  2.79  2.67  0.28   \n",
       "18             -0.085394       -1.176906  1.18  1.63  0.19   \n",
       "19             -1.303531        1.722326  2.16  1.61  0.26   \n",
       "20              1.781122        1.423378  2.28  2.24  0.34   \n",
       "21              1.897493        0.775899  2.05  1.73  0.31   \n",
       "22              2.120522        2.233783  3.08  1.98  0.35   \n",
       "23              2.010626        3.857445  4.35  2.71  0.45   \n",
       "24             -0.773526        3.689791  3.77  2.95  0.44   \n",
       "25              0.459042        3.782245  3.81  1.34  0.41   \n",
       "26              0.782260        3.123535  3.22  2.46  0.34   \n",
       "27             -0.935534        3.858196  3.97  3.11  0.45   \n",
       "28              0.278965        3.308259  3.32  2.67  0.37   \n",
       "29             -0.344917        2.435700  2.46  1.13  0.30   \n",
       "...                  ...             ...   ...   ...   ...   \n",
       "254851         -1.685755        2.672794  3.16  1.30  0.36   \n",
       "254852          0.370777        1.975506  2.01  1.38  0.24   \n",
       "254853         -1.820112        3.449231  3.90  2.35  0.38   \n",
       "254854         -1.048862        1.853858  2.13  1.05  0.20   \n",
       "254855         -0.551221        1.608153  1.70  3.18  0.17   \n",
       "254856         -1.502665        1.634136  2.22  0.59  0.24   \n",
       "254857         -2.526568        2.214961  3.36  3.08  0.32   \n",
       "254858          0.808190        0.818125  1.15  1.93  0.10   \n",
       "254859          0.858259       -0.331347  0.92  0.72  0.09   \n",
       "254860         -0.976430       -0.548620  1.12  0.49  0.11   \n",
       "254861         -1.189188        3.195924  3.41  1.29  0.33   \n",
       "254862         -0.592884        2.818313  2.88  3.38  0.35   \n",
       "254863          0.233290        2.970854  2.98  1.47  0.33   \n",
       "254864         -1.247345        2.816120  3.08  1.42  0.30   \n",
       "254865         -0.657018        1.600384  1.73  0.69  0.17   \n",
       "254866         -1.423531        2.091521  2.53  0.52  0.25   \n",
       "254867         -2.886861        1.978896  3.50  2.38  0.39   \n",
       "254868          0.633205        2.252699  2.34  2.24  0.22   \n",
       "254869          0.426724       -0.196994  0.47  0.61  0.05   \n",
       "254870          1.866797        2.219250  2.90  2.67  0.29   \n",
       "254871         -3.623083        2.702531  4.52  2.55  0.44   \n",
       "254872          0.317721        1.084414  1.13  1.88  0.11   \n",
       "254873         -1.318718        1.409213  1.93  0.88  0.21   \n",
       "254874          1.314707        0.306668  1.35  2.17  0.12   \n",
       "254875          0.587459        2.357921  2.43  1.85  0.25   \n",
       "254876          0.979845       -0.454206  1.08  2.78  0.11   \n",
       "254877          0.208047        0.028573  0.21  0.89  0.04   \n",
       "254878         -1.829245       -0.731275  1.97  1.40  0.19   \n",
       "254879         -1.188154       -0.502385  1.29  1.35  0.11   \n",
       "254880          2.361334       -2.023908  3.11  2.47  0.31   \n",
       "\n",
       "        Distance_to_Rusher  Degree_to_Rusher  Degree_Diff  Min_Time_Tacke  \\\n",
       "0                 9.902020        146.951875    81.211875        2.176268   \n",
       "1                10.622476        117.409349    51.669349        5.836525   \n",
       "2                 6.480872        131.684932    65.944932        3.834835   \n",
       "3                 5.448982        119.340570    53.600570        4.466378   \n",
       "4                 4.593310        117.346055    51.606055       10.936453   \n",
       "5                 4.880256         70.488329     4.748329        6.778134   \n",
       "6                 7.820038         68.783638     3.043638       18.619139   \n",
       "7                22.415872         80.680549    14.940549       86.214891   \n",
       "8                 7.500467         29.470106    36.269894        7.426205   \n",
       "9                12.968593         24.509770    41.230230       10.458543   \n",
       "10               14.644511         18.472065    47.267935       13.193253   \n",
       "11                8.583356        141.527841     9.327841        5.610037   \n",
       "12                6.658686        130.675959     1.524041        9.121488   \n",
       "13                5.821151        120.221013    11.978987        4.850959   \n",
       "14               23.025872         91.294037    40.905963       21.519507   \n",
       "15                4.287773         95.218625    36.981375        3.573144   \n",
       "16                7.760058         90.221503    41.978497        4.217423   \n",
       "17               10.579986         86.477715    45.722285        3.792110   \n",
       "18                5.322875         57.116021    75.083979        4.510911   \n",
       "19               10.224094         40.279138    91.920862        4.733377   \n",
       "20               12.301711         28.606743   103.593257        5.395487   \n",
       "21               18.701749         18.551207   113.648793        9.122804   \n",
       "22               15.189486        155.122113   113.162113        4.931651   \n",
       "23               14.379447        142.317225   100.357225        3.305620   \n",
       "24                8.387163        152.212824   110.252824        2.224712   \n",
       "25                8.175292        139.862413    97.902413        2.145746   \n",
       "26                6.074084        135.200101    93.240101        1.886362   \n",
       "27               20.726285         99.862255    57.902255        5.220727   \n",
       "28                8.406343        113.484978    71.524978        2.532031   \n",
       "29                4.221670        108.220359    66.260359        1.716126   \n",
       "...                    ...               ...          ...             ...   \n",
       "254851            3.595998        115.709954    74.459954        1.137974   \n",
       "254852            4.726616         86.968099    45.718099        2.351550   \n",
       "254853            5.793962         74.380608    33.130608        1.485631   \n",
       "254854            4.249859         45.476659     4.226659        1.995239   \n",
       "254855            5.701903         41.658574     0.408574        3.354061   \n",
       "254856            7.616305         26.094045    15.155955        3.430768   \n",
       "254857           11.382812         16.747457    24.502543        3.387742   \n",
       "254858           17.451470         19.307090    21.942910       15.175191   \n",
       "254859           16.725696        161.164236   119.924236       18.180104   \n",
       "254860           13.379256        112.731867    71.491867       11.945765   \n",
       "254861            5.419096        133.205419    91.965419        1.589178   \n",
       "254862            4.090880        114.246904    73.006904        1.420444   \n",
       "254863            4.615734         87.143794    45.903794        1.548904   \n",
       "254864            5.026420         74.774874    33.534874        1.631955   \n",
       "254865            4.188031         53.348996    12.108996        2.420827   \n",
       "254866            6.377625         47.605447     6.365447        2.520800   \n",
       "254867            6.964266         19.371581    21.868419        1.989790   \n",
       "254868           13.787650         28.033376    13.206624        5.892158   \n",
       "254869           19.113474         16.567167    24.672833       40.666967   \n",
       "254870            8.354717        122.834119     4.594119        2.880937   \n",
       "254871            8.143279        119.177615     0.937615        1.801610   \n",
       "254872            7.197555        111.860538     6.379462        6.369518   \n",
       "254873            5.328461        108.264932     9.975068        2.760861   \n",
       "254874            7.137654         81.540680    36.699320        5.287151   \n",
       "254875            6.782463         77.828542    40.411458        2.791137   \n",
       "254876            7.612253         77.095648    41.144352        7.048383   \n",
       "254877            6.126018         72.422797    45.817203       29.171516   \n",
       "254878           18.663526         79.316226    38.923774        9.473871   \n",
       "254879            6.248104         53.460228    64.779772        4.843491   \n",
       "254880           18.918100         29.410547    88.829453        6.082990   \n",
       "\n",
       "                0          1  C  CB  DB  DE  DL  DT  FB  FS  G  ILB  LB  MLB  \\\n",
       "0        3.663441   5.799078  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "1        5.890306   6.356886  0   0   0   0   0   0   0   1  0    0   0    0   \n",
       "2        1.847647   2.866234  0   0   0   0   0   0   0   0  0    0   0    0   \n",
       "3        0.780064   1.449966  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "4        0.580517   0.763217  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "5        0.483011   0.608112  0   0   0   0   0   1   0   0  0    0   0    0   \n",
       "6        3.213612   3.427944  0   0   0   0   0   0   0   0  0    1   0    0   \n",
       "7       18.018529  18.086760  0   0   0   0   0   0   0   0  0    0   0    0   \n",
       "8        1.400000   4.495698  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "9        1.407302   2.715032  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "10       1.941778   2.617365  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "11       2.497759   3.619351  0   0   0   0   0   0   0   0  0    0   0    0   \n",
       "12       0.736817   1.221884  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "13       0.250000   0.593970  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "14      18.326803  18.517241  0   0   0   0   0   0   0   0  0    0   0    0   \n",
       "15       0.603738   1.448102  0   0   0   0   0   1   0   0  0    0   0    0   \n",
       "16       4.009102   4.078946  0   0   0   0   0   0   0   0  0    1   0    0   \n",
       "17       6.737069   6.822815  0   0   0   0   0   0   0   1  0    0   0    0   \n",
       "18       1.500966   3.626307  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "19       3.727144   6.175176  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "20       1.751457   5.693505  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "21       1.971243   7.353700  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "22       1.886054   4.838450  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "23       4.180574   5.462838  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "24       1.403887   2.477781  0   0   0   0   0   0   0   0  0    0   0    0   \n",
       "25       0.840119   2.493772  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "26       0.443847   1.817058  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "27      14.935488  15.503096  0   0   0   0   0   0   0   0  0    0   0    0   \n",
       "28       2.261526   3.952480  0   0   0   0   0   0   0   1  0    0   0    0   \n",
       "29       0.903383   1.981161  0   0   0   0   0   1   0   0  0    0   0    0   \n",
       "...           ...        ... ..  ..  ..  ..  ..  ..  ..  .. ..  ...  ..  ...   \n",
       "254851   1.725399   2.930734  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "254852   0.839345   1.344656  0   0   0   0   0   1   0   0  0    0   0    0   \n",
       "254853   1.719767   2.264906  0   0   0   0   0   0   0   0  0    1   0    0   \n",
       "254854   0.796116   0.857030  0   0   0   0   0   1   0   0  0    0   0    0   \n",
       "254855   1.141271   2.284426  0   0   0   0   0   0   0   0  0    1   0    0   \n",
       "254856   1.536522   3.108456  0   0   0   0   0   0   0   0  0    0   0    0   \n",
       "254857   2.265149   5.056896  0   0   0   0   0   0   0   1  0    0   0    0   \n",
       "254858   1.527121   6.956903  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "254859   2.364762  14.571321  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "254860  10.075560  10.163513  0   0   0   0   0   0   0   1  0    0   0    0   \n",
       "254861   2.477761   3.747693  0   0   0   0   0   0   0   1  0    0   0    0   \n",
       "254862   0.882950   1.710117  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "254863   0.921954   1.153126  0   0   0   0   0   1   0   0  0    0   0    0   \n",
       "254864   1.120893   1.721540  0   0   0   0   0   0   0   0  0    1   0    0   \n",
       "254865   0.632456   0.748131  0   0   0   0   0   1   0   0  0    0   0    0   \n",
       "254866   2.136001   2.586832  0   0   0   0   0   0   0   0  0    1   0    0   \n",
       "254867   1.330038   3.616435  0   0   0   0   0   0   0   0  0    0   0    0   \n",
       "254868   5.483885   7.178649  0   0   0   0   0   0   0   1  0    0   0    0   \n",
       "254869   2.290589   7.272634  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "254870   1.078703   2.601327  0   0   0   0   0   0   0   0  0    1   0    0   \n",
       "254871   1.205031   2.147557  0   0   0   0   0   0   0   1  0    0   0    0   \n",
       "254872   0.886002   1.800250  0   0   0   0   0   0   0   0  0    1   0    0   \n",
       "254873   0.411461   1.028834  0   0   0   1   0   0   0   0  0    0   0    0   \n",
       "254874   0.694622   1.121784  0   0   0   0   0   0   0   0  0    1   0    0   \n",
       "254875   0.749533   0.899389  0   0   0   0   0   1   0   0  0    0   0    0   \n",
       "254876   1.386218   1.699559  0   0   0   0   0   0   0   1  0    0   0    0   \n",
       "254877   0.948472   1.027035  0   0   0   0   0   1   0   0  0    0   0    0   \n",
       "254878  12.196393  12.656275  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "254879   1.132299   2.576296  0   0   0   0   0   0   0   0  0    0   0    0   \n",
       "254880   3.113535  14.526644  0   1   0   0   0   0   0   0  0    0   0    0   \n",
       "\n",
       "        NT  OLB  OT  S  SAF  SS  WR  \n",
       "0        0    0   0  0    0   0   0  \n",
       "1        0    0   0  0    0   0   0  \n",
       "2        0    0   0  0    0   1   0  \n",
       "3        0    0   0  0    0   0   0  \n",
       "4        0    0   0  0    0   0   0  \n",
       "5        0    0   0  0    0   0   0  \n",
       "6        0    0   0  0    0   0   0  \n",
       "7        0    0   0  0    0   1   0  \n",
       "8        0    0   0  0    0   0   0  \n",
       "9        0    0   0  0    0   0   0  \n",
       "10       0    0   0  0    0   0   0  \n",
       "11       0    0   0  0    0   1   0  \n",
       "12       0    0   0  0    0   0   0  \n",
       "13       0    0   0  0    0   0   0  \n",
       "14       0    0   0  0    0   1   0  \n",
       "15       0    0   0  0    0   0   0  \n",
       "16       0    0   0  0    0   0   0  \n",
       "17       0    0   0  0    0   0   0  \n",
       "18       0    0   0  0    0   0   0  \n",
       "19       0    0   0  0    0   0   0  \n",
       "20       0    0   0  0    0   0   0  \n",
       "21       0    0   0  0    0   0   0  \n",
       "22       0    0   0  0    0   0   0  \n",
       "23       0    0   0  0    0   0   0  \n",
       "24       0    0   0  0    0   1   0  \n",
       "25       0    0   0  0    0   0   0  \n",
       "26       0    0   0  0    0   0   0  \n",
       "27       0    0   0  0    0   1   0  \n",
       "28       0    0   0  0    0   0   0  \n",
       "29       0    0   0  0    0   0   0  \n",
       "...     ..  ...  .. ..  ...  ..  ..  \n",
       "254851   0    0   0  0    0   0   0  \n",
       "254852   0    0   0  0    0   0   0  \n",
       "254853   0    0   0  0    0   0   0  \n",
       "254854   0    0   0  0    0   0   0  \n",
       "254855   0    0   0  0    0   0   0  \n",
       "254856   0    1   0  0    0   0   0  \n",
       "254857   0    0   0  0    0   0   0  \n",
       "254858   0    0   0  0    0   0   0  \n",
       "254859   0    0   0  0    0   0   0  \n",
       "254860   0    0   0  0    0   0   0  \n",
       "254861   0    0   0  0    0   0   0  \n",
       "254862   0    0   0  0    0   0   0  \n",
       "254863   0    0   0  0    0   0   0  \n",
       "254864   0    0   0  0    0   0   0  \n",
       "254865   0    0   0  0    0   0   0  \n",
       "254866   0    0   0  0    0   0   0  \n",
       "254867   0    1   0  0    0   0   0  \n",
       "254868   0    0   0  0    0   0   0  \n",
       "254869   0    0   0  0    0   0   0  \n",
       "254870   0    0   0  0    0   0   0  \n",
       "254871   0    0   0  0    0   0   0  \n",
       "254872   0    0   0  0    0   0   0  \n",
       "254873   0    0   0  0    0   0   0  \n",
       "254874   0    0   0  0    0   0   0  \n",
       "254875   0    0   0  0    0   0   0  \n",
       "254876   0    0   0  0    0   0   0  \n",
       "254877   0    0   0  0    0   0   0  \n",
       "254878   0    0   0  0    0   0   0  \n",
       "254879   0    1   0  0    0   0   0  \n",
       "254880   0    0   0  0    0   0   0  \n",
       "\n",
       "[254881 rows x 39 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 330)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offender_players = [offender.drop('PlayId',axis = 1).iloc[np.arange(k, len(offender), 10)].reset_index(drop = True) for k in range(10)]\n",
    "offender_players = np.hstack([t.values for t in offender_players])\n",
    "offender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 418)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defender_players = [defender.drop('PlayId',axis = 1).iloc[np.arange(k, len(defender), 11)].reset_index(drop = True) for k in range(11)]\n",
    "defender_players = np.hstack([t.values for t in defender_players])\n",
    "defender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([rusher.drop('PlayId',axis = 1).values,game.drop('PlayId',axis = 1).values,offender_players,defender_players])\n",
    "Y = np.zeros((y.Yards.shape[0], 199))\n",
    "for idx, target in enumerate(list(y.Yards)):\n",
    "    Y[idx][99 + target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(X)))\n",
    "print(np.all(np.isfinite(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(Callback):\n",
    "    def __init__(self, model, callbacks, data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.callbacks = callbacks\n",
    "        self.data = data\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_end(logs)\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "#         X_train, y_train = self.data[0][0], self.data[0][1]\n",
    "#         y_pred = self.model.predict(X_train)\n",
    "#         y_true = np.clip(np.cumsum(y_train, axis=1), 0, 1)\n",
    "#         y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "#         tr_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_train.shape[0])\n",
    "#         tr_s = np.round(tr_s, 6)\n",
    "        logs['tr_CRPS'] = 0\n",
    "\n",
    "        X_valid, y_valid = self.data[1][0], self.data[1][1]\n",
    "\n",
    "        y_pred = self.model.predict(X_valid)\n",
    "        y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "        val_s = np.round(val_s, 6)\n",
    "        logs['val_CRPS'] = val_s\n",
    "        print('tr CRPS', 'Grr', 'val CRPS', val_s)\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_end(batch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(GaussianNoise(0.25))\n",
    "    model.add(Dense(199, activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(GaussianNoise(0.1))\n",
    "    model.add(Dense(199, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=[])\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 19309 samples, validate on 3862 samples\n",
      "Epoch 1/250\n",
      "19309/19309 [==============================] - ETA: 49s - loss: 5.45 - ETA: 9s - loss: 5.5047 - ETA: 5s - loss: 5.463 - ETA: 4s - loss: 5.444 - ETA: 3s - loss: 5.421 - ETA: 3s - loss: 5.395 - ETA: 2s - loss: 5.369 - ETA: 2s - loss: 5.338 - ETA: 2s - loss: 5.306 - ETA: 2s - loss: 5.282 - ETA: 1s - loss: 5.247 - ETA: 1s - loss: 5.223 - ETA: 1s - loss: 5.195 - ETA: 1s - loss: 5.158 - ETA: 1s - loss: 5.130 - ETA: 1s - loss: 5.105 - ETA: 1s - loss: 5.075 - ETA: 1s - loss: 5.048 - ETA: 1s - loss: 5.013 - ETA: 0s - loss: 4.983 - ETA: 0s - loss: 4.960 - ETA: 0s - loss: 4.926 - ETA: 0s - loss: 4.890 - ETA: 0s - loss: 4.858 - ETA: 0s - loss: 4.827 - ETA: 0s - loss: 4.798 - ETA: 0s - loss: 4.760 - ETA: 0s - loss: 4.725 - ETA: 0s - loss: 4.695 - ETA: 0s - loss: 4.657 - ETA: 0s - loss: 4.619 - ETA: 0s - loss: 4.588 - ETA: 0s - loss: 4.551 - ETA: 0s - loss: 4.517 - 2s 118us/step - loss: 4.5055 - val_loss: 3.2424\n",
      "tr CRPS Grr val CRPS 0.019708\n",
      "Epoch 2/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 3.278 - ETA: 1s - loss: 3.232 - ETA: 1s - loss: 3.189 - ETA: 1s - loss: 3.170 - ETA: 1s - loss: 3.120 - ETA: 1s - loss: 3.090 - ETA: 1s - loss: 3.083 - ETA: 1s - loss: 3.065 - ETA: 1s - loss: 3.059 - ETA: 1s - loss: 3.042 - ETA: 1s - loss: 3.032 - ETA: 1s - loss: 3.022 - ETA: 1s - loss: 3.023 - ETA: 1s - loss: 3.026 - ETA: 1s - loss: 3.018 - ETA: 0s - loss: 3.007 - ETA: 0s - loss: 2.998 - ETA: 0s - loss: 2.992 - ETA: 0s - loss: 2.983 - ETA: 0s - loss: 2.974 - ETA: 0s - loss: 2.967 - ETA: 0s - loss: 2.959 - ETA: 0s - loss: 2.952 - ETA: 0s - loss: 2.949 - ETA: 0s - loss: 2.946 - ETA: 0s - loss: 2.943 - ETA: 0s - loss: 2.936 - ETA: 0s - loss: 2.936 - ETA: 0s - loss: 2.934 - ETA: 0s - loss: 2.932 - ETA: 0s - loss: 2.930 - ETA: 0s - loss: 2.927 - ETA: 0s - loss: 2.924 - ETA: 0s - loss: 2.921 - 2s 104us/step - loss: 2.9216 - val_loss: 2.8385\n",
      "tr CRPS Grr val CRPS 0.013071\n",
      "Epoch 3/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.753 - ETA: 1s - loss: 2.771 - ETA: 1s - loss: 2.787 - ETA: 1s - loss: 2.787 - ETA: 1s - loss: 2.781 - ETA: 1s - loss: 2.791 - ETA: 1s - loss: 2.784 - ETA: 1s - loss: 2.776 - ETA: 1s - loss: 2.776 - ETA: 1s - loss: 2.761 - ETA: 1s - loss: 2.760 - ETA: 1s - loss: 2.755 - ETA: 1s - loss: 2.750 - ETA: 1s - loss: 2.752 - ETA: 1s - loss: 2.747 - ETA: 0s - loss: 2.748 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.747 - ETA: 0s - loss: 2.747 - ETA: 0s - loss: 2.746 - ETA: 0s - loss: 2.746 - ETA: 0s - loss: 2.743 - ETA: 0s - loss: 2.741 - ETA: 0s - loss: 2.743 - ETA: 0s - loss: 2.741 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.748 - ETA: 0s - loss: 2.748 - ETA: 0s - loss: 2.747 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.744 - 2s 100us/step - loss: 2.7452 - val_loss: 2.8065\n",
      "tr CRPS Grr val CRPS 0.012925\n",
      "Epoch 4/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.595 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.647 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.678 - ETA: 1s - loss: 2.675 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.679 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.688 - 2s 100us/step - loss: 2.6881 - val_loss: 2.8027\n",
      "tr CRPS Grr val CRPS 0.012857\n",
      "Epoch 5/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.613 - ETA: 1s - loss: 2.536 - ETA: 1s - loss: 2.588 - ETA: 1s - loss: 2.598 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.631 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.653 - ETA: 0s - loss: 2.653 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.653 - 2s 100us/step - loss: 2.6545 - val_loss: 2.8074\n",
      "tr CRPS Grr val CRPS 0.012868\n",
      "Epoch 6/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.539 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.693 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.609 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.604 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.620 - 2s 100us/step - loss: 2.6212 - val_loss: 2.8156\n",
      "tr CRPS Grr val CRPS 0.012887\n",
      "Epoch 7/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.433 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.539 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.575 - ETA: 1s - loss: 2.572 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.590 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.592 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.592 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.598 - 2s 102us/step - loss: 2.5982 - val_loss: 2.8217\n",
      "tr CRPS Grr val CRPS 0.01285\n",
      "Epoch 8/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.423 - ETA: 1s - loss: 2.504 - ETA: 1s - loss: 2.496 - ETA: 1s - loss: 2.482 - ETA: 1s - loss: 2.481 - ETA: 1s - loss: 2.484 - ETA: 1s - loss: 2.499 - ETA: 1s - loss: 2.504 - ETA: 1s - loss: 2.510 - ETA: 1s - loss: 2.521 - ETA: 1s - loss: 2.523 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.527 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.541 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.545 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.561 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.567 - 2s 100us/step - loss: 2.5696 - val_loss: 2.8249\n",
      "tr CRPS Grr val CRPS 0.012821\n",
      "Epoch 9/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19309/19309 [==============================] - ETA: 1s - loss: 2.471 - ETA: 1s - loss: 2.493 - ETA: 1s - loss: 2.492 - ETA: 1s - loss: 2.497 - ETA: 1s - loss: 2.492 - ETA: 1s - loss: 2.490 - ETA: 1s - loss: 2.487 - ETA: 1s - loss: 2.494 - ETA: 1s - loss: 2.496 - ETA: 1s - loss: 2.504 - ETA: 1s - loss: 2.504 - ETA: 1s - loss: 2.509 - ETA: 1s - loss: 2.508 - ETA: 1s - loss: 2.511 - ETA: 1s - loss: 2.513 - ETA: 0s - loss: 2.511 - ETA: 0s - loss: 2.518 - ETA: 0s - loss: 2.517 - ETA: 0s - loss: 2.514 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.520 - ETA: 0s - loss: 2.522 - ETA: 0s - loss: 2.524 - ETA: 0s - loss: 2.528 - ETA: 0s - loss: 2.529 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.533 - ETA: 0s - loss: 2.534 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.539 - 2s 100us/step - loss: 2.5401 - val_loss: 2.8426\n",
      "tr CRPS Grr val CRPS 0.012834\n",
      "Epoch 10/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.421 - ETA: 1s - loss: 2.361 - ETA: 1s - loss: 2.433 - ETA: 1s - loss: 2.452 - ETA: 1s - loss: 2.447 - ETA: 1s - loss: 2.455 - ETA: 1s - loss: 2.469 - ETA: 1s - loss: 2.475 - ETA: 1s - loss: 2.473 - ETA: 1s - loss: 2.485 - ETA: 1s - loss: 2.483 - ETA: 1s - loss: 2.486 - ETA: 1s - loss: 2.488 - ETA: 1s - loss: 2.488 - ETA: 0s - loss: 2.494 - ETA: 0s - loss: 2.495 - ETA: 0s - loss: 2.494 - ETA: 0s - loss: 2.501 - ETA: 0s - loss: 2.502 - ETA: 0s - loss: 2.504 - ETA: 0s - loss: 2.505 - ETA: 0s - loss: 2.504 - ETA: 0s - loss: 2.505 - ETA: 0s - loss: 2.509 - ETA: 0s - loss: 2.510 - ETA: 0s - loss: 2.512 - ETA: 0s - loss: 2.514 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.524 - ETA: 0s - loss: 2.524 - ETA: 0s - loss: 2.523 - ETA: 0s - loss: 2.525 - 2s 97us/step - loss: 2.5253 - val_loss: 2.8495\n",
      "tr CRPS Grr val CRPS 0.012868\n",
      "Epoch 11/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.505 - ETA: 1s - loss: 2.391 - ETA: 1s - loss: 2.413 - ETA: 1s - loss: 2.431 - ETA: 1s - loss: 2.442 - ETA: 1s - loss: 2.448 - ETA: 1s - loss: 2.446 - ETA: 1s - loss: 2.456 - ETA: 1s - loss: 2.462 - ETA: 1s - loss: 2.464 - ETA: 1s - loss: 2.462 - ETA: 1s - loss: 2.473 - ETA: 1s - loss: 2.477 - ETA: 1s - loss: 2.474 - ETA: 0s - loss: 2.479 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.474 - ETA: 0s - loss: 2.475 - ETA: 0s - loss: 2.477 - ETA: 0s - loss: 2.479 - ETA: 0s - loss: 2.481 - ETA: 0s - loss: 2.482 - ETA: 0s - loss: 2.480 - ETA: 0s - loss: 2.481 - ETA: 0s - loss: 2.484 - ETA: 0s - loss: 2.488 - ETA: 0s - loss: 2.486 - ETA: 0s - loss: 2.488 - ETA: 0s - loss: 2.490 - ETA: 0s - loss: 2.492 - ETA: 0s - loss: 2.493 - ETA: 0s - loss: 2.493 - ETA: 0s - loss: 2.497 - 2s 100us/step - loss: 2.4974 - val_loss: 2.8645\n",
      "tr CRPS Grr val CRPS 0.012871\n",
      "Epoch 12/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.334 - ETA: 1s - loss: 2.380 - ETA: 1s - loss: 2.403 - ETA: 1s - loss: 2.418 - ETA: 1s - loss: 2.440 - ETA: 1s - loss: 2.435 - ETA: 1s - loss: 2.435 - ETA: 1s - loss: 2.443 - ETA: 1s - loss: 2.439 - ETA: 1s - loss: 2.440 - ETA: 1s - loss: 2.439 - ETA: 1s - loss: 2.447 - ETA: 1s - loss: 2.448 - ETA: 1s - loss: 2.455 - ETA: 1s - loss: 2.458 - ETA: 0s - loss: 2.459 - ETA: 0s - loss: 2.462 - ETA: 0s - loss: 2.464 - ETA: 0s - loss: 2.462 - ETA: 0s - loss: 2.463 - ETA: 0s - loss: 2.462 - ETA: 0s - loss: 2.464 - ETA: 0s - loss: 2.466 - ETA: 0s - loss: 2.466 - ETA: 0s - loss: 2.467 - ETA: 0s - loss: 2.470 - ETA: 0s - loss: 2.471 - ETA: 0s - loss: 2.472 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.475 - ETA: 0s - loss: 2.479 - ETA: 0s - loss: 2.479 - ETA: 0s - loss: 2.481 - 2s 100us/step - loss: 2.4815 - val_loss: 2.8607\n",
      "tr CRPS Grr val CRPS 0.012828\n",
      "Epoch 13/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.282 - ETA: 1s - loss: 2.340 - ETA: 1s - loss: 2.352 - ETA: 1s - loss: 2.363 - ETA: 1s - loss: 2.369 - ETA: 1s - loss: 2.386 - ETA: 1s - loss: 2.391 - ETA: 1s - loss: 2.391 - ETA: 1s - loss: 2.397 - ETA: 1s - loss: 2.404 - ETA: 1s - loss: 2.411 - ETA: 1s - loss: 2.416 - ETA: 1s - loss: 2.417 - ETA: 1s - loss: 2.426 - ETA: 1s - loss: 2.424 - ETA: 1s - loss: 2.428 - ETA: 0s - loss: 2.429 - ETA: 0s - loss: 2.430 - ETA: 0s - loss: 2.432 - ETA: 0s - loss: 2.434 - ETA: 0s - loss: 2.438 - ETA: 0s - loss: 2.440 - ETA: 0s - loss: 2.440 - ETA: 0s - loss: 2.442 - ETA: 0s - loss: 2.446 - ETA: 0s - loss: 2.450 - ETA: 0s - loss: 2.451 - ETA: 0s - loss: 2.452 - ETA: 0s - loss: 2.455 - ETA: 0s - loss: 2.458 - ETA: 0s - loss: 2.459 - ETA: 0s - loss: 2.462 - ETA: 0s - loss: 2.463 - ETA: 0s - loss: 2.465 - 2s 101us/step - loss: 2.4650 - val_loss: 2.8766\n",
      "tr CRPS Grr val CRPS 0.012842\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00013: early stopping\n",
      "1\n",
      "Train on 19309 samples, validate on 3862 samples\n",
      "Epoch 1/250\n",
      "19309/19309 [==============================] - ETA: 53s - loss: 5.54 - ETA: 10s - loss: 5.54 - ETA: 6s - loss: 5.5235 - ETA: 4s - loss: 5.466 - ETA: 3s - loss: 5.431 - ETA: 3s - loss: 5.389 - ETA: 2s - loss: 5.358 - ETA: 2s - loss: 5.333 - ETA: 2s - loss: 5.308 - ETA: 2s - loss: 5.276 - ETA: 1s - loss: 5.242 - ETA: 1s - loss: 5.213 - ETA: 1s - loss: 5.192 - ETA: 1s - loss: 5.163 - ETA: 1s - loss: 5.132 - ETA: 1s - loss: 5.101 - ETA: 1s - loss: 5.081 - ETA: 1s - loss: 5.053 - ETA: 1s - loss: 5.026 - ETA: 0s - loss: 4.992 - ETA: 0s - loss: 4.958 - ETA: 0s - loss: 4.925 - ETA: 0s - loss: 4.904 - ETA: 0s - loss: 4.873 - ETA: 0s - loss: 4.846 - ETA: 0s - loss: 4.817 - ETA: 0s - loss: 4.780 - ETA: 0s - loss: 4.745 - ETA: 0s - loss: 4.708 - ETA: 0s - loss: 4.676 - ETA: 0s - loss: 4.647 - ETA: 0s - loss: 4.613 - ETA: 0s - loss: 4.576 - ETA: 0s - loss: 4.539 - 2s 120us/step - loss: 4.5266 - val_loss: 3.2502\n",
      "tr CRPS Grr val CRPS 0.020083\n",
      "Epoch 2/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 3.213 - ETA: 1s - loss: 3.110 - ETA: 1s - loss: 3.110 - ETA: 1s - loss: 3.101 - ETA: 1s - loss: 3.098 - ETA: 1s - loss: 3.078 - ETA: 1s - loss: 3.062 - ETA: 1s - loss: 3.064 - ETA: 1s - loss: 3.058 - ETA: 1s - loss: 3.050 - ETA: 1s - loss: 3.036 - ETA: 1s - loss: 3.031 - ETA: 1s - loss: 3.020 - ETA: 1s - loss: 3.015 - ETA: 1s - loss: 3.007 - ETA: 1s - loss: 2.999 - ETA: 0s - loss: 2.990 - ETA: 0s - loss: 2.984 - ETA: 0s - loss: 2.978 - ETA: 0s - loss: 2.976 - ETA: 0s - loss: 2.972 - ETA: 0s - loss: 2.963 - ETA: 0s - loss: 2.957 - ETA: 0s - loss: 2.952 - ETA: 0s - loss: 2.946 - ETA: 0s - loss: 2.941 - ETA: 0s - loss: 2.936 - ETA: 0s - loss: 2.935 - ETA: 0s - loss: 2.927 - ETA: 0s - loss: 2.923 - ETA: 0s - loss: 2.918 - ETA: 0s - loss: 2.920 - ETA: 0s - loss: 2.918 - ETA: 0s - loss: 2.916 - 2s 102us/step - loss: 2.9162 - val_loss: 2.8202\n",
      "tr CRPS Grr val CRPS 0.013413\n",
      "Epoch 3/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.743 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.715 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.706 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.719 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.729 - ETA: 1s - loss: 2.735 - ETA: 1s - loss: 2.738 - ETA: 1s - loss: 2.743 - ETA: 1s - loss: 2.742 - ETA: 0s - loss: 2.748 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.751 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.754 - ETA: 0s - loss: 2.751 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.748 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.751 - ETA: 0s - loss: 2.753 - ETA: 0s - loss: 2.752 - ETA: 0s - loss: 2.752 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.752 - 2s 103us/step - loss: 2.7521 - val_loss: 2.8002\n",
      "tr CRPS Grr val CRPS 0.013262\n",
      "Epoch 4/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19309/19309 [==============================] - ETA: 1s - loss: 2.647 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.657 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.674 - ETA: 1s - loss: 2.674 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.690 - 2s 101us/step - loss: 2.6900 - val_loss: 2.7954\n",
      "tr CRPS Grr val CRPS 0.013209\n",
      "Epoch 5/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.554 - ETA: 1s - loss: 2.522 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.598 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.625 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.647 - 2s 104us/step - loss: 2.6473 - val_loss: 2.8013\n",
      "tr CRPS Grr val CRPS 0.013212\n",
      "Epoch 6/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.719 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.585 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.598 - ETA: 1s - loss: 2.598 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.600 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.620 - 2s 106us/step - loss: 2.6203 - val_loss: 2.8114\n",
      "tr CRPS Grr val CRPS 0.013231\n",
      "Epoch 7/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.623 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.585 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.587 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.586 - ETA: 0s - loss: 2.581 - ETA: 0s - loss: 2.579 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.598 - 2s 101us/step - loss: 2.5983 - val_loss: 2.8183\n",
      "tr CRPS Grr val CRPS 0.013231\n",
      "Epoch 8/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.470 - ETA: 1s - loss: 2.490 - ETA: 1s - loss: 2.524 - ETA: 1s - loss: 2.512 - ETA: 1s - loss: 2.519 - ETA: 1s - loss: 2.526 - ETA: 1s - loss: 2.538 - ETA: 1s - loss: 2.543 - ETA: 1s - loss: 2.546 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.548 - ETA: 1s - loss: 2.550 - ETA: 0s - loss: 2.548 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.557 - ETA: 0s - loss: 2.557 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.559 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.559 - ETA: 0s - loss: 2.561 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.566 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.566 - 2s 98us/step - loss: 2.5670 - val_loss: 2.8353\n",
      "tr CRPS Grr val CRPS 0.013233\n",
      "Epoch 9/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.438 - ETA: 1s - loss: 2.525 - ETA: 1s - loss: 2.501 - ETA: 1s - loss: 2.521 - ETA: 1s - loss: 2.518 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.532 - ETA: 1s - loss: 2.531 - ETA: 1s - loss: 2.521 - ETA: 1s - loss: 2.517 - ETA: 1s - loss: 2.521 - ETA: 1s - loss: 2.516 - ETA: 1s - loss: 2.523 - ETA: 1s - loss: 2.522 - ETA: 0s - loss: 2.525 - ETA: 0s - loss: 2.526 - ETA: 0s - loss: 2.525 - ETA: 0s - loss: 2.523 - ETA: 0s - loss: 2.524 - ETA: 0s - loss: 2.520 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.518 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.524 - ETA: 0s - loss: 2.526 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.534 - ETA: 0s - loss: 2.535 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.539 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.543 - ETA: 0s - loss: 2.544 - 2s 96us/step - loss: 2.5450 - val_loss: 2.8291\n",
      "tr CRPS Grr val CRPS 0.013212\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00009: early stopping\n",
      "2\n",
      "Train on 19309 samples, validate on 3862 samples\n",
      "Epoch 1/250\n",
      "19309/19309 [==============================] - ETA: 48s - loss: 5.57 - ETA: 9s - loss: 5.5113 - ETA: 6s - loss: 5.477 - ETA: 4s - loss: 5.449 - ETA: 3s - loss: 5.426 - ETA: 3s - loss: 5.398 - ETA: 3s - loss: 5.370 - ETA: 2s - loss: 5.348 - ETA: 2s - loss: 5.321 - ETA: 2s - loss: 5.288 - ETA: 2s - loss: 5.263 - ETA: 1s - loss: 5.238 - ETA: 1s - loss: 5.212 - ETA: 1s - loss: 5.180 - ETA: 1s - loss: 5.149 - ETA: 1s - loss: 5.124 - ETA: 1s - loss: 5.103 - ETA: 1s - loss: 5.074 - ETA: 1s - loss: 5.050 - ETA: 1s - loss: 5.020 - ETA: 0s - loss: 4.989 - ETA: 0s - loss: 4.963 - ETA: 0s - loss: 4.928 - ETA: 0s - loss: 4.894 - ETA: 0s - loss: 4.857 - ETA: 0s - loss: 4.823 - ETA: 0s - loss: 4.786 - ETA: 0s - loss: 4.750 - ETA: 0s - loss: 4.721 - ETA: 0s - loss: 4.685 - ETA: 0s - loss: 4.645 - ETA: 0s - loss: 4.611 - ETA: 0s - loss: 4.574 - ETA: 0s - loss: 4.540 - 2s 118us/step - loss: 4.5332 - val_loss: 3.3048\n",
      "tr CRPS Grr val CRPS 0.0205\n",
      "Epoch 2/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 3.328 - ETA: 1s - loss: 3.192 - ETA: 1s - loss: 3.168 - ETA: 1s - loss: 3.148 - ETA: 1s - loss: 3.136 - ETA: 1s - loss: 3.144 - ETA: 1s - loss: 3.116 - ETA: 1s - loss: 3.103 - ETA: 1s - loss: 3.098 - ETA: 1s - loss: 3.085 - ETA: 1s - loss: 3.070 - ETA: 1s - loss: 3.068 - ETA: 1s - loss: 3.053 - ETA: 1s - loss: 3.039 - ETA: 1s - loss: 3.028 - ETA: 0s - loss: 3.020 - ETA: 0s - loss: 3.014 - ETA: 0s - loss: 3.008 - ETA: 0s - loss: 3.001 - ETA: 0s - loss: 2.989 - ETA: 0s - loss: 2.981 - ETA: 0s - loss: 2.975 - ETA: 0s - loss: 2.971 - ETA: 0s - loss: 2.968 - ETA: 0s - loss: 2.960 - ETA: 0s - loss: 2.954 - ETA: 0s - loss: 2.949 - ETA: 0s - loss: 2.946 - ETA: 0s - loss: 2.943 - ETA: 0s - loss: 2.936 - ETA: 0s - loss: 2.936 - ETA: 0s - loss: 2.933 - ETA: 0s - loss: 2.930 - 2s 100us/step - loss: 2.9308 - val_loss: 2.8394\n",
      "tr CRPS Grr val CRPS 0.013237\n",
      "Epoch 3/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19309/19309 [==============================] - ETA: 1s - loss: 2.828 - ETA: 1s - loss: 2.760 - ETA: 1s - loss: 2.704 - ETA: 1s - loss: 2.729 - ETA: 1s - loss: 2.725 - ETA: 1s - loss: 2.725 - ETA: 1s - loss: 2.735 - ETA: 1s - loss: 2.736 - ETA: 1s - loss: 2.727 - ETA: 1s - loss: 2.726 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.729 - ETA: 0s - loss: 2.731 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.731 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.732 - ETA: 0s - loss: 2.731 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.735 - ETA: 0s - loss: 2.738 - ETA: 0s - loss: 2.738 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.739 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.742 - 2s 98us/step - loss: 2.7426 - val_loss: 2.8193\n",
      "tr CRPS Grr val CRPS 0.013078\n",
      "Epoch 4/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.499 - ETA: 1s - loss: 2.591 - ETA: 1s - loss: 2.572 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.670 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.688 - 2s 100us/step - loss: 2.6872 - val_loss: 2.8113\n",
      "tr CRPS Grr val CRPS 0.013064\n",
      "Epoch 5/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.537 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.630 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.653 - 2s 98us/step - loss: 2.6539 - val_loss: 2.8229\n",
      "tr CRPS Grr val CRPS 0.01307\n",
      "Epoch 6/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.382 - ETA: 1s - loss: 2.484 - ETA: 1s - loss: 2.510 - ETA: 1s - loss: 2.523 - ETA: 1s - loss: 2.533 - ETA: 1s - loss: 2.550 - ETA: 1s - loss: 2.558 - ETA: 1s - loss: 2.569 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.572 - ETA: 1s - loss: 2.571 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.575 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.586 - ETA: 0s - loss: 2.592 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.621 - 2s 98us/step - loss: 2.6217 - val_loss: 2.8232\n",
      "tr CRPS Grr val CRPS 0.013014\n",
      "Epoch 7/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.571 - ETA: 1s - loss: 2.526 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.571 - ETA: 1s - loss: 2.575 - ETA: 1s - loss: 2.575 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.580 - ETA: 0s - loss: 2.581 - ETA: 0s - loss: 2.586 - ETA: 0s - loss: 2.586 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.586 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.594 - 2s 98us/step - loss: 2.5946 - val_loss: 2.8341\n",
      "tr CRPS Grr val CRPS 0.012986\n",
      "Epoch 8/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.629 - ETA: 1s - loss: 2.485 - ETA: 1s - loss: 2.499 - ETA: 1s - loss: 2.527 - ETA: 1s - loss: 2.526 - ETA: 1s - loss: 2.524 - ETA: 1s - loss: 2.521 - ETA: 1s - loss: 2.532 - ETA: 1s - loss: 2.537 - ETA: 1s - loss: 2.542 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.538 - ETA: 1s - loss: 2.549 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.549 - ETA: 1s - loss: 2.552 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.561 - ETA: 0s - loss: 2.562 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.566 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.570 - 2s 102us/step - loss: 2.5707 - val_loss: 2.8397\n",
      "tr CRPS Grr val CRPS 0.012989\n",
      "Epoch 9/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.523 - ETA: 1s - loss: 2.474 - ETA: 1s - loss: 2.496 - ETA: 1s - loss: 2.493 - ETA: 1s - loss: 2.509 - ETA: 1s - loss: 2.517 - ETA: 1s - loss: 2.508 - ETA: 1s - loss: 2.506 - ETA: 1s - loss: 2.510 - ETA: 1s - loss: 2.512 - ETA: 1s - loss: 2.508 - ETA: 1s - loss: 2.513 - ETA: 1s - loss: 2.516 - ETA: 1s - loss: 2.518 - ETA: 0s - loss: 2.521 - ETA: 0s - loss: 2.521 - ETA: 0s - loss: 2.518 - ETA: 0s - loss: 2.518 - ETA: 0s - loss: 2.520 - ETA: 0s - loss: 2.523 - ETA: 0s - loss: 2.528 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.538 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.543 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.545 - ETA: 0s - loss: 2.546 - ETA: 0s - loss: 2.546 - ETA: 0s - loss: 2.549 - 2s 99us/step - loss: 2.5499 - val_loss: 2.8453\n",
      "tr CRPS Grr val CRPS 0.013007\n",
      "Epoch 10/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.314 - ETA: 1s - loss: 2.479 - ETA: 1s - loss: 2.474 - ETA: 1s - loss: 2.470 - ETA: 1s - loss: 2.439 - ETA: 1s - loss: 2.443 - ETA: 1s - loss: 2.459 - ETA: 1s - loss: 2.465 - ETA: 1s - loss: 2.457 - ETA: 1s - loss: 2.467 - ETA: 1s - loss: 2.465 - ETA: 1s - loss: 2.475 - ETA: 1s - loss: 2.480 - ETA: 1s - loss: 2.487 - ETA: 0s - loss: 2.495 - ETA: 0s - loss: 2.499 - ETA: 0s - loss: 2.496 - ETA: 0s - loss: 2.497 - ETA: 0s - loss: 2.500 - ETA: 0s - loss: 2.498 - ETA: 0s - loss: 2.503 - ETA: 0s - loss: 2.505 - ETA: 0s - loss: 2.503 - ETA: 0s - loss: 2.502 - ETA: 0s - loss: 2.503 - ETA: 0s - loss: 2.504 - ETA: 0s - loss: 2.506 - ETA: 0s - loss: 2.507 - ETA: 0s - loss: 2.506 - ETA: 0s - loss: 2.510 - ETA: 0s - loss: 2.513 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.521 - 2s 98us/step - loss: 2.5220 - val_loss: 2.8628\n",
      "tr CRPS Grr val CRPS 0.013037\n",
      "Epoch 11/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19309/19309 [==============================] - ETA: 2s - loss: 2.313 - ETA: 1s - loss: 2.408 - ETA: 1s - loss: 2.428 - ETA: 1s - loss: 2.423 - ETA: 1s - loss: 2.416 - ETA: 1s - loss: 2.434 - ETA: 1s - loss: 2.431 - ETA: 1s - loss: 2.439 - ETA: 1s - loss: 2.456 - ETA: 1s - loss: 2.463 - ETA: 1s - loss: 2.462 - ETA: 1s - loss: 2.465 - ETA: 1s - loss: 2.471 - ETA: 1s - loss: 2.472 - ETA: 1s - loss: 2.471 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.474 - ETA: 0s - loss: 2.472 - ETA: 0s - loss: 2.474 - ETA: 0s - loss: 2.476 - ETA: 0s - loss: 2.479 - ETA: 0s - loss: 2.480 - ETA: 0s - loss: 2.484 - ETA: 0s - loss: 2.487 - ETA: 0s - loss: 2.489 - ETA: 0s - loss: 2.491 - ETA: 0s - loss: 2.491 - ETA: 0s - loss: 2.492 - ETA: 0s - loss: 2.493 - ETA: 0s - loss: 2.496 - ETA: 0s - loss: 2.496 - ETA: 0s - loss: 2.498 - ETA: 0s - loss: 2.498 - 2s 98us/step - loss: 2.4996 - val_loss: 2.8711\n",
      "tr CRPS Grr val CRPS 0.013028\n",
      "Epoch 12/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.499 - ETA: 1s - loss: 2.456 - ETA: 1s - loss: 2.456 - ETA: 1s - loss: 2.415 - ETA: 1s - loss: 2.423 - ETA: 1s - loss: 2.435 - ETA: 1s - loss: 2.449 - ETA: 1s - loss: 2.451 - ETA: 1s - loss: 2.450 - ETA: 1s - loss: 2.448 - ETA: 1s - loss: 2.455 - ETA: 1s - loss: 2.460 - ETA: 1s - loss: 2.457 - ETA: 1s - loss: 2.463 - ETA: 0s - loss: 2.469 - ETA: 0s - loss: 2.470 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.474 - ETA: 0s - loss: 2.476 - ETA: 0s - loss: 2.476 - ETA: 0s - loss: 2.471 - ETA: 0s - loss: 2.469 - ETA: 0s - loss: 2.470 - ETA: 0s - loss: 2.475 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.476 - ETA: 0s - loss: 2.477 - ETA: 0s - loss: 2.479 - ETA: 0s - loss: 2.480 - ETA: 0s - loss: 2.482 - ETA: 0s - loss: 2.483 - 2s 100us/step - loss: 2.4861 - val_loss: 2.8755\n",
      "tr CRPS Grr val CRPS 0.013018\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00012: early stopping\n",
      "3\n",
      "Train on 19309 samples, validate on 3862 samples\n",
      "Epoch 1/250\n",
      "19309/19309 [==============================] - ETA: 52s - loss: 5.47 - ETA: 12s - loss: 5.49 - ETA: 7s - loss: 5.5066 - ETA: 5s - loss: 5.483 - ETA: 4s - loss: 5.458 - ETA: 4s - loss: 5.449 - ETA: 3s - loss: 5.419 - ETA: 3s - loss: 5.388 - ETA: 2s - loss: 5.365 - ETA: 2s - loss: 5.323 - ETA: 2s - loss: 5.292 - ETA: 2s - loss: 5.265 - ETA: 2s - loss: 5.236 - ETA: 1s - loss: 5.212 - ETA: 1s - loss: 5.190 - ETA: 1s - loss: 5.160 - ETA: 1s - loss: 5.131 - ETA: 1s - loss: 5.094 - ETA: 1s - loss: 5.064 - ETA: 1s - loss: 5.038 - ETA: 1s - loss: 5.009 - ETA: 1s - loss: 4.982 - ETA: 1s - loss: 4.954 - ETA: 0s - loss: 4.920 - ETA: 0s - loss: 4.886 - ETA: 0s - loss: 4.856 - ETA: 0s - loss: 4.818 - ETA: 0s - loss: 4.794 - ETA: 0s - loss: 4.763 - ETA: 0s - loss: 4.726 - ETA: 0s - loss: 4.698 - ETA: 0s - loss: 4.660 - ETA: 0s - loss: 4.629 - ETA: 0s - loss: 4.593 - ETA: 0s - loss: 4.564 - ETA: 0s - loss: 4.536 - ETA: 0s - loss: 4.509 - ETA: 0s - loss: 4.479 - 2s 127us/step - loss: 4.4785 - val_loss: 3.2352\n",
      "tr CRPS Grr val CRPS 0.019567\n",
      "Epoch 2/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 3.079 - ETA: 1s - loss: 3.221 - ETA: 1s - loss: 3.159 - ETA: 1s - loss: 3.115 - ETA: 1s - loss: 3.117 - ETA: 1s - loss: 3.102 - ETA: 1s - loss: 3.076 - ETA: 1s - loss: 3.053 - ETA: 1s - loss: 3.040 - ETA: 1s - loss: 3.043 - ETA: 1s - loss: 3.036 - ETA: 1s - loss: 3.038 - ETA: 1s - loss: 3.022 - ETA: 1s - loss: 3.011 - ETA: 1s - loss: 3.003 - ETA: 1s - loss: 2.997 - ETA: 1s - loss: 2.991 - ETA: 1s - loss: 2.987 - ETA: 0s - loss: 2.981 - ETA: 0s - loss: 2.972 - ETA: 0s - loss: 2.968 - ETA: 0s - loss: 2.959 - ETA: 0s - loss: 2.956 - ETA: 0s - loss: 2.950 - ETA: 0s - loss: 2.945 - ETA: 0s - loss: 2.944 - ETA: 0s - loss: 2.941 - ETA: 0s - loss: 2.938 - ETA: 0s - loss: 2.933 - ETA: 0s - loss: 2.932 - ETA: 0s - loss: 2.927 - ETA: 0s - loss: 2.923 - ETA: 0s - loss: 2.922 - ETA: 0s - loss: 2.919 - ETA: 0s - loss: 2.916 - 2s 105us/step - loss: 2.9156 - val_loss: 2.8591\n",
      "tr CRPS Grr val CRPS 0.013771\n",
      "Epoch 3/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.498 - ETA: 2s - loss: 2.653 - ETA: 2s - loss: 2.660 - ETA: 2s - loss: 2.682 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.675 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.694 - ETA: 1s - loss: 2.697 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.709 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.714 - ETA: 1s - loss: 2.723 - ETA: 1s - loss: 2.728 - ETA: 0s - loss: 2.729 - ETA: 0s - loss: 2.729 - ETA: 0s - loss: 2.727 - ETA: 0s - loss: 2.732 - ETA: 0s - loss: 2.731 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.732 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.739 - ETA: 0s - loss: 2.739 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.738 - 2s 107us/step - loss: 2.7383 - val_loss: 2.8359\n",
      "tr CRPS Grr val CRPS 0.013579\n",
      "Epoch 4/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.564 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.649 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.659 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.656 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.686 - 2s 104us/step - loss: 2.6856 - val_loss: 2.8421\n",
      "tr CRPS Grr val CRPS 0.013551\n",
      "Epoch 5/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.468 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.620 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.638 - 2s 103us/step - loss: 2.6388 - val_loss: 2.8411\n",
      "tr CRPS Grr val CRPS 0.013544\n",
      "Epoch 6/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.626 - ETA: 1s - loss: 2.526 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.554 - ETA: 1s - loss: 2.555 - ETA: 1s - loss: 2.556 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.558 - ETA: 1s - loss: 2.572 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.589 - ETA: 1s - loss: 2.591 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.590 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.614 - 2s 105us/step - loss: 2.6154 - val_loss: 2.8585\n",
      "tr CRPS Grr val CRPS 0.013618\n",
      "Epoch 7/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19309/19309 [==============================] - ETA: 2s - loss: 2.809 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.572 - ETA: 1s - loss: 2.575 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.568 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.571 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.565 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.576 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.581 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.586 - 2s 102us/step - loss: 2.5867 - val_loss: 2.8611\n",
      "tr CRPS Grr val CRPS 0.013572\n",
      "Epoch 8/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.624 - ETA: 1s - loss: 2.525 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.542 - ETA: 1s - loss: 2.537 - ETA: 1s - loss: 2.539 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.537 - ETA: 1s - loss: 2.537 - ETA: 1s - loss: 2.529 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.524 - ETA: 1s - loss: 2.529 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.531 - ETA: 0s - loss: 2.538 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.543 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.557 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.560 - 2s 101us/step - loss: 2.5608 - val_loss: 2.8765\n",
      "tr CRPS Grr val CRPS 0.013606\n",
      "Epoch 9/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.392 - ETA: 2s - loss: 2.436 - ETA: 1s - loss: 2.484 - ETA: 1s - loss: 2.470 - ETA: 1s - loss: 2.488 - ETA: 1s - loss: 2.495 - ETA: 1s - loss: 2.488 - ETA: 1s - loss: 2.488 - ETA: 1s - loss: 2.496 - ETA: 1s - loss: 2.498 - ETA: 1s - loss: 2.499 - ETA: 1s - loss: 2.511 - ETA: 1s - loss: 2.515 - ETA: 1s - loss: 2.515 - ETA: 1s - loss: 2.522 - ETA: 1s - loss: 2.516 - ETA: 1s - loss: 2.516 - ETA: 1s - loss: 2.519 - ETA: 0s - loss: 2.520 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.522 - ETA: 0s - loss: 2.525 - ETA: 0s - loss: 2.528 - ETA: 0s - loss: 2.528 - ETA: 0s - loss: 2.529 - ETA: 0s - loss: 2.528 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.533 - ETA: 0s - loss: 2.534 - ETA: 0s - loss: 2.536 - ETA: 0s - loss: 2.538 - ETA: 0s - loss: 2.539 - ETA: 0s - loss: 2.538 - 2s 105us/step - loss: 2.5388 - val_loss: 2.8809\n",
      "tr CRPS Grr val CRPS 0.013554\n",
      "Epoch 10/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.528 - ETA: 2s - loss: 2.456 - ETA: 1s - loss: 2.437 - ETA: 1s - loss: 2.465 - ETA: 1s - loss: 2.459 - ETA: 1s - loss: 2.454 - ETA: 1s - loss: 2.461 - ETA: 1s - loss: 2.467 - ETA: 1s - loss: 2.472 - ETA: 1s - loss: 2.478 - ETA: 1s - loss: 2.473 - ETA: 1s - loss: 2.477 - ETA: 1s - loss: 2.482 - ETA: 1s - loss: 2.485 - ETA: 1s - loss: 2.485 - ETA: 1s - loss: 2.486 - ETA: 1s - loss: 2.488 - ETA: 0s - loss: 2.489 - ETA: 0s - loss: 2.490 - ETA: 0s - loss: 2.493 - ETA: 0s - loss: 2.492 - ETA: 0s - loss: 2.494 - ETA: 0s - loss: 2.496 - ETA: 0s - loss: 2.499 - ETA: 0s - loss: 2.501 - ETA: 0s - loss: 2.504 - ETA: 0s - loss: 2.505 - ETA: 0s - loss: 2.505 - ETA: 0s - loss: 2.510 - ETA: 0s - loss: 2.514 - ETA: 0s - loss: 2.514 - ETA: 0s - loss: 2.513 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.515 - ETA: 0s - loss: 2.516 - 2s 106us/step - loss: 2.5166 - val_loss: 2.8939\n",
      "tr CRPS Grr val CRPS 0.013547\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00010: early stopping\n",
      "4\n",
      "Train on 19309 samples, validate on 3862 samples\n",
      "Epoch 1/250\n",
      "19309/19309 [==============================] - ETA: 47s - loss: 5.54 - ETA: 11s - loss: 5.49 - ETA: 7s - loss: 5.5210 - ETA: 5s - loss: 5.482 - ETA: 4s - loss: 5.450 - ETA: 3s - loss: 5.428 - ETA: 3s - loss: 5.396 - ETA: 2s - loss: 5.375 - ETA: 2s - loss: 5.347 - ETA: 2s - loss: 5.326 - ETA: 2s - loss: 5.297 - ETA: 2s - loss: 5.276 - ETA: 2s - loss: 5.248 - ETA: 1s - loss: 5.214 - ETA: 1s - loss: 5.190 - ETA: 1s - loss: 5.165 - ETA: 1s - loss: 5.143 - ETA: 1s - loss: 5.118 - ETA: 1s - loss: 5.086 - ETA: 1s - loss: 5.053 - ETA: 1s - loss: 5.026 - ETA: 1s - loss: 5.000 - ETA: 1s - loss: 4.975 - ETA: 0s - loss: 4.950 - ETA: 0s - loss: 4.921 - ETA: 0s - loss: 4.894 - ETA: 0s - loss: 4.866 - ETA: 0s - loss: 4.836 - ETA: 0s - loss: 4.799 - ETA: 0s - loss: 4.765 - ETA: 0s - loss: 4.728 - ETA: 0s - loss: 4.693 - ETA: 0s - loss: 4.663 - ETA: 0s - loss: 4.634 - ETA: 0s - loss: 4.597 - ETA: 0s - loss: 4.561 - ETA: 0s - loss: 4.526 - 2s 126us/step - loss: 4.5070 - val_loss: 3.2581\n",
      "tr CRPS Grr val CRPS 0.020146\n",
      "Epoch 2/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 3.065 - ETA: 1s - loss: 3.123 - ETA: 1s - loss: 3.133 - ETA: 1s - loss: 3.157 - ETA: 1s - loss: 3.149 - ETA: 1s - loss: 3.124 - ETA: 1s - loss: 3.103 - ETA: 1s - loss: 3.098 - ETA: 1s - loss: 3.076 - ETA: 1s - loss: 3.061 - ETA: 1s - loss: 3.037 - ETA: 1s - loss: 3.027 - ETA: 1s - loss: 3.018 - ETA: 1s - loss: 3.011 - ETA: 1s - loss: 3.004 - ETA: 1s - loss: 2.991 - ETA: 0s - loss: 2.985 - ETA: 0s - loss: 2.978 - ETA: 0s - loss: 2.971 - ETA: 0s - loss: 2.963 - ETA: 0s - loss: 2.963 - ETA: 0s - loss: 2.958 - ETA: 0s - loss: 2.950 - ETA: 0s - loss: 2.945 - ETA: 0s - loss: 2.943 - ETA: 0s - loss: 2.940 - ETA: 0s - loss: 2.941 - ETA: 0s - loss: 2.938 - ETA: 0s - loss: 2.936 - ETA: 0s - loss: 2.933 - ETA: 0s - loss: 2.930 - ETA: 0s - loss: 2.925 - ETA: 0s - loss: 2.924 - ETA: 0s - loss: 2.919 - 2s 104us/step - loss: 2.9183 - val_loss: 2.8620\n",
      "tr CRPS Grr val CRPS 0.013842\n",
      "Epoch 3/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.742 - ETA: 1s - loss: 2.739 - ETA: 1s - loss: 2.734 - ETA: 1s - loss: 2.734 - ETA: 1s - loss: 2.742 - ETA: 1s - loss: 2.744 - ETA: 1s - loss: 2.744 - ETA: 1s - loss: 2.745 - ETA: 1s - loss: 2.749 - ETA: 1s - loss: 2.749 - ETA: 1s - loss: 2.749 - ETA: 1s - loss: 2.755 - ETA: 1s - loss: 2.754 - ETA: 0s - loss: 2.754 - ETA: 0s - loss: 2.754 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.746 - ETA: 0s - loss: 2.748 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.741 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.743 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.742 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.743 - ETA: 0s - loss: 2.743 - 2s 102us/step - loss: 2.7434 - val_loss: 2.8416\n",
      "tr CRPS Grr val CRPS 0.013657\n",
      "Epoch 4/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.650 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.664 - ETA: 0s - loss: 2.662 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.688 - 2s 105us/step - loss: 2.6891 - val_loss: 2.8339\n",
      "tr CRPS Grr val CRPS 0.01358\n",
      "Epoch 5/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19309/19309 [==============================] - ETA: 2s - loss: 2.588 - ETA: 2s - loss: 2.498 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.538 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.585 - ETA: 1s - loss: 2.597 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.611 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.646 - 2s 104us/step - loss: 2.6469 - val_loss: 2.8472\n",
      "tr CRPS Grr val CRPS 0.013597\n",
      "Epoch 6/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.571 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.562 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.585 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.600 - ETA: 1s - loss: 2.603 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.620 - 2s 105us/step - loss: 2.6220 - val_loss: 2.8568\n",
      "tr CRPS Grr val CRPS 0.013624\n",
      "Epoch 7/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.580 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.568 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.569 - ETA: 1s - loss: 2.568 - ETA: 1s - loss: 2.566 - ETA: 1s - loss: 2.563 - ETA: 1s - loss: 2.562 - ETA: 1s - loss: 2.556 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.558 - ETA: 0s - loss: 2.559 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.578 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.587 - 2s 102us/step - loss: 2.5892 - val_loss: 2.8598\n",
      "tr CRPS Grr val CRPS 0.013552\n",
      "Epoch 8/250\n",
      "19309/19309 [==============================] - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.492 - ETA: 1s - loss: 2.503 - ETA: 1s - loss: 2.511 - ETA: 1s - loss: 2.515 - ETA: 1s - loss: 2.520 - ETA: 1s - loss: 2.517 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.550 - ETA: 1s - loss: 2.550 - ETA: 1s - loss: 2.555 - ETA: 0s - loss: 2.557 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.557 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.559 - ETA: 0s - loss: 2.561 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.566 - ETA: 0s - loss: 2.566 - 2s 102us/step - loss: 2.5684 - val_loss: 2.8695\n",
      "tr CRPS Grr val CRPS 0.013559\n",
      "Epoch 9/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.527 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.535 - ETA: 1s - loss: 2.523 - ETA: 1s - loss: 2.505 - ETA: 1s - loss: 2.495 - ETA: 1s - loss: 2.500 - ETA: 1s - loss: 2.504 - ETA: 1s - loss: 2.508 - ETA: 1s - loss: 2.506 - ETA: 1s - loss: 2.504 - ETA: 1s - loss: 2.502 - ETA: 1s - loss: 2.510 - ETA: 1s - loss: 2.519 - ETA: 1s - loss: 2.525 - ETA: 1s - loss: 2.523 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.527 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.529 - ETA: 0s - loss: 2.528 - ETA: 0s - loss: 2.529 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.536 - ETA: 0s - loss: 2.535 - ETA: 0s - loss: 2.534 - ETA: 0s - loss: 2.535 - ETA: 0s - loss: 2.535 - ETA: 0s - loss: 2.536 - ETA: 0s - loss: 2.536 - ETA: 0s - loss: 2.538 - ETA: 0s - loss: 2.539 - 2s 105us/step - loss: 2.5397 - val_loss: 2.8827\n",
      "tr CRPS Grr val CRPS 0.013559\n",
      "Epoch 10/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.515 - ETA: 1s - loss: 2.477 - ETA: 1s - loss: 2.452 - ETA: 1s - loss: 2.465 - ETA: 1s - loss: 2.461 - ETA: 1s - loss: 2.472 - ETA: 1s - loss: 2.479 - ETA: 1s - loss: 2.474 - ETA: 1s - loss: 2.475 - ETA: 1s - loss: 2.481 - ETA: 1s - loss: 2.484 - ETA: 1s - loss: 2.481 - ETA: 1s - loss: 2.485 - ETA: 1s - loss: 2.486 - ETA: 1s - loss: 2.488 - ETA: 1s - loss: 2.492 - ETA: 0s - loss: 2.489 - ETA: 0s - loss: 2.488 - ETA: 0s - loss: 2.488 - ETA: 0s - loss: 2.488 - ETA: 0s - loss: 2.490 - ETA: 0s - loss: 2.496 - ETA: 0s - loss: 2.499 - ETA: 0s - loss: 2.501 - ETA: 0s - loss: 2.506 - ETA: 0s - loss: 2.507 - ETA: 0s - loss: 2.510 - ETA: 0s - loss: 2.510 - ETA: 0s - loss: 2.513 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.517 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.518 - ETA: 0s - loss: 2.521 - 2s 104us/step - loss: 2.5214 - val_loss: 2.8988\n",
      "tr CRPS Grr val CRPS 0.013612\n",
      "Epoch 11/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.571 - ETA: 2s - loss: 2.490 - ETA: 1s - loss: 2.489 - ETA: 1s - loss: 2.466 - ETA: 1s - loss: 2.432 - ETA: 1s - loss: 2.443 - ETA: 1s - loss: 2.434 - ETA: 1s - loss: 2.434 - ETA: 1s - loss: 2.439 - ETA: 1s - loss: 2.447 - ETA: 1s - loss: 2.448 - ETA: 1s - loss: 2.451 - ETA: 1s - loss: 2.458 - ETA: 1s - loss: 2.461 - ETA: 1s - loss: 2.466 - ETA: 0s - loss: 2.469 - ETA: 0s - loss: 2.468 - ETA: 0s - loss: 2.472 - ETA: 0s - loss: 2.477 - ETA: 0s - loss: 2.481 - ETA: 0s - loss: 2.480 - ETA: 0s - loss: 2.480 - ETA: 0s - loss: 2.482 - ETA: 0s - loss: 2.482 - ETA: 0s - loss: 2.484 - ETA: 0s - loss: 2.485 - ETA: 0s - loss: 2.486 - ETA: 0s - loss: 2.486 - ETA: 0s - loss: 2.487 - ETA: 0s - loss: 2.492 - ETA: 0s - loss: 2.493 - ETA: 0s - loss: 2.500 - ETA: 0s - loss: 2.500 - 2s 100us/step - loss: 2.5016 - val_loss: 2.9018\n",
      "tr CRPS Grr val CRPS 0.013564\n",
      "Epoch 12/250\n",
      "19309/19309 [==============================] - ETA: 2s - loss: 2.260 - ETA: 1s - loss: 2.428 - ETA: 1s - loss: 2.452 - ETA: 1s - loss: 2.451 - ETA: 1s - loss: 2.469 - ETA: 1s - loss: 2.460 - ETA: 1s - loss: 2.462 - ETA: 1s - loss: 2.462 - ETA: 1s - loss: 2.466 - ETA: 1s - loss: 2.466 - ETA: 1s - loss: 2.464 - ETA: 1s - loss: 2.469 - ETA: 1s - loss: 2.477 - ETA: 1s - loss: 2.473 - ETA: 0s - loss: 2.472 - ETA: 0s - loss: 2.467 - ETA: 0s - loss: 2.466 - ETA: 0s - loss: 2.465 - ETA: 0s - loss: 2.466 - ETA: 0s - loss: 2.467 - ETA: 0s - loss: 2.466 - ETA: 0s - loss: 2.464 - ETA: 0s - loss: 2.463 - ETA: 0s - loss: 2.463 - ETA: 0s - loss: 2.462 - ETA: 0s - loss: 2.462 - ETA: 0s - loss: 2.464 - ETA: 0s - loss: 2.465 - ETA: 0s - loss: 2.467 - ETA: 0s - loss: 2.469 - ETA: 0s - loss: 2.471 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.475 - 2s 99us/step - loss: 2.4748 - val_loss: 2.9158\n",
      "tr CRPS Grr val CRPS 0.013557\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00012: early stopping\n",
      "5\n",
      "Train on 19310 samples, validate on 3861 samples\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19310/19310 [==============================] - ETA: 46s - loss: 5.55 - ETA: 9s - loss: 5.5685 - ETA: 5s - loss: 5.514 - ETA: 4s - loss: 5.505 - ETA: 3s - loss: 5.487 - ETA: 3s - loss: 5.453 - ETA: 2s - loss: 5.421 - ETA: 2s - loss: 5.398 - ETA: 2s - loss: 5.357 - ETA: 2s - loss: 5.326 - ETA: 2s - loss: 5.303 - ETA: 1s - loss: 5.272 - ETA: 1s - loss: 5.241 - ETA: 1s - loss: 5.209 - ETA: 1s - loss: 5.171 - ETA: 1s - loss: 5.143 - ETA: 1s - loss: 5.112 - ETA: 1s - loss: 5.076 - ETA: 1s - loss: 5.044 - ETA: 1s - loss: 5.017 - ETA: 0s - loss: 4.981 - ETA: 0s - loss: 4.952 - ETA: 0s - loss: 4.917 - ETA: 0s - loss: 4.884 - ETA: 0s - loss: 4.847 - ETA: 0s - loss: 4.812 - ETA: 0s - loss: 4.776 - ETA: 0s - loss: 4.742 - ETA: 0s - loss: 4.703 - ETA: 0s - loss: 4.661 - ETA: 0s - loss: 4.626 - ETA: 0s - loss: 4.591 - ETA: 0s - loss: 4.556 - ETA: 0s - loss: 4.521 - 2s 116us/step - loss: 4.5141 - val_loss: 3.2301\n",
      "tr CRPS Grr val CRPS 0.019638\n",
      "Epoch 2/250\n",
      "19310/19310 [==============================] - ETA: 2s - loss: 2.922 - ETA: 1s - loss: 2.986 - ETA: 1s - loss: 3.056 - ETA: 1s - loss: 3.053 - ETA: 1s - loss: 3.061 - ETA: 1s - loss: 3.048 - ETA: 1s - loss: 3.032 - ETA: 1s - loss: 3.020 - ETA: 1s - loss: 3.015 - ETA: 1s - loss: 2.998 - ETA: 1s - loss: 2.992 - ETA: 1s - loss: 2.985 - ETA: 1s - loss: 2.970 - ETA: 1s - loss: 2.970 - ETA: 1s - loss: 2.962 - ETA: 0s - loss: 2.954 - ETA: 0s - loss: 2.957 - ETA: 0s - loss: 2.955 - ETA: 0s - loss: 2.952 - ETA: 0s - loss: 2.944 - ETA: 0s - loss: 2.941 - ETA: 0s - loss: 2.940 - ETA: 0s - loss: 2.936 - ETA: 0s - loss: 2.931 - ETA: 0s - loss: 2.928 - ETA: 0s - loss: 2.925 - ETA: 0s - loss: 2.923 - ETA: 0s - loss: 2.921 - ETA: 0s - loss: 2.919 - ETA: 0s - loss: 2.915 - ETA: 0s - loss: 2.912 - ETA: 0s - loss: 2.909 - ETA: 0s - loss: 2.906 - 2s 97us/step - loss: 2.9059 - val_loss: 2.8437\n",
      "tr CRPS Grr val CRPS 0.013759\n",
      "Epoch 3/250\n",
      "19310/19310 [==============================] - ETA: 1s - loss: 2.517 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.694 - ETA: 1s - loss: 2.693 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.713 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.715 - ETA: 1s - loss: 2.717 - ETA: 1s - loss: 2.726 - ETA: 1s - loss: 2.725 - ETA: 1s - loss: 2.723 - ETA: 1s - loss: 2.725 - ETA: 1s - loss: 2.733 - ETA: 0s - loss: 2.731 - ETA: 0s - loss: 2.729 - ETA: 0s - loss: 2.732 - ETA: 0s - loss: 2.729 - ETA: 0s - loss: 2.735 - ETA: 0s - loss: 2.739 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.738 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.738 - ETA: 0s - loss: 2.740 - 2s 97us/step - loss: 2.7415 - val_loss: 2.8303\n",
      "tr CRPS Grr val CRPS 0.013655\n",
      "Epoch 4/250\n",
      "19310/19310 [==============================] - ETA: 2s - loss: 2.678 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.667 - ETA: 1s - loss: 2.665 - ETA: 1s - loss: 2.675 - ETA: 1s - loss: 2.671 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.667 - ETA: 1s - loss: 2.667 - ETA: 1s - loss: 2.664 - ETA: 0s - loss: 2.662 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.682 - 2s 96us/step - loss: 2.6822 - val_loss: 2.8219\n",
      "tr CRPS Grr val CRPS 0.013585\n",
      "Epoch 5/250\n",
      "19310/19310 [==============================] - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.621 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.649 - 2s 98us/step - loss: 2.6499 - val_loss: 2.8289\n",
      "tr CRPS Grr val CRPS 0.013553\n",
      "Epoch 6/250\n",
      "19310/19310 [==============================] - ETA: 2s - loss: 2.461 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.589 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.609 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.607 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.622 - 2s 96us/step - loss: 2.6228 - val_loss: 2.8363\n",
      "tr CRPS Grr val CRPS 0.01358\n",
      "Epoch 7/250\n",
      "19310/19310 [==============================] - ETA: 2s - loss: 2.546 - ETA: 1s - loss: 2.546 - ETA: 1s - loss: 2.536 - ETA: 1s - loss: 2.511 - ETA: 1s - loss: 2.525 - ETA: 1s - loss: 2.536 - ETA: 1s - loss: 2.560 - ETA: 1s - loss: 2.556 - ETA: 1s - loss: 2.568 - ETA: 1s - loss: 2.568 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.563 - ETA: 1s - loss: 2.563 - ETA: 1s - loss: 2.566 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.586 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.592 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.590 - 2s 96us/step - loss: 2.5904 - val_loss: 2.8443\n",
      "tr CRPS Grr val CRPS 0.013559\n",
      "Epoch 8/250\n",
      "19310/19310 [==============================] - ETA: 2s - loss: 2.603 - ETA: 1s - loss: 2.532 - ETA: 1s - loss: 2.522 - ETA: 1s - loss: 2.511 - ETA: 1s - loss: 2.504 - ETA: 1s - loss: 2.501 - ETA: 1s - loss: 2.499 - ETA: 1s - loss: 2.509 - ETA: 1s - loss: 2.509 - ETA: 1s - loss: 2.517 - ETA: 1s - loss: 2.516 - ETA: 1s - loss: 2.513 - ETA: 1s - loss: 2.518 - ETA: 1s - loss: 2.516 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.523 - ETA: 0s - loss: 2.529 - ETA: 0s - loss: 2.536 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.546 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.546 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.561 - 2s 96us/step - loss: 2.5613 - val_loss: 2.8516\n",
      "tr CRPS Grr val CRPS 0.01354\n",
      "Epoch 9/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19310/19310 [==============================] - ETA: 1s - loss: 2.445 - ETA: 1s - loss: 2.454 - ETA: 1s - loss: 2.446 - ETA: 1s - loss: 2.446 - ETA: 1s - loss: 2.473 - ETA: 1s - loss: 2.476 - ETA: 1s - loss: 2.481 - ETA: 1s - loss: 2.487 - ETA: 1s - loss: 2.488 - ETA: 1s - loss: 2.490 - ETA: 1s - loss: 2.490 - ETA: 1s - loss: 2.492 - ETA: 1s - loss: 2.497 - ETA: 1s - loss: 2.501 - ETA: 0s - loss: 2.501 - ETA: 0s - loss: 2.501 - ETA: 0s - loss: 2.503 - ETA: 0s - loss: 2.508 - ETA: 0s - loss: 2.510 - ETA: 0s - loss: 2.513 - ETA: 0s - loss: 2.515 - ETA: 0s - loss: 2.518 - ETA: 0s - loss: 2.517 - ETA: 0s - loss: 2.520 - ETA: 0s - loss: 2.522 - ETA: 0s - loss: 2.524 - ETA: 0s - loss: 2.526 - ETA: 0s - loss: 2.528 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.533 - ETA: 0s - loss: 2.536 - ETA: 0s - loss: 2.538 - 2s 95us/step - loss: 2.5380 - val_loss: 2.8577\n",
      "tr CRPS Grr val CRPS 0.013516\n",
      "Epoch 10/250\n",
      "19310/19310 [==============================] - ETA: 2s - loss: 2.411 - ETA: 1s - loss: 2.458 - ETA: 1s - loss: 2.462 - ETA: 1s - loss: 2.459 - ETA: 1s - loss: 2.456 - ETA: 1s - loss: 2.462 - ETA: 1s - loss: 2.461 - ETA: 1s - loss: 2.463 - ETA: 1s - loss: 2.460 - ETA: 1s - loss: 2.469 - ETA: 1s - loss: 2.474 - ETA: 1s - loss: 2.476 - ETA: 1s - loss: 2.479 - ETA: 1s - loss: 2.482 - ETA: 1s - loss: 2.489 - ETA: 0s - loss: 2.489 - ETA: 0s - loss: 2.494 - ETA: 0s - loss: 2.496 - ETA: 0s - loss: 2.498 - ETA: 0s - loss: 2.504 - ETA: 0s - loss: 2.506 - ETA: 0s - loss: 2.509 - ETA: 0s - loss: 2.507 - ETA: 0s - loss: 2.509 - ETA: 0s - loss: 2.507 - ETA: 0s - loss: 2.514 - ETA: 0s - loss: 2.512 - ETA: 0s - loss: 2.512 - ETA: 0s - loss: 2.515 - ETA: 0s - loss: 2.514 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.520 - 2s 97us/step - loss: 2.5208 - val_loss: 2.8708\n",
      "tr CRPS Grr val CRPS 0.013542\n",
      "Epoch 11/250\n",
      "19310/19310 [==============================] - ETA: 1s - loss: 2.374 - ETA: 1s - loss: 2.440 - ETA: 1s - loss: 2.451 - ETA: 1s - loss: 2.437 - ETA: 1s - loss: 2.442 - ETA: 1s - loss: 2.439 - ETA: 1s - loss: 2.459 - ETA: 1s - loss: 2.460 - ETA: 1s - loss: 2.462 - ETA: 1s - loss: 2.456 - ETA: 1s - loss: 2.466 - ETA: 1s - loss: 2.469 - ETA: 1s - loss: 2.473 - ETA: 1s - loss: 2.474 - ETA: 0s - loss: 2.476 - ETA: 0s - loss: 2.482 - ETA: 0s - loss: 2.483 - ETA: 0s - loss: 2.485 - ETA: 0s - loss: 2.488 - ETA: 0s - loss: 2.490 - ETA: 0s - loss: 2.491 - ETA: 0s - loss: 2.494 - ETA: 0s - loss: 2.492 - ETA: 0s - loss: 2.492 - ETA: 0s - loss: 2.492 - ETA: 0s - loss: 2.493 - ETA: 0s - loss: 2.495 - ETA: 0s - loss: 2.495 - ETA: 0s - loss: 2.495 - ETA: 0s - loss: 2.498 - ETA: 0s - loss: 2.499 - ETA: 0s - loss: 2.500 - ETA: 0s - loss: 2.500 - 2s 96us/step - loss: 2.5003 - val_loss: 2.8728\n",
      "tr CRPS Grr val CRPS 0.013535\n",
      "Epoch 12/250\n",
      "19310/19310 [==============================] - ETA: 2s - loss: 2.518 - ETA: 1s - loss: 2.497 - ETA: 1s - loss: 2.439 - ETA: 1s - loss: 2.456 - ETA: 1s - loss: 2.444 - ETA: 1s - loss: 2.450 - ETA: 1s - loss: 2.460 - ETA: 1s - loss: 2.455 - ETA: 1s - loss: 2.462 - ETA: 1s - loss: 2.459 - ETA: 1s - loss: 2.453 - ETA: 1s - loss: 2.453 - ETA: 1s - loss: 2.450 - ETA: 1s - loss: 2.451 - ETA: 1s - loss: 2.455 - ETA: 0s - loss: 2.461 - ETA: 0s - loss: 2.466 - ETA: 0s - loss: 2.466 - ETA: 0s - loss: 2.468 - ETA: 0s - loss: 2.468 - ETA: 0s - loss: 2.468 - ETA: 0s - loss: 2.468 - ETA: 0s - loss: 2.471 - ETA: 0s - loss: 2.471 - ETA: 0s - loss: 2.471 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.475 - ETA: 0s - loss: 2.477 - ETA: 0s - loss: 2.478 - ETA: 0s - loss: 2.481 - ETA: 0s - loss: 2.480 - 2s 97us/step - loss: 2.4800 - val_loss: 2.8873\n",
      "tr CRPS Grr val CRPS 0.013571\n",
      "Epoch 13/250\n",
      "19310/19310 [==============================] - ETA: 1s - loss: 2.457 - ETA: 1s - loss: 2.361 - ETA: 1s - loss: 2.383 - ETA: 1s - loss: 2.402 - ETA: 1s - loss: 2.399 - ETA: 1s - loss: 2.398 - ETA: 1s - loss: 2.399 - ETA: 1s - loss: 2.409 - ETA: 1s - loss: 2.412 - ETA: 1s - loss: 2.421 - ETA: 1s - loss: 2.421 - ETA: 1s - loss: 2.421 - ETA: 1s - loss: 2.420 - ETA: 1s - loss: 2.419 - ETA: 0s - loss: 2.420 - ETA: 0s - loss: 2.424 - ETA: 0s - loss: 2.427 - ETA: 0s - loss: 2.430 - ETA: 0s - loss: 2.433 - ETA: 0s - loss: 2.436 - ETA: 0s - loss: 2.440 - ETA: 0s - loss: 2.441 - ETA: 0s - loss: 2.441 - ETA: 0s - loss: 2.445 - ETA: 0s - loss: 2.448 - ETA: 0s - loss: 2.454 - ETA: 0s - loss: 2.451 - ETA: 0s - loss: 2.455 - ETA: 0s - loss: 2.457 - ETA: 0s - loss: 2.457 - ETA: 0s - loss: 2.459 - ETA: 0s - loss: 2.461 - ETA: 0s - loss: 2.463 - 2s 95us/step - loss: 2.4630 - val_loss: 2.8915\n",
      "tr CRPS Grr val CRPS 0.013548\n",
      "Epoch 14/250\n",
      "19310/19310 [==============================] - ETA: 2s - loss: 2.353 - ETA: 1s - loss: 2.362 - ETA: 1s - loss: 2.342 - ETA: 1s - loss: 2.381 - ETA: 1s - loss: 2.355 - ETA: 1s - loss: 2.361 - ETA: 1s - loss: 2.360 - ETA: 1s - loss: 2.371 - ETA: 1s - loss: 2.380 - ETA: 1s - loss: 2.382 - ETA: 1s - loss: 2.390 - ETA: 1s - loss: 2.399 - ETA: 1s - loss: 2.400 - ETA: 1s - loss: 2.404 - ETA: 1s - loss: 2.409 - ETA: 0s - loss: 2.412 - ETA: 0s - loss: 2.414 - ETA: 0s - loss: 2.417 - ETA: 0s - loss: 2.417 - ETA: 0s - loss: 2.416 - ETA: 0s - loss: 2.415 - ETA: 0s - loss: 2.414 - ETA: 0s - loss: 2.417 - ETA: 0s - loss: 2.418 - ETA: 0s - loss: 2.421 - ETA: 0s - loss: 2.423 - ETA: 0s - loss: 2.429 - ETA: 0s - loss: 2.430 - ETA: 0s - loss: 2.431 - ETA: 0s - loss: 2.432 - ETA: 0s - loss: 2.434 - ETA: 0s - loss: 2.434 - ETA: 0s - loss: 2.436 - 2s 98us/step - loss: 2.4381 - val_loss: 2.9046\n",
      "tr CRPS Grr val CRPS 0.013583\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "\n",
    "rkf = GroupKFold(6)\n",
    "for fold_id, (tr_idx, vl_idx) in enumerate(rkf.split(rusher['PlayId'],rusher['PlayId'],rusher['PlayId'])):\n",
    "    print(fold_id)\n",
    "\n",
    "    x_tr, y_tr = X[tr_idx], Y[tr_idx]\n",
    "    x_vl, y_vl = X[vl_idx], Y[vl_idx]    \n",
    "\n",
    "    model= get_model()\n",
    "    es = EarlyStopping(monitor='val_CRPS', \n",
    "                   mode='min',\n",
    "                   restore_best_weights=True, \n",
    "                   verbose=1, \n",
    "                   patience=5)\n",
    "    es.set_model(model)\n",
    "    metric = Metric(model, [es], [(x_tr, y_tr), (x_vl, y_vl)])\n",
    "\n",
    "\n",
    "\n",
    "    model.fit(x_tr, y_tr, callbacks=[metric], epochs=250, batch_size=100, validation_data=[x_vl, y_vl])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 632)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m632\u001b[0m\n\u001b[1;33m    0.250000*np.tanh(((((((((((((data[:,2]) - (data[:,7]))) * 2.0)) + (data[:,7]))) * 2.0)) + (data[:,0]))) + (((((data[:,2]) + (data[:,0]))) - (data[:,7]))))) +\\\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class GP:\n",
    "    def __init__(self):\n",
    "        self.classes = 20\n",
    "        self.class_names = [ 'class_0',\n",
    "                             'class_1',\n",
    "                             'class_2',\n",
    "                             'class_3',\n",
    "                             'class_4',\n",
    "                             'class_5',\n",
    "                             'class_6',\n",
    "                             'class_7',\n",
    "                             'class_8',\n",
    "                             'class_9',\n",
    "                             'class_10',\n",
    "                             'class_11',\n",
    "                             'class_12',\n",
    "                             'class_13',\n",
    "                            'class_14',\n",
    "                            'class_15',\n",
    "                            'class_16',\n",
    "                            'class_17',\n",
    "                            'class_18',\n",
    "                            'class_19',\n",
    "                           ]\n",
    "\n",
    "\n",
    "    def GrabPredictions(self, data):\n",
    "        oof_preds = np.zeros((len(data), len(self.class_names)))\n",
    "        oof_preds[:,0] = self.GP_class_0(data)\n",
    "        oof_preds[:,1] = self.GP_class_1(data)\n",
    "        oof_preds[:,2] = self.GP_class_2(data)\n",
    "        oof_preds[:,3] = self.GP_class_3(data)\n",
    "        oof_preds[:,4] = self.GP_class_4(data)\n",
    "        oof_preds[:,5] = self.GP_class_5(data)\n",
    "        oof_preds[:,6] = self.GP_class_6(data)\n",
    "        oof_preds[:,7] = self.GP_class_7(data)\n",
    "        oof_preds[:,8] = self.GP_class_8(data)\n",
    "        oof_preds[:,9] = self.GP_class_9(data)\n",
    "        oof_preds[:,10] = self.GP_class_10(data)\n",
    "        oof_preds[:,11] = self.GP_class_11(data)\n",
    "        oof_preds[:,12] = self.GP_class_12(data)\n",
    "        oof_preds[:,13] = self.GP_class_13(data)\n",
    "        oof_preds[:,14] = self.GP_class_14(data)\n",
    "        oof_preds[:,15] = self.GP_class_15(data)\n",
    "        oof_preds[:,16] = self.GP_class_16(data)\n",
    "        oof_preds[:,17] = self.GP_class_17(data)\n",
    "        oof_preds[:,18] = self.GP_class_18(data)\n",
    "        oof_preds[:,19] = self.GP_class_19(data)\n",
    "        oof_df = pd.DataFrame(np.exp(oof_preds), columns=self.class_names)\n",
    "        oof_df =oof_df.div(oof_df.sum(axis=1), axis=0)\n",
    "        \n",
    "        return oof_df.values\n",
    "\n",
    "\n",
    "    def GP_class_0(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,0]) - (((data[:,0]) + (data[:,0]))))) + (data[:,0]))) + (((((data[:,0]) * 2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,2]) - (data[:,7]))) * 2.0)) + (data[:,7]))) * 2.0)) + (data[:,0]))) + (((((data[:,2]) + (data[:,0]))) - (data[:,7]))))) +\n",
    "                0.250000*np.tanh(((((((((((((((((((data[:,3]) - (data[:,7]))) - (((data[:,0]) / 2.0)))) + (data[:,0]))) - (data[:,7]))) + (data[:,2]))) + (((data[:,7]) + (data[:,2]))))) + (data[:,7]))) - (data[:,7]))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,0]) - (data[:,7]))) - (data[:,14]))) + (((data[:,17]) - (data[:,14]))))) + (((((((data[:,0]) - ((1.0)))) - (data[:,0]))) + (data[:,20]))))) +\n",
    "                0.250000*np.tanh(((((data[:,18]) + (((((((data[:,0]) - (data[:,7]))) + (data[:,2]))) + (data[:,0]))))) - (((data[:,7]) + (data[:,2]))))) +\n",
    "                0.250000*np.tanh((((((((data[:,8]) + ((((((((data[:,13]) + (data[:,3]))) + (data[:,0]))/2.0)) + ((((((((data[:,0]) + (((((data[:,0]) - (data[:,0]))) / 2.0)))) + (data[:,17]))/2.0)) + (data[:,11]))))))/2.0)) + (data[:,0]))) - (data[:,13]))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) * 2.0)) + (((((((((data[:,2]) + (data[:,2]))) * 2.0)) - (((data[:,14]) - (((np.tanh((data[:,2]))) * 2.0)))))) - (data[:,7]))))) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,17]) - (((data[:,17]) * (((((data[:,17]) * (data[:,17]))) * 2.0)))))) + (((((((data[:,17]) * 2.0)) * 2.0)) * 2.0)))/2.0)) / 2.0)) + (((data[:,17]) - ((7.76236486434936523)))))/2.0)) + (((((((data[:,17]) * (data[:,17]))) * 2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,17]) + (data[:,17]))/2.0)) + ((((data[:,17]) + ((((data[:,17]) + (data[:,17]))/2.0)))/2.0)))/2.0)) * (data[:,17]))) - (data[:,13]))) +\n",
    "                0.250000*np.tanh((((((data[:,19]) + (((((((((data[:,19]) * 2.0)) + (data[:,19]))) - ((1.07645297050476074)))) + (((data[:,22]) + (data[:,22]))))))/2.0)) + (((data[:,22]) + (data[:,4]))))))\n",
    "    \n",
    "    def GP_class_1(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((((data[:,3]) + (((np.tanh((data[:,2]))) - (data[:,14]))))) - ((10.0)))) - ((4.88989353179931641)))) - ((13.92175483703613281)))) / 2.0)) - (data[:,6]))) +\n",
    "                0.250000*np.tanh(data[:,3]) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((np.tanh((((data[:,14]) * 2.0)))) - (((((((data[:,7]) * 2.0)) - (((((data[:,0]) - (data[:,14]))) - (data[:,7]))))) - (data[:,0]))))) + (data[:,0]))))) +\n",
    "                0.250000*np.tanh(((((((data[:,0]) - ((-1.0*((data[:,14])))))) + ((((((((((data[:,0]) - (data[:,7]))) - ((((data[:,14]) + (data[:,14]))/2.0)))) + (((data[:,2]) - (((data[:,0]) * (data[:,14]))))))/2.0)) - (data[:,14]))))) - (data[:,7]))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) / 2.0)) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((data[:,19]) - (data[:,19]))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((np.tanh((((np.tanh((data[:,5]))) - ((((1.69341480731964111)) + ((((((np.tanh((data[:,14]))) - (data[:,14]))) + (data[:,14]))/2.0)))))))) - (data[:,2]))) - (((data[:,14]) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,22]) + (((data[:,0]) + ((((((((data[:,22]) / 2.0)) + ((-1.0*((data[:,13])))))/2.0)) + (data[:,19]))))))/2.0)) - (data[:,13]))) +\n",
    "                0.250000*np.tanh(((((((data[:,17]) / 2.0)) * (data[:,17]))) * (((data[:,17]) + (((data[:,17]) * (((((((((data[:,17]) + (data[:,17]))) * (data[:,17]))) * (data[:,17]))) + (((np.tanh((data[:,17]))) / 2.0)))))))))) +\n",
    "                0.250000*np.tanh((((((data[:,14]) * (((data[:,13]) + (data[:,3]))))) + (((data[:,14]) * (((data[:,14]) - ((-1.0*((data[:,3])))))))))/2.0)))\n",
    "    \n",
    "    def GP_class_2(self,data):\n",
    "        return(0.250000*np.tanh(((data[:,0]) + (np.tanh((((((((((data[:,2]) + (((data[:,2]) / 2.0)))/2.0)) + (data[:,0]))/2.0)) * (data[:,7]))))))) +\n",
    "                0.250000*np.tanh((((data[:,22]) + (data[:,22]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + ((-1.0*((((((4.73206138610839844)) + (((((((((((np.tanh((data[:,7]))) + (data[:,1]))/2.0)) - (np.tanh((((((data[:,0]) - (data[:,20]))) - (data[:,14]))))))) * ((7.0)))) + (data[:,14]))/2.0)))/2.0))))))/2.0)) - (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((data[:,1]) + ((4.15603733062744141)))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,0]) - (data[:,7]))) - (data[:,7]))) + ((((data[:,0]) + (data[:,0]))/2.0)))) * 2.0)) + (data[:,0]))) * 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,11]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((((((((((((data[:,2]) / 2.0)) + (((data[:,2]) / 2.0)))/2.0)) / 2.0)) / 2.0)) / 2.0)) + ((((-1.0*((((data[:,0]) / 2.0))))) * (((data[:,0]) / 2.0)))))/2.0)) + (data[:,0]))/2.0)) + (np.tanh((data[:,0]))))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((data[:,0]) + (((((((data[:,14]) * (data[:,14]))) + (data[:,14]))) - (data[:,0]))))))) - (data[:,14]))) +\n",
    "                0.250000*np.tanh((((((np.tanh((np.tanh(((0.0)))))) * (data[:,15]))) + (data[:,20]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) * ((((data[:,13]) + ((((data[:,13]) + ((((data[:,14]) + ((((((data[:,14]) + ((((data[:,14]) + (((data[:,13]) - ((((-1.0*(((((data[:,14]) + (data[:,14]))/2.0))))) * 2.0)))))/2.0)))) + (data[:,14]))/2.0)))/2.0)))/2.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_3(self,data):\n",
    "        return(0.250000*np.tanh(((((((((8.0)) + (((((((5.33416414260864258)) + ((9.0)))/2.0)) + ((((8.0)) * 2.0)))))) * 2.0)) + ((5.33416414260864258)))/2.0)) +\n",
    "                0.250000*np.tanh((((9.48088836669921875)) + (((((10.56953334808349609)) + ((((4.48959350585937500)) + (np.tanh(((((3.0)) + ((9.0)))))))))/2.0)))) +\n",
    "                0.250000*np.tanh((((((((((data[:,22]) / 2.0)) + (data[:,22]))/2.0)) * 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((10.44883441925048828)) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((data[:,0]) + ((-1.0*((data[:,9])))))))) + (((((data[:,0]) - (data[:,7]))) - (data[:,9]))))) +\n",
    "                0.250000*np.tanh(((np.tanh((data[:,6]))) - (data[:,21]))) +\n",
    "                0.250000*np.tanh(((data[:,0]) - (((((data[:,14]) + (((((data[:,14]) + (((data[:,14]) + (((data[:,14]) - (data[:,0]))))))) - (((((data[:,0]) - (data[:,14]))) + (data[:,14]))))))) - (((((data[:,14]) * (data[:,14]))) + (data[:,18]))))))) +\n",
    "                0.250000*np.tanh(((data[:,14]) * ((((data[:,13]) + (data[:,14]))/2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,8]) * (((data[:,8]) / 2.0)))) + ((((((data[:,9]) * (data[:,8]))) + (data[:,8]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh((((data[:,2]) + (((((((data[:,2]) + (data[:,20]))/2.0)) + ((((((((data[:,2]) + (data[:,8]))/2.0)) / 2.0)) - (data[:,8]))))/2.0)))/2.0)))\n",
    "    \n",
    "    def GP_class_4(self,data):\n",
    "        return(0.250000*np.tanh((((12.98819637298583984)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((4.75780344009399414)) + (((((((8.66014671325683594)) + ((4.18107128143310547)))/2.0)) * ((8.97841739654541016)))))/2.0)) +\n",
    "                0.250000*np.tanh((((9.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((10.0)) + (np.tanh((((((6.0)) + ((((13.80149555206298828)) + ((7.0)))))/2.0)))))) + ((10.0)))) + (((((((data[:,0]) + ((8.0)))) / 2.0)) / 2.0)))/2.0)) + ((((-1.0*((((data[:,2]) * (data[:,9])))))) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((((((data[:,22]) + (data[:,22]))/2.0)) + (data[:,22]))/2.0)))) + ((((((data[:,22]) + ((((((data[:,22]) * 2.0)) + (data[:,22]))/2.0)))) + (data[:,18]))/2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((np.tanh((data[:,18]))) + ((((data[:,1]) + (data[:,18]))/2.0)))/2.0)) * (data[:,18]))) * (data[:,18]))) + (((data[:,18]) * (data[:,18]))))/2.0)) - (((((((np.tanh((data[:,18]))) + (((data[:,18]) * (data[:,18]))))/2.0)) + (data[:,17]))/2.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh(((((((np.tanh((data[:,6]))) - (((np.tanh((data[:,6]))) - (data[:,6]))))) + (np.tanh((data[:,6]))))/2.0)))) - ((((data[:,10]) + ((((data[:,2]) + (((np.tanh((data[:,6]))) - (((np.tanh((np.tanh((data[:,6]))))) - (data[:,10]))))))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh((((((((((((data[:,10]) + (data[:,4]))) + (((data[:,10]) + (((data[:,0]) * (data[:,10]))))))/2.0)) + (((data[:,4]) * (((data[:,10]) + (data[:,4]))))))/2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,11]) + (((((data[:,18]) / 2.0)) * (((data[:,11]) * (data[:,18]))))))/2.0)) * (((data[:,18]) * (((((((((data[:,18]) * (((((((data[:,11]) / 2.0)) / 2.0)) * (data[:,18]))))) / 2.0)) / 2.0)) * ((-1.0*((data[:,21])))))))))) +\n",
    "                0.250000*np.tanh((((-1.0*((((((((((((data[:,2]) - (data[:,2]))) * (np.tanh((data[:,2]))))) + (np.tanh((((data[:,14]) * 2.0)))))/2.0)) + (data[:,2]))/2.0))))) - (data[:,2]))))\n",
    "    \n",
    "    def GP_class_5(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((3.46574378013610840)) + ((((np.tanh(((3.46574378013610840)))) + ((8.46705245971679688)))/2.0)))/2.0)) * 2.0)) + ((((3.46574378013610840)) + ((4.0)))))) + ((((4.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((10.55856513977050781)) / 2.0)) +\n",
    "                0.250000*np.tanh((((3.76695251464843750)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((6.0)) / 2.0)) + ((((8.57984828948974609)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((((((((3.42168045043945312)) + (data[:,7]))) + (np.tanh((data[:,7]))))) + (np.tanh((np.tanh((np.tanh(((3.42168045043945312)))))))))/2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((data[:,6]) - (data[:,9]))) + (data[:,7]))/2.0)) * 2.0)) + ((((((data[:,7]) + (data[:,9]))/2.0)) - (data[:,9]))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((data[:,22]) + (data[:,22]))) + (data[:,11]))/2.0)) + (data[:,22]))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((0.76044219732284546)) / 2.0)) + ((0.76044219732284546)))/2.0)) + (np.tanh((np.tanh((((((((0.76043862104415894)) / 2.0)) + ((1.0)))/2.0)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,12]) + (np.tanh((data[:,9]))))/2.0)) + (((((((((((data[:,12]) + (((((0.0)) + (np.tanh((((((((data[:,7]) + (data[:,6]))/2.0)) + (data[:,7]))/2.0)))))/2.0)))/2.0)) / 2.0)) / 2.0)) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,20]) / 2.0)) / 2.0)) * (((np.tanh((data[:,20]))) * (((data[:,20]) / 2.0)))))) * ((((((data[:,20]) / 2.0)) + (((data[:,20]) / 2.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_6(self,data):\n",
    "        return(0.250000*np.tanh(((((((11.68076229095458984)) + (((((11.68075847625732422)) + ((((11.47270107269287109)) + (((((11.47269725799560547)) + ((11.68076229095458984)))/2.0)))))/2.0)))/2.0)) + ((((4.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((8.0)) + ((((10.0)) + ((6.59042119979858398)))))) +\n",
    "                0.250000*np.tanh(((((((((((13.33760547637939453)) + (((((3.86388397216796875)) + (((((((8.18321037292480469)) + (data[:,4]))) + (((((((5.95386552810668945)) + ((12.93883609771728516)))) + (((((10.73907089233398438)) + ((4.0)))/2.0)))/2.0)))/2.0)))/2.0)))/2.0)) + (np.tanh(((3.0)))))) - ((2.0)))) + (((((10.61559963226318359)) + (data[:,1]))/2.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh(((((((((((7.13513946533203125)) + ((12.48778533935546875)))/2.0)) + (((((((7.13513565063476562)) - ((8.12031841278076172)))) + (((((((((7.13513565063476562)) + ((((10.69830417633056641)) + ((10.69830799102783203)))))) + ((10.69830799102783203)))) + ((7.83078956604003906)))/2.0)))/2.0)))/2.0)) * 2.0)))) + ((3.0)))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,7]) - (data[:,0]))) * 2.0)) - (data[:,7]))) + (data[:,7]))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((data[:,7]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((1.0)) + (((((((data[:,2]) + (((((((1.0)) * (data[:,2]))) + (data[:,14]))/2.0)))/2.0)) + ((1.0)))/2.0)))) + ((((1.0)) - (((data[:,2]) * (data[:,14]))))))/2.0)) - (data[:,2]))) * 2.0)) + (data[:,14]))/2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((np.tanh((np.tanh(((((((data[:,19]) * ((0.0)))) + ((0.0)))/2.0)))))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((0.0)) / 2.0)) / 2.0)) * (((((((((data[:,15]) / 2.0)) * ((0.0)))) / 2.0)) * ((((-1.0*(((0.0))))) / 2.0)))))) +\n",
    "                0.250000*np.tanh(((((data[:,15]) * (((((((((((((np.tanh(((((0.09032609313726425)) / 2.0)))) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)))) / 2.0)))\n",
    "    \n",
    "    def GP_class_7(self,data):\n",
    "        return(0.250000*np.tanh((10.27210903167724609)) +\n",
    "                0.250000*np.tanh((((((((((10.0)) + (((((((((8.26972770690917969)) + ((11.06334972381591797)))/2.0)) * 2.0)) / 2.0)))) + ((((((5.0)) + ((((5.0)) + ((7.92727756500244141)))))) * 2.0)))) * ((7.92728137969970703)))) + ((10.0)))) +\n",
    "                0.250000*np.tanh((8.42519950866699219)) +\n",
    "                0.250000*np.tanh(((((((data[:,14]) + (data[:,14]))) + ((((((1.59392631053924561)) + (data[:,14]))) + (data[:,14]))))) + (np.tanh((((((data[:,14]) + (((((((3.0)) + (((data[:,14]) * 2.0)))/2.0)) + ((1.59391915798187256)))))) + ((1.59392631053924561)))))))) +\n",
    "                0.250000*np.tanh((((data[:,7]) + (((data[:,0]) + (((((((data[:,7]) + (data[:,4]))/2.0)) + (((data[:,7]) * 2.0)))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((data[:,9]) - (((data[:,0]) - (data[:,0]))))) - (((data[:,0]) / 2.0)))) / 2.0)) - (((data[:,21]) - (data[:,7]))))) + (data[:,21]))/2.0)) - (data[:,0]))) +\n",
    "                0.250000*np.tanh((((((((((2.0)) + ((((((data[:,21]) + ((((data[:,13]) + (((((((((((data[:,13]) * 2.0)) + (data[:,21]))/2.0)) + (data[:,13]))/2.0)) * 2.0)))/2.0)))/2.0)) - (np.tanh(((((0.0)) - (data[:,21]))))))))) + ((1.0)))/2.0)) + (data[:,13]))/2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,14]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((-1.0*(((((((data[:,21]) / 2.0)) + (data[:,8]))/2.0))))) / 2.0)) / 2.0)) / 2.0)) + (data[:,9]))/2.0)) / 2.0)) + ((((((((((((data[:,7]) / 2.0)) / 2.0)) / 2.0)) / 2.0)) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((np.tanh(((1.0)))) / 2.0)) / 2.0)) / 2.0)))\n",
    "    \n",
    "    def GP_class_8(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,0]) + (((((6.71804094314575195)) + (data[:,15]))/2.0)))) + ((((((11.56385326385498047)) * 2.0)) * ((((10.48986148834228516)) + ((11.56385326385498047)))))))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((data[:,14]) / 2.0)) + ((2.83755254745483398)))/2.0)) + ((((((data[:,12]) + (data[:,14]))/2.0)) + (data[:,14]))))) + ((((data[:,9]) + (((data[:,12]) + (data[:,14]))))/2.0)))) +\n",
    "                0.250000*np.tanh(((((((((data[:,6]) + (((((((3.50821948051452637)) + ((((data[:,21]) + ((11.92932796478271484)))/2.0)))) + ((1.0)))/2.0)))) + (data[:,10]))/2.0)) + (data[:,21]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) + (np.tanh((np.tanh(((-1.0*((((data[:,22]) - (data[:,13])))))))))))) +\n",
    "                0.250000*np.tanh(((((1.0)) + ((((data[:,7]) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,21]) / 2.0)) / 2.0)) * (((((((np.tanh((((np.tanh((data[:,13]))) / 2.0)))) / 2.0)) + (((((((np.tanh(((((data[:,21]) + (data[:,21]))/2.0)))) / 2.0)) - (data[:,12]))) / 2.0)))) / 2.0)))) - (data[:,12]))) +\n",
    "                0.250000*np.tanh((((data[:,7]) + (np.tanh(((((data[:,12]) + (((data[:,7]) * ((((data[:,13]) + (data[:,13]))/2.0)))))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,13]) / 2.0)) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((np.tanh((data[:,9]))) + (data[:,13]))/2.0)) + ((((((((data[:,21]) / 2.0)) * 2.0)) + ((((3.94983267784118652)) / 2.0)))/2.0)))/2.0)) + ((((np.tanh(((3.94983267784118652)))) + (data[:,9]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((((data[:,14]) * (((((((((data[:,19]) / 2.0)) * (np.tanh((((data[:,2]) / 2.0)))))) / 2.0)) / 2.0)))) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)) * (((((data[:,11]) / 2.0)) / 2.0)))))\n",
    "    \n",
    "    def GP_class_9(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,14]) * 2.0)) / 2.0)) + (((((data[:,14]) + (np.tanh((((data[:,14]) * 2.0)))))) + (data[:,14]))))) +\n",
    "                0.250000*np.tanh(((data[:,9]) - (((((-1.0*((data[:,11])))) + (data[:,9]))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,21]) * 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,14]))/2.0)) + ((((data[:,13]) + ((((np.tanh((((data[:,9]) + ((6.0)))))) + (data[:,9]))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh(np.tanh(((1.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh((np.tanh(((((np.tanh((((data[:,20]) * (((((((np.tanh((((data[:,20]) / 2.0)))) + (data[:,12]))/2.0)) + ((((data[:,15]) + ((((data[:,17]) + (data[:,9]))/2.0)))/2.0)))/2.0)))))) + (data[:,9]))/2.0)))))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,2]) - (data[:,11]))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,13]) / 2.0)) + (((data[:,7]) + (data[:,7]))))/2.0)) - (((((data[:,22]) + (((((data[:,14]) * (((((data[:,7]) * (((data[:,13]) - ((((data[:,7]) + (((((data[:,13]) / 2.0)) + (data[:,7]))))/2.0)))))) / 2.0)))) * 2.0)))) / 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((((data[:,1]) / 2.0)) + ((1.0)))/2.0)) + ((1.0)))/2.0)) + ((((((((((1.0)) / 2.0)) + (np.tanh(((1.0)))))/2.0)) + (np.tanh((((((1.0)) + ((1.0)))/2.0)))))/2.0)))/2.0)) + ((((data[:,20]) + ((1.0)))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,1]) * ((((data[:,14]) + (np.tanh(((((0.0)) / 2.0)))))/2.0)))))\n",
    "    \n",
    "    def GP_class_10(self,data):\n",
    "        return(0.250000*np.tanh((((((((((data[:,2]) + (((data[:,9]) * (np.tanh((data[:,14]))))))/2.0)) + ((((((data[:,14]) + (data[:,20]))/2.0)) + (data[:,0]))))/2.0)) + (data[:,14]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,9]) + ((-1.0*((((((((2.04309988021850586)) + (((data[:,11]) + (((np.tanh((data[:,0]))) / 2.0)))))/2.0)) * 2.0))))))/2.0)) + (data[:,2]))) +\n",
    "                0.250000*np.tanh(data[:,21]) +\n",
    "                0.250000*np.tanh((((((((data[:,14]) + (np.tanh((((data[:,6]) / 2.0)))))/2.0)) + (data[:,14]))) + (((((data[:,14]) * 2.0)) + ((((data[:,13]) + (data[:,14]))/2.0)))))) +\n",
    "                0.250000*np.tanh(data[:,9]) +\n",
    "                0.250000*np.tanh(((((((data[:,15]) * 2.0)) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((2.72836518287658691)) * ((((1.0)) / 2.0)))) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((np.tanh((((data[:,7]) + (np.tanh(((((((((((0.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)))))))) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(np.tanh((((np.tanh(((11.43236827850341797)))) / 2.0)))) +\n",
    "                0.250000*np.tanh(np.tanh((((data[:,7]) / 2.0)))))\n",
    "    \n",
    "    def GP_class_11(self,data):\n",
    "        return(0.250000*np.tanh((-1.0*((((((((((((((data[:,5]) - (((data[:,9]) - ((((-1.0*(((11.40053558349609375))))) / 2.0)))))) + ((((11.40053558349609375)) + ((((11.40053558349609375)) * 2.0)))))) / 2.0)) - (data[:,7]))) - ((-1.0*(((11.40053939819335938))))))) * 2.0))))) +\n",
    "                0.250000*np.tanh(((((data[:,14]) * 2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((data[:,5]) + (data[:,3]))) + ((((data[:,2]) + (((data[:,3]) * 2.0)))/2.0)))))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,21]) + (data[:,21]))) + ((-1.0*(((((np.tanh((np.tanh((((data[:,14]) / 2.0)))))) + (data[:,21]))/2.0))))))/2.0)) * 2.0)) + ((((data[:,14]) + (data[:,3]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,0]) + ((((data[:,9]) + ((((data[:,9]) + (((((((((((((((data[:,9]) / 2.0)) - (data[:,10]))) + (data[:,5]))/2.0)) - (data[:,9]))) + (data[:,9]))/2.0)) / 2.0)))/2.0)))/2.0)))/2.0)) + (data[:,9]))/2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,13]) + ((((data[:,13]) + (data[:,13]))/2.0)))) + (data[:,1]))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(data[:,14]) +\n",
    "                0.250000*np.tanh(((((data[:,2]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((data[:,9]) + (data[:,9]))/2.0)) +\n",
    "                0.250000*np.tanh(data[:,2]))\n",
    "    \n",
    "    def GP_class_12(self,data):\n",
    "        return(0.250000*np.tanh((((((((-1.0*((data[:,18])))) - (np.tanh((data[:,9]))))) + ((8.0)))) - ((14.74865913391113281)))) +\n",
    "                0.250000*np.tanh((((((data[:,21]) + (np.tanh((data[:,9]))))) + ((((((((data[:,5]) / 2.0)) * 2.0)) + (data[:,5]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,14]) + (data[:,14]))) + (((data[:,14]) * 2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((((data[:,14]) + ((((np.tanh((data[:,10]))) + (data[:,17]))/2.0)))/2.0)) + (data[:,21]))/2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,9]) + ((((((((((((data[:,9]) + ((((((data[:,9]) / 2.0)) + (((data[:,9]) * 2.0)))/2.0)))/2.0)) + ((-1.0*((data[:,21])))))/2.0)) * (data[:,9]))) + (((((np.tanh((((data[:,21]) / 2.0)))) / 2.0)) / 2.0)))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((0.0)) + (data[:,13]))/2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,2]) / 2.0)) * 2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) * 2.0)) + (np.tanh((data[:,14]))))/2.0)) +\n",
    "                0.250000*np.tanh(np.tanh((((((((((-1.0*((((np.tanh((data[:,9]))) / 2.0))))) / 2.0)) / 2.0)) + (((data[:,3]) * (data[:,13]))))/2.0)))) +\n",
    "                0.250000*np.tanh((-1.0*((((((((-1.0*(((((((-1.0*((data[:,18])))) - ((((0.0)) / 2.0)))) / 2.0))))) + (np.tanh(((((-1.0*(((-1.0*((data[:,22]))))))) / 2.0)))))/2.0)) / 2.0))))))\n",
    "    \n",
    "    def GP_class_13(self,data):\n",
    "        return(0.250000*np.tanh(((((np.tanh((np.tanh((data[:,2]))))) - ((10.0)))) - (np.tanh((((((data[:,7]) - ((((((6.0)) - ((4.87243366241455078)))) - ((9.0)))))) - ((14.80352973937988281)))))))) +\n",
    "                0.250000*np.tanh(((np.tanh((((((3.0)) + (data[:,1]))/2.0)))) - ((7.0)))) +\n",
    "                0.250000*np.tanh(((((np.tanh((np.tanh((np.tanh((data[:,6]))))))) * 2.0)) - ((6.10337877273559570)))) +\n",
    "                0.250000*np.tanh(((((((data[:,9]) + (data[:,14]))) + (data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((((np.tanh(((((-1.0*(((((((data[:,2]) + ((10.0)))/2.0)) / 2.0))))) - ((13.28130435943603516)))))) + ((10.0)))) - ((13.28130435943603516)))) + ((-1.0*((data[:,5])))))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,20]) + (((((((((data[:,20]) * 2.0)) * 2.0)) * 2.0)) + (data[:,13]))))/2.0)) + (((data[:,9]) + (((data[:,9]) + (((data[:,6]) + (data[:,9]))))))))/2.0)) + (data[:,20]))) + (data[:,15]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,14]) / 2.0)) + ((((data[:,9]) + (((data[:,15]) + (((data[:,5]) + ((((((data[:,9]) + (((data[:,5]) + (data[:,14]))))) + (data[:,9]))/2.0)))))))/2.0)))) * 2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh((((data[:,13]) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,9]) + ((((data[:,3]) + ((((data[:,21]) + (data[:,3]))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,2]) + (((((((((((((((data[:,20]) + (data[:,1]))) + (((data[:,2]) + (data[:,14]))))) + (data[:,2]))) + (np.tanh((data[:,2]))))/2.0)) + (((data[:,14]) + (data[:,2]))))) + (data[:,14]))/2.0)))/2.0)))\n",
    "    \n",
    "    def GP_class_14(self,data):\n",
    "        return(0.250000*np.tanh((((((((((((5.54024744033813477)) - ((((((9.0)) * 2.0)) * 2.0)))) - (data[:,0]))) - ((((7.0)) + ((4.74105215072631836)))))) - (((((7.0)) + (((data[:,5]) * 2.0)))/2.0)))) - ((9.0)))) +\n",
    "                0.250000*np.tanh(((((((((9.0)) - ((14.27298927307128906)))) - (data[:,0]))) + (np.tanh(((((12.77708148956298828)) - ((14.80560111999511719)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((0.0)) + ((-1.0*((((data[:,22]) + (((((((((13.30077362060546875)) - (np.tanh((data[:,4]))))) + (((data[:,22]) / 2.0)))/2.0)) / 2.0))))))))/2.0)) - (((np.tanh((((data[:,7]) - (data[:,7]))))) / 2.0)))) +\n",
    "                0.250000*np.tanh(((((((data[:,6]) + (data[:,14]))/2.0)) + (((np.tanh((((((data[:,14]) + (data[:,14]))) + (((data[:,6]) - (((data[:,5]) + (((np.tanh((data[:,21]))) + ((((data[:,14]) + ((((data[:,14]) + (data[:,14]))/2.0)))/2.0)))))))))))) + (data[:,5]))))/2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((((data[:,2]) + (data[:,16]))) + ((((((data[:,2]) / 2.0)) + (data[:,9]))/2.0)))/2.0)) + (np.tanh((data[:,10]))))/2.0)) + (data[:,9]))) + (data[:,9]))/2.0)) + (data[:,21]))) + (data[:,3]))) +\n",
    "                0.250000*np.tanh((((data[:,13]) + (((((((((((data[:,3]) / 2.0)) / 2.0)) / 2.0)) * (data[:,3]))) / 2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) + (((((((data[:,14]) / 2.0)) + (data[:,14]))) * 2.0)))) +\n",
    "                0.250000*np.tanh(data[:,9]) +\n",
    "                0.250000*np.tanh(((data[:,1]) / 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,2]) + ((((((data[:,13]) + (data[:,14]))) + (data[:,13]))/2.0)))) + (np.tanh((data[:,2]))))/2.0)))\n",
    "    \n",
    "    def GP_class_15(self,data):\n",
    "        return(0.250000*np.tanh((((((((4.0)) + ((((8.0)) / 2.0)))) - ((9.56193733215332031)))) - (((((np.tanh(((13.93556308746337891)))) - (data[:,18]))) + ((13.93556308746337891)))))) +\n",
    "                0.250000*np.tanh(((data[:,4]) - ((((12.76094818115234375)) - (data[:,8]))))) +\n",
    "                0.250000*np.tanh((((-1.0*(((12.35446166992187500))))) - (((((12.35446166992187500)) + ((((((12.35446166992187500)) - ((-1.0*(((0.0))))))) - (data[:,0]))))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,21]) - ((14.46367263793945312)))) +\n",
    "                0.250000*np.tanh(((((data[:,2]) + ((((data[:,9]) + ((-1.0*(((-1.0*(((-1.0*((((data[:,7]) * (((data[:,21]) * 2.0))))))))))))))/2.0)))) + (data[:,9]))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,7]) + (data[:,3]))/2.0)) + (data[:,20]))/2.0)) - ((((2.33354020118713379)) / 2.0)))) - ((((2.0)) + ((8.78930377960205078)))))) +\n",
    "                0.250000*np.tanh(((((((data[:,14]) + (((((((data[:,14]) + (((data[:,15]) + (data[:,14]))))) + (((data[:,15]) + (data[:,14]))))) + (((data[:,14]) / 2.0)))))) + (data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,13]) + (data[:,13]))) + (((data[:,13]) + (data[:,12]))))) + (data[:,9]))) + ((((((data[:,9]) + (((data[:,13]) + ((((data[:,9]) + (((((data[:,13]) * 2.0)) / 2.0)))/2.0)))))/2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,9]) + ((((((data[:,9]) + (data[:,9]))/2.0)) / 2.0)))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,8]))) + (data[:,14]))/2.0)))\n",
    "    \n",
    "    def GP_class_16(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((((9.37592792510986328)) - ((13.36316204071044922)))) + ((11.89122962951660156)))/2.0)) - ((((9.0)) - (((((((data[:,13]) / 2.0)) / 2.0)) + ((((-1.0*((((data[:,4]) / 2.0))))) * 2.0)))))))) - ((12.24639320373535156)))) - ((11.89122581481933594)))) +\n",
    "                0.250000*np.tanh(((((np.tanh(((4.51821422576904297)))) - ((13.23712635040283203)))) - ((((((13.23712635040283203)) + (((data[:,22]) - ((((11.40539550781250000)) - (((((9.0)) + ((((((((data[:,7]) + (((data[:,17]) / 2.0)))/2.0)) * 2.0)) / 2.0)))/2.0)))))))) - (data[:,5]))))) +\n",
    "                0.250000*np.tanh(((data[:,14]) - ((((4.0)) + (((((13.41770648956298828)) + ((12.42538261413574219)))/2.0)))))) +\n",
    "                0.250000*np.tanh((((5.0)) - ((9.27778816223144531)))) +\n",
    "                0.250000*np.tanh(((((data[:,16]) - (((((((data[:,1]) - (((np.tanh((((((((9.29507255554199219)) - (((((((14.34461498260498047)) * 2.0)) + (((((7.0)) + ((9.10683441162109375)))/2.0)))/2.0)))) + ((4.21145153045654297)))/2.0)))) * 2.0)))) - ((9.10683441162109375)))) * 2.0)))) - ((((14.34461498260498047)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((((((data[:,17]) / 2.0)) + (((data[:,13]) + (data[:,9]))))/2.0)) + (((data[:,17]) + (data[:,9]))))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((data[:,13]) + (((data[:,14]) - (data[:,21]))))) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,5]))/2.0)) + (((((((data[:,9]) / 2.0)) + (data[:,14]))) / 2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,17]) + (data[:,9]))) + (((((data[:,17]) / 2.0)) + ((((((((((data[:,9]) + (data[:,9]))) - ((3.0)))) + (data[:,7]))) + (data[:,9]))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh(np.tanh(((((((((((((((data[:,2]) + (((((((((((data[:,22]) + (data[:,21]))/2.0)) + (data[:,2]))/2.0)) * 2.0)) + ((((((data[:,21]) * 2.0)) + (data[:,21]))/2.0)))))) + (data[:,2]))/2.0)) + (data[:,17]))/2.0)) + (np.tanh((data[:,8]))))/2.0)) + (data[:,2]))))))\n",
    "    \n",
    "    def GP_class_17(self,data):\n",
    "        return(0.250000*np.tanh(((((data[:,14]) - ((((data[:,5]) + (((((14.43326377868652344)) + ((6.0)))/2.0)))/2.0)))) - (((((((10.0)) + ((14.84462165832519531)))/2.0)) - ((((7.0)) + (data[:,13]))))))) +\n",
    "                0.250000*np.tanh((((((((((data[:,14]) + (((((((((data[:,11]) - ((9.71331787109375000)))) / 2.0)) + ((9.0)))) - ((3.0)))))/2.0)) - ((10.0)))) - ((((10.0)) + ((((9.0)) - ((((((10.0)) - ((9.0)))) / 2.0)))))))) - ((10.0)))) +\n",
    "                0.250000*np.tanh((((((((((8.0)) - ((12.78277492523193359)))) - (data[:,10]))) - (np.tanh(((((((7.0)) - ((14.95321178436279297)))) - ((8.0)))))))) - ((14.95321178436279297)))) +\n",
    "                0.250000*np.tanh((((7.45682907104492188)) - ((14.98023796081542969)))) +\n",
    "                0.250000*np.tanh(((((((((((7.0)) + (((((np.tanh((((((((8.0)) * (data[:,8]))) + (data[:,11]))/2.0)))) / 2.0)) - ((8.0)))))/2.0)) - (data[:,20]))) - ((((8.0)) * 2.0)))) + ((8.0)))) +\n",
    "                0.250000*np.tanh(((data[:,8]) + (((data[:,4]) + (((np.tanh((data[:,4]))) + (((data[:,13]) + (data[:,13]))))))))) +\n",
    "                0.250000*np.tanh(data[:,14]) +\n",
    "                0.250000*np.tanh(((((((((((data[:,14]) + (np.tanh((((data[:,3]) * (data[:,13]))))))) + (data[:,14]))) + (data[:,0]))) + (data[:,8]))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,9]) + (np.tanh(((((((data[:,19]) * (((((((data[:,1]) + (((((((data[:,21]) + (data[:,9]))/2.0)) + (data[:,6]))/2.0)))/2.0)) + (data[:,17]))/2.0)))) + (((data[:,15]) / 2.0)))/2.0)))))/2.0)) * 2.0)) +\n",
    "                0.250000*np.tanh(((data[:,1]) + (((((data[:,3]) + (data[:,15]))) + (np.tanh(((((data[:,20]) + (((data[:,1]) * 2.0)))/2.0)))))))))\n",
    "    \n",
    "    def GP_class_18(self,data):\n",
    "        return(0.250000*np.tanh((((((((((12.59485149383544922)) - ((12.59485149383544922)))) - ((12.59485149383544922)))) - ((((11.47756862640380859)) / 2.0)))) - ((12.59485149383544922)))) +\n",
    "                0.250000*np.tanh((((((-1.0*(((11.26121807098388672))))) - (((((((((11.33140659332275391)) - ((-1.0*(((9.76293182373046875))))))) - (((((11.33140659332275391)) + ((8.0)))/2.0)))) + ((9.76293182373046875)))/2.0)))) - (data[:,11]))) +\n",
    "                0.250000*np.tanh(((((((((((3.40250444412231445)) - (np.tanh(((14.86789989471435547)))))) - ((14.86789989471435547)))) + ((((((data[:,5]) + ((-1.0*(((((14.86789989471435547)) * 2.0))))))/2.0)) - ((14.86789989471435547)))))/2.0)) - (((((14.86789989471435547)) + (((((7.0)) + ((-1.0*((data[:,16])))))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,18]) - ((11.84332561492919922)))) +\n",
    "                0.250000*np.tanh(((((np.tanh(((((8.96548557281494141)) * (data[:,12]))))) - ((-1.0*((((data[:,2]) * (((((data[:,4]) - ((-1.0*((data[:,9])))))) - ((9.0))))))))))) - ((8.96548557281494141)))) +\n",
    "                0.250000*np.tanh(((((((10.0)) - (data[:,12]))) + (((((((((data[:,13]) - ((12.43707370758056641)))) - ((((12.43707370758056641)) - (((data[:,12]) / 2.0)))))) - ((((12.43707370758056641)) - ((((data[:,13]) + ((12.43707370758056641)))/2.0)))))) - ((12.43707370758056641)))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((np.tanh((((np.tanh((data[:,14]))) + (data[:,13]))))) * 2.0)) + (data[:,14]))) + (data[:,13]))) +\n",
    "                0.250000*np.tanh(((np.tanh((data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((data[:,9]) + (((((data[:,13]) + (data[:,4]))) + (data[:,13]))))) / 2.0)) +\n",
    "                0.250000*np.tanh(((data[:,15]) - ((((data[:,3]) + ((5.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_19(self,data):\n",
    "        return(0.250000*np.tanh((((((data[:,13]) + (data[:,13]))/2.0)) + ((((((data[:,8]) + ((((data[:,14]) + (data[:,14]))/2.0)))/2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,3]) + (((data[:,8]) + (np.tanh(((((((-1.0*((((((9.05535793304443359)) + ((((data[:,14]) + (((((((data[:,1]) - (((data[:,12]) * 2.0)))) * ((-1.0*((data[:,17])))))) / 2.0)))/2.0)))/2.0))))) + (data[:,2]))) * 2.0)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,3]) + (((((data[:,14]) + (data[:,14]))) * 2.0)))) + ((((data[:,14]) + (np.tanh((((data[:,14]) + (np.tanh((data[:,14]))))))))/2.0)))) * 2.0)) + ((((data[:,14]) + (data[:,2]))/2.0)))) +\n",
    "                0.250000*np.tanh(((((data[:,8]) + (((data[:,4]) + (((data[:,13]) + (data[:,10]))))))) + (((((data[:,13]) + (((((data[:,13]) / 2.0)) + (data[:,9]))))) + (np.tanh(((((data[:,8]) + (data[:,8]))/2.0)))))))) +\n",
    "                0.250000*np.tanh((((((data[:,19]) + (((((data[:,10]) + ((((data[:,11]) + (data[:,19]))/2.0)))) + (data[:,10]))))/2.0)) + (data[:,2]))) +\n",
    "                0.250000*np.tanh((((((data[:,0]) + (((((((((data[:,0]) + (((((data[:,0]) - (data[:,11]))) / 2.0)))/2.0)) * 2.0)) + ((((((np.tanh((data[:,13]))) + (((data[:,0]) / 2.0)))/2.0)) / 2.0)))/2.0)))/2.0)) * 2.0)) +\n",
    "                0.250000*np.tanh(((((-1.0*((data[:,15])))) + (((data[:,14]) + (data[:,14]))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,0]) + (data[:,15]))/2.0)) + (((data[:,15]) * (data[:,15]))))/2.0)) - (data[:,11]))) +\n",
    "                0.250000*np.tanh(data[:,13]) +\n",
    "                0.250000*np.tanh(((((((((data[:,18]) + ((((data[:,4]) + (data[:,18]))/2.0)))) / 2.0)) + ((((data[:,18]) + (data[:,4]))/2.0)))) * (data[:,4])))    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from kaggle.competitions import nflrush\n",
    "env = nflrush.make_env()\n",
    "iter_test = env.iter_test()\n",
    "gp = GP()\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    basetable = create_features(test_df, deploy=True)\n",
    "    basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n",
    "    scaled_basetable = scaler.transform(basetable)\n",
    "    \n",
    "    p = [m.predict(scaled_basetable) for m in models]\n",
    "    y_pred_nn = (np.array(p)).mean(0)\n",
    "    #np.expm1(np.log1p(np.array(p)).mean(0))\n",
    "\n",
    "    y_pred_gp = np.zeros((test_df.shape[0],199))\n",
    "    ans = gp.GrabPredictions(scaled_basetable)\n",
    "    y_pred_gp[:,96:96+20] = ans\n",
    "    \n",
    "    y_pred = (.6*y_pred_nn+.4*y_pred_gp)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n",
    "    \n",
    "    preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n",
    "    env.predict(preds_df)\n",
    "    \n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
