{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import datetime, tqdm\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "pd.set_option('max_columns', 100)\n",
    "#from kaggle.competitions import nflrush\n",
    "from sklearn.model_selection import KFold, RepeatedKFold,GroupKFold\n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense,Dropout, PReLU, BatchNormalization, ELU, GaussianNoise, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import keras.backend as K\n",
    "#note： \n",
    "#1. As a result it might not be worthwhile to use features related to game clock/quarter of the game。\n",
    "#2. There is no relationships between number of rushes before and running yards gained。\n",
    "#3. rushing success larger depends on defender in box, or defender that are close to offensive lineman and attempt \n",
    "#   to counter the blocking.\n",
    "#4. highly drafted player has the same average rushing yards as the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\38980\\OneDrive\\Desktop\\study\\kaggle\\NFL\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team abbreviations correct\n",
    "def data_clean(df):\n",
    "#correct name   \n",
    "    df.loc[df['PossessionTeam'] == 'ARZ', 'PossessionTeam'] = 'ARI'\n",
    "    df.loc[df['PossessionTeam'] == 'BLT', 'PossessionTeam'] = 'BAL'\n",
    "    df.loc[df['PossessionTeam'] == 'CLV', 'PossessionTeam'] = 'CLE'\n",
    "    df.loc[df['PossessionTeam'] == 'HST', 'PossessionTeam'] = 'HOU'\n",
    "    df.loc[df['FieldPosition'] == 'ARZ', 'FieldPosition'] = 'ARI'\n",
    "    df.loc[df['FieldPosition'] == 'BLT', 'FieldPosition'] = 'BAL'\n",
    "    df.loc[df['FieldPosition'] == 'CLV', 'FieldPosition'] = 'CLE'\n",
    "    df.loc[df['FieldPosition'] == 'HST', 'FieldPosition'] = 'HOU'\n",
    "\n",
    "\n",
    "# offense time and defence time\n",
    "    df['TeamOnOffense'] = \"home\"\n",
    "    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    df['IsOnOffense'] = df.Team == df.TeamOnOffense # Is player on offense?\n",
    "    \n",
    "#time\n",
    "    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    seconds_in_year = 60*60*24*365.25\n",
    "    df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "    df['GameClock'] = df['GameClock'].apply(lambda x: float(x.split(\":\")[0]) + float(x.split(\":\")[1])/60)\n",
    "    df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "#player height\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "\n",
    "#weather\n",
    "    def map_weather(txt):\n",
    "        ans = 1\n",
    "        if pd.isna(txt):\n",
    "            return 0\n",
    "        if 'partly' in txt:\n",
    "            ans*=0.5\n",
    "        if 'climate controlled' in txt or 'indoor' in txt:\n",
    "            return ans*3\n",
    "        if 'sunny' in txt or 'sun' in txt:\n",
    "            return ans*2\n",
    "        if 'clear' in txt:\n",
    "            return ans\n",
    "        if 'cloudy' in txt:\n",
    "            return -ans\n",
    "        if 'rain' in txt or 'rainy' in txt:\n",
    "            return -2*ans\n",
    "        if 'snow' in txt:\n",
    "            return -3*ans\n",
    "        return 0\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['Cleaned_GameWeather'].apply(map_weather)\n",
    "\n",
    "#diff Score    \n",
    "    df[\"DiffScoreBeforePlay_ob\"] = (df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"])\n",
    "    df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]] = - df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]]\n",
    "\n",
    "#left to right\n",
    "    df['New_X'] = df['X']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_X'] = 120 - df.loc[df['PlayDirection'] == 'left','X']\n",
    "    df['New_Y'] = df['Y']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_Y'] = 160/3 - df.loc[df['PlayDirection'] == 'left','Y']\n",
    "    df['Orientation_std'] = df['Orientation']\n",
    "    df.loc[df['Season'] == 2017, 'Orientation_std'] = df.loc[df['Season'] == 2017, 'Orientation_std'] + 90\n",
    "    #df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std'] = 360 - df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Orientation_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Orientation_std'], 360)\n",
    "    df['Dir_std'] = df['Dir']\n",
    "    #df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = 360 - df.loc[df['PlayDirection'] == 'left', 'Dir_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Dir_std'], 360)\n",
    "    df['YardLine_std'] = 100 - df['YardLine']\n",
    "    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine_std'\n",
    "         ] = df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine']\n",
    "    df[\"Orientation_sin\"] = df[\"Orientation_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Orientation_cos\"] = df[\"Orientation_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_sin\"] = df[\"Dir_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_cos\"] = df[\"Dir_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "\n",
    "#distance and S\n",
    "    \n",
    "    #distance to yardline\n",
    "    df['Dis_YardLine'] = df['New_X'] - df['YardLine_std'] - 10\n",
    "    \n",
    "    #distance to rusher\n",
    "    def Distance(x1,x2,y1,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "    def Degree(x1,x2,y1,y2):\n",
    "        try:\n",
    "            tan = (y1-y2)/(x1-x2)\n",
    "        except:\n",
    "            tan = 0\n",
    "        degree = 90 - math.atan(tan)/(2*np.pi)*360\n",
    "        return degree\n",
    "    df['IsRusher'] = (df['NflId'] == df['NflIdRusher'])\n",
    "    Rusher =df.loc[df['IsRusher'],['PlayId','X','Y','Dir_std','S']].rename(columns={\"X\":\"Rusher_X\",\"Y\":\"Rusher_Y\",'PossessionTeam':'Offense_Team','Dir_std':'Rusher_Dir_std','S':'Rusher_Speed'})\n",
    "    df = df.merge(Rusher,how = 'left',on = 'PlayId')\n",
    "    df['Distance_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Distance(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_to_Rusher'] = df[[\"X\",\"Rusher_X\",\"Y\",\"Rusher_Y\"]].apply(lambda x: Degree(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_Diff'] = df['Degree_to_Rusher'] - df['Rusher_Dir_std']\n",
    "    df['Degree_Diff2'] = 270 - (90-df['Degree_to_Rusher']) - df['Dir_std']\n",
    "    df['Speed_Ratio'] =  (df['Rusher_Speed']+0.01)/(df['S']+0.01)\n",
    "\n",
    "\n",
    "# speed\n",
    "    df.loc[df['Season'] == 2017, 'S'] = (df.loc[df['Season'] == 2017, 'S'] - 2.4355) / 1.2930 * 1.4551 + 2.7570\n",
    "    df['Horizontal Speed'] = df['S']*df[\"Dir_sin\"]\n",
    "    df['Vertical Speed'] = df['S']*df[\"Dir_cos\"]\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: RuntimeWarning: invalid value encountered in remainder\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in remainder\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:96: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "train = data_clean(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PlayId  num_def  num_of  def-of\n",
      "0      20170907000118        1     2.0    -1.0\n",
      "1      20170907000189       10    11.0    -1.0\n",
      "2      20170907000516        7     8.0    -1.0\n",
      "3      20170907000917        7     8.0    -1.0\n",
      "4      20170907001077        2     2.0     0.0\n",
      "5      20170907001156        9    10.0    -1.0\n",
      "6      20170907001488        5     6.0    -1.0\n",
      "7      20170907001509        4     5.0    -1.0\n",
      "8      20170907001530        4     6.0    -2.0\n",
      "9      20170907001605        4     6.0    -2.0\n",
      "10     20170907001715        1     NaN     NaN\n",
      "11     20170907002648        4     4.0     0.0\n",
      "12     20170907002829        3     3.0     0.0\n",
      "13     20170907002900        5     8.0    -3.0\n",
      "14     20170907003444        4     4.0     0.0\n",
      "15     20170907003465        5     6.0    -1.0\n",
      "16     20170907003507        4     4.0     0.0\n",
      "17     20170907004046        6     9.0    -3.0\n",
      "18     20170907004182        5     7.0    -2.0\n",
      "19     20170907004465        3     5.0    -2.0\n",
      "20     20170907004721        6     7.0    -1.0\n",
      "21     20170910000221        9    10.0    -1.0\n",
      "22     20170910000242        8    10.0    -2.0\n",
      "23     20170910000263        7     9.0    -2.0\n",
      "24     20170910000358        4     4.0     0.0\n",
      "25     20170910001020        8     9.0    -1.0\n",
      "26     20170910001102        5     6.0    -1.0\n",
      "27     20170910001123        5     6.0    -1.0\n",
      "28     20170910001522        4     5.0    -1.0\n",
      "29     20170910001622        5     5.0     0.0\n",
      "...               ...      ...     ...     ...\n",
      "23075  20181230150105        4     3.0     1.0\n",
      "23076  20181230150181        2     2.0     0.0\n",
      "23077  20181230150371        5     5.0     0.0\n",
      "23078  20181230150440        6     7.0    -1.0\n",
      "23079  20181230150528        8    10.0    -2.0\n",
      "23080  20181230150550       10    10.0     0.0\n",
      "23081  20181230150618        6     7.0    -1.0\n",
      "23082  20181230150826        1     NaN     NaN\n",
      "23083  20181230150927        5     4.0     1.0\n",
      "23084  20181230151022        8     9.0    -1.0\n",
      "23085  20181230151427        7     7.0     0.0\n",
      "23086  20181230151537        4     3.0     1.0\n",
      "23087  20181230151672        6     5.0     1.0\n",
      "23088  20181230151746        9    11.0    -2.0\n",
      "23089  20181230152303        4     2.0     2.0\n",
      "23090  20181230152535        5     4.0     1.0\n",
      "23091  20181230152582        6     6.0     0.0\n",
      "23092  20181230152720        5     5.0     0.0\n",
      "23093  20181230152792        3     4.0    -1.0\n",
      "23094  20181230153023        5     4.0     1.0\n",
      "23095  20181230153136        7     8.0    -1.0\n",
      "23096  20181230153158        8     9.0    -1.0\n",
      "23097  20181230153420        4     2.0     2.0\n",
      "23098  20181230153515        4     3.0     1.0\n",
      "23099  20181230153631        6     6.0     0.0\n",
      "23100  20181230153866        4     3.0     1.0\n",
      "23101  20181230153888        6     8.0    -2.0\n",
      "23102  20181230153910       10    11.0    -1.0\n",
      "23103  20181230154035        5     7.0    -2.0\n",
      "23104  20181230154157        4     4.0     0.0\n",
      "\n",
      "[23105 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "temp = train.drop(train[(train['Position'].isin(['FS','S','SS'])) & (train['Distance_to_Rusher']>15)].index)\n",
    "temp = temp.merge(train.loc[train['IsRusher'],['PlayId','New_X','New_Y','Dir_std']]\\\n",
    "                  .rename(columns={'New_X':'Rusher_X','New_Y':'Rusher_Y','Dir_std':'Rusher_Dir'}), on = 'PlayId',how = 'left')\n",
    "\n",
    "#temp2 = temp.loc[(temp['IsOnOffense'])]\n",
    "temp = temp.loc[(~temp['IsOnOffense'])]\n",
    "\n",
    "\n",
    "op_up = temp[((temp['Rusher_Dir']<90)|(temp['Rusher_Dir']>270))&(temp['New_Y']>=temp['Rusher_Y_x'])]\n",
    "op_up = op_up.sort_values(['PlayId','New_Y'])\n",
    "op_up[['Next_Y','Next_X']] = op_up[['New_Y','New_X']].shift(1,axis = 0)\n",
    "op_up['Gap'] = op_up['New_Y'] - op_up['Next_Y']\n",
    "op_up[['PlayId','New_Y','Next_Y','Gap']]\n",
    "closest_op_up = op_up[['PlayId','Gap']].groupby('PlayId').head(1).reset_index()\n",
    "best_up = op_up[['PlayId','Gap']].groupby('PlayId').max().reset_index()\n",
    "def_num_up = op_up[['PlayId','Gap']].rename(columns={'Gap': 'num_def'}).groupby('PlayId').count().reset_index()\n",
    "\n",
    "op_down = temp[(~((temp['Rusher_Dir']<90)|(temp['Rusher_Dir']>270)))&(temp['New_Y']<temp['Rusher_Y_x'])]\n",
    "op_down = op_down.sort_values(['PlayId','New_Y'])\n",
    "op_down[['Next_Y','Next_X']] = op_down[['New_Y','New_X']].shift(1,axis = 0)\n",
    "op_down['Gap'] = op_down['New_Y'] - op_down['Next_Y']\n",
    "op_down[['PlayId','New_Y','Next_Y','Gap']]\n",
    "closest_op_down = op_down[['PlayId','Gap']].groupby('PlayId').tail(1).reset_index()\n",
    "best_down = op_down[['PlayId','Gap']].groupby('PlayId').max().reset_index()\n",
    "def_num_down = op_down[['PlayId','Gap']].rename(columns={'Gap': 'num_def'}).groupby('PlayId').count().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "closest_op = closest_op_up.append(closest_op_down)\n",
    "best = best_up.append(best_down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    df1 = df.loc[df['IsRusher']]\n",
    "    df2 = df.loc[df['IsOnOffense'] & (~df['IsRusher'])]\n",
    "    df3 = df.loc[~df['IsOnOffense']]\n",
    "\n",
    "# max yards\n",
    "    df1['Max_Yards'] = df1['YardLine']\n",
    "    df1.loc[(df1.FieldPosition.fillna('') == df1.PossessionTeam)&(df1.PlayDirection =='left'),  'Max_Yards'] \\\n",
    "    = 100 - df1.loc[(df1.FieldPosition.fillna('') == df1.PossessionTeam)&(df1.PlayDirection =='left'),  'Max_Yards']\n",
    "    df1.loc[(df1.FieldPosition.fillna('') != df1.PossessionTeam)&(df1.PlayDirection =='right'),  'Max_Yards'] \\\n",
    "    = 100 - df1.loc[(df1.FieldPosition.fillna('') != df1.PossessionTeam)&(df1.PlayDirection =='right'),  'Max_Yards']\n",
    "\n",
    "# min_time_to_tacke\n",
    "    df3['Min_Time_Tacke'] = (df3['Distance_to_Rusher']+0.01)/(df3['S']+0.01)\n",
    "    df3.loc[df3['Min_Time_Tacke'] == np.inf, 'Min_Time_Tacke'] = 20\n",
    "\n",
    "# defence_X_Y_spread\n",
    "    Defence_X_Y_std = df3[[\"PlayId\",'New_X','New_Y']].groupby(\"PlayId\").std().rename(columns={'New_X':'Defense_X_std','New_Y':'Defense_Y_std'}) \\\n",
    "    .reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed2_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed2_std'}).reset_index()\n",
    "\n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_Y_Removed2_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(4).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed4_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(2).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed4_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_Y_Removed4_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(4).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Defence_X_Y_std, how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "\n",
    "#distance to QB\n",
    "    dis_QB = df2.loc[df2[\"Position\"] =='QB',['PlayId','Distance_to_Rusher']].groupby(['PlayId']).mean().rename(columns={'Distance_to_Rusher':'dis_to_QB'})\n",
    "    df1 = df1.merge(dis_QB,how = 'left', on='PlayId')\n",
    "\n",
    "#defence min,max,mean,std distance to rusher\n",
    "    stat = df3.groupby(['GameId','PlayId']).agg({'Distance_to_Rusher':['min','max','mean','std']})\n",
    "    stat.columns = stat.columns.droplevel()\n",
    "    df1 = df1.merge(stat,how = 'left', on='PlayId')\n",
    "\n",
    "# offense_X_Y_spread\n",
    "    df2 = df2.sort_values(['PlayId','New_X'])\n",
    "    Offense_X_Removed2_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed2_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed2_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_X_Removed4_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed4_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed4_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Offense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    \n",
    "# nearest offenders to defender\n",
    "    dis_to_closest_offender = pd.DataFrame()\n",
    "    dis_to_closest_defender = pd.DataFrame()\n",
    "    for playid in df3['PlayId'].unique():\n",
    "        offense = df2.loc[df2['PlayId'] == playid]\n",
    "        defence = df3.loc[df3['PlayId'] == playid]\n",
    "        ary = scipy.spatial.distance.cdist(defence[['New_X','New_Y']], offense[['New_X','New_Y']], metric='euclidean')\n",
    "        ary.sort(axis=1)\n",
    "        ary = pd.DataFrame(data = ary)\n",
    "        ary['PlayId'] = playid\n",
    "        ary.reset_index(drop=True, inplace=True)\n",
    "        ary = pd.concat([ary, defence[['NflId']].reset_index(drop=True)], axis=1)\n",
    "        dis_to_closest_offender = dis_to_closest_offender.append(ary)\n",
    "        \n",
    "        ary = scipy.spatial.distance.cdist(offense[['New_X','New_Y']], defence[['New_X','New_Y']],  metric='euclidean')\n",
    "        ary.sort(axis=1)\n",
    "        ary = pd.DataFrame(data = ary)\n",
    "        ary['PlayId'] = playid\n",
    "        ary.reset_index(drop=True, inplace=True)\n",
    "        ary = pd.concat([ary, offense[['NflId']].reset_index(drop=True)], axis=1)\n",
    "        dis_to_closest_defender = dis_to_closest_defender.append(ary)\n",
    "    df3 = df3.merge(dis_to_closest_offender,how = 'left',on = ['PlayId','NflId'])\n",
    "    df2 = df2.merge(dis_to_closest_defender,how = 'left',on = ['PlayId','NflId'])\n",
    "\n",
    "#degree to closest offender\n",
    "    def Degree(x1,x2,y1,y2):\n",
    "        try:\n",
    "            tan = (y1-y2)/(x1-x2)\n",
    "        except:\n",
    "            tan = 0\n",
    "        degree = 90 - math.atan(tan)/(2*np.pi)*360\n",
    "        return degree\n",
    "    df4 = df3.merge(df2, how = 'left', on = ['PlayId',0],suffixes=('_defender', '_offender'))\n",
    "    df4['degree_to_closest_offender'] = df4[['New_X_offender','New_X_defender','New_Y_offender','New_Y_defender']].apply(lambda x: Degree(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df3['degree_to_closest_offender'] = df4['degree_to_closest_offender']\n",
    "\n",
    "# personnel_features\n",
    "    def defense_formation(l):\n",
    "        dl = 0\n",
    "        lb = 0\n",
    "        db = 0\n",
    "        other = 0\n",
    "\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            if sub_string[1] == 'DL':\n",
    "                dl += int(sub_string[0])\n",
    "            elif sub_string[1] in ['LB','OL']:\n",
    "                lb += int(sub_string[0])\n",
    "            else:\n",
    "                db += int(sub_string[0])\n",
    "\n",
    "        counts = (dl,lb,db,other)\n",
    "\n",
    "        return counts\n",
    "    def offense_formation(l):\n",
    "        qb = 0\n",
    "        rb = 0\n",
    "        wr = 0\n",
    "        te = 0\n",
    "        ol = 0\n",
    "\n",
    "        sub_total = 0\n",
    "        qb_listed = False\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            pos = sub_string[1]\n",
    "            cnt = int(sub_string[0])\n",
    "\n",
    "            if pos == 'QB':\n",
    "                qb += cnt\n",
    "                sub_total += cnt\n",
    "                qb_listed = True\n",
    "            # Assuming LB is a line backer lined up as full back\n",
    "            elif pos in ['RB','LB']:\n",
    "                rb += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DB is a defensive back and lined up as WR\n",
    "            elif pos in ['WR','DB']:\n",
    "                wr += cnt\n",
    "                sub_total += cnt\n",
    "            elif pos == 'TE':\n",
    "                te += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DL is a defensive lineman lined up as an additional line man\n",
    "            else:\n",
    "                ol += cnt\n",
    "                sub_total += cnt\n",
    "\n",
    "        # If not all 11 players were noted at given positions we need to make some assumptions\n",
    "        # I will assume if a QB is not listed then there was 1 QB on the play\n",
    "        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n",
    "        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n",
    "        if sub_total < 11:\n",
    "            diff = 11 - sub_total\n",
    "            if not qb_listed:\n",
    "                qb += 1\n",
    "                diff -= 1\n",
    "            ol += diff\n",
    "\n",
    "        counts = (qb,rb,wr,te,ol)\n",
    "\n",
    "        return counts\n",
    "    def split_personnel(s):\n",
    "        splits = s.split(',')\n",
    "        for i in range(len(splits)):\n",
    "            splits[i] = splits[i].strip()\n",
    "\n",
    "        return splits    \n",
    "    def personnel_features(df):\n",
    "        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n",
    "        personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n",
    "\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n",
    "        personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n",
    "        personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n",
    "        personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n",
    "\n",
    "        # Let's create some features to specify if the OL is covered\n",
    "        personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n",
    "        personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n",
    "        # Let's create a feature to specify if the defense is preventing the run\n",
    "        # Let's just assume 7 or more DL and LB is run prevention\n",
    "        personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n",
    "\n",
    "        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n",
    "        \n",
    "        return personnel\n",
    "    \n",
    "    personnel = personnel_features(df1)   \n",
    "    df1 = df1.merge(personnel,how = 'left',  on ='PlayId')\n",
    "    \n",
    "# Gap\n",
    "    temp = df3.drop(df3[(df3['Position'].isin(['FS','S','SS'])) & (df3['Distance_to_Rusher']>15)].index)\n",
    "    temp = df3.merge(df.loc[df['IsRusher'],['PlayId','New_X','New_Y','Dir_std']]\\\n",
    "                      .rename(columns={'New_X':'Rusher_X','New_Y':'Rusher_Y','Dir_std':'Rusher_Dir'}), on = 'PlayId',how = 'left')\n",
    "\n",
    "\n",
    "    op_up = temp[((temp['Rusher_Dir']<90)|(temp['Rusher_Dir']>270))&(temp['New_Y']>=temp['Rusher_Y_x'])]\n",
    "    op_up = op_up.sort_values(['PlayId','New_Y'])\n",
    "    op_up[['Next_Y','Next_X']] = op_up[['New_Y','New_X']].shift(1,axis = 0)\n",
    "    op_up['Gap'] = op_up['New_Y'] - op_up['Next_Y']\n",
    "    op_up[['PlayId','New_Y','Next_Y','Gap']]\n",
    "    closest_op_up = op_up[['PlayId','Gap']].groupby('PlayId').head(1).reset_index()\n",
    "    best_up = op_up[['PlayId','Gap']].groupby('PlayId').max().reset_index()\n",
    "    def_num_up = op_up[['PlayId','Gap']].rename(columns={'Gap': 'num_def'}).groupby('PlayId').count().reset_index()\n",
    "\n",
    "    op_down = temp[(~((temp['Rusher_Dir']<90)|(temp['Rusher_Dir']>270)))&(temp['New_Y']<temp['Rusher_Y_x'])]\n",
    "    op_down = op_down.sort_values(['PlayId','New_Y'])\n",
    "    op_down[['Next_Y','Next_X']] = op_down[['New_Y','New_X']].shift(1,axis = 0)\n",
    "    op_down['Gap'] = op_down['New_Y'] - op_down['Next_Y']\n",
    "    op_down[['PlayId','New_Y','Next_Y','Gap']]\n",
    "    closest_op_down = op_down[['PlayId','Gap']].groupby('PlayId').tail(1).reset_index()\n",
    "    best_down = op_down[['PlayId','Gap']].groupby('PlayId').max().reset_index()\n",
    "    def_num_down = op_down[['PlayId','Gap']].rename(columns={'Gap': 'num_def'}).groupby('PlayId').count().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    closest_op = closest_op_up.append(closest_op_down).rename(columns = {'Gap':'Closet_Gap'})\n",
    "    best = best_up.append(best_down).rename(columns = {'Gap':'Best_Gap'})\n",
    "    df1 = df1.merge(closest_op, on='PlayId',how = 'left')\n",
    "    \n",
    "#select useful columns    \n",
    "    rusher = df1[['PlayId','TimeDelta','Team','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y', \\\n",
    "                 'Orientation_std','Dir_std','Dis_YardLine','Horizontal Speed','Vertical Speed','S','A','Dis','Position',\\\n",
    "                 'Quarter','GameClock','Down','Distance','OffenseFormation',\\\n",
    "                  'DefendersInTheBox','HomeScoreBeforePlay','VisitorScoreBeforePlay',\\\n",
    "                 'Offense_X_Removed2_std','Offense_Y_Removed2_std','Offense_X_Removed4_std','Offense_Y_Removed4_std',\\\n",
    "                 'Defense_X_std','Defense_Y_std','Defense_X_Removed2_std','Defense_Y_Removed2_std','Defense_X_Removed4_std',\\\n",
    "                 'Defense_Y_Removed4_std',\\\n",
    "                  'num_DL','num_LB','num_DB','num_QB','num_RB','num_WR','num_TE','num_OL','OL_diff','OL_TE_diff','run_def',\\\n",
    "                 'min','max','std','mean','dis_to_QB','Max_Yards','DiffScoreBeforePlay_ob','Closet_Gap']]\n",
    "    rusher = rusher.sort_values('PlayId')\n",
    "    game = df1[['PlayId','Cleaned_GameWeather']]\n",
    "    game = game.sort_values('PlayId')\n",
    "    offender = df2[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff']]\n",
    "    offender = offender.sort_values(['PlayId','Distance_to_Rusher'])\n",
    "    defender = df3[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff','Min_Time_Tacke','Speed_Ratio','degree_to_closest_offender']+list(range(2))] #list(range(2)) two closest offenders\n",
    "    defender = defender.sort_values(['PlayId','Distance_to_Rusher'])\n",
    "\n",
    "    \n",
    "    return rusher, game, offender, defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "rusher, game, offender, defender = split_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove some columns\n",
    "rusher = rusher.drop('max',axis = 1)\n",
    "\n",
    "offender = offender.sort_values(['PlayId','Distance_to_Rusher']).groupby('PlayId').head(2)\n",
    "\n",
    "defender = defender.sort_values(['PlayId','Distance_to_Rusher']).drop(['New_Y','Position'],axis = 1).groupby('PlayId').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACE', 'C', 'CB', 'DE', 'DT', 'EMPTY', 'FB', 'G', 'HB', 'I_FORM',\n",
       "       'JUMBO', 'NT', 'OG', 'OLB', 'OT', 'PISTOL', 'QB', 'RB', 'SHOTGUN',\n",
       "       'SINGLEBACK', 'T', 'TE', 'WILDCAT', 'WR', 'away', 'home', 'nan'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding fit\n",
    "le = preprocessing.LabelEncoder()\n",
    "categories =[]\n",
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = rusher[i].astype(str)\n",
    "    categories.append(rusher[i].unique())\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = game[i].astype(str)\n",
    "    categories.append(game[i].unique())\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = offender[i].astype(str)\n",
    "    categories.append(offender[i].unique())\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = defender[i].astype(str)\n",
    "    categories.append(defender[i].unique())\n",
    "categories = np.hstack(categories)\n",
    "le.fit(categories)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding transform\n",
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = le.transform(rusher[i])\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = le.transform(game[i])\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = le.transform(offender[i])\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = le.transform(defender[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape offender\n",
    "offender_players = [offender.drop('PlayId',axis = 1).iloc[np.arange(k, len(offender), 2)].reset_index(drop = True) for k in range(2)]\n",
    "offender_players = np.hstack([t.values for t in offender_players])\n",
    "offender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 114)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape defender\n",
    "defender_players = [defender.drop('PlayId',axis = 1).iloc[np.arange(k, len(defender), 6)].reset_index(drop = True) for k in range(6)]\n",
    "defender_players = np.hstack([t.values for t in defender_players])\n",
    "defender_players.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 53)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusher.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_y =train.loc[train['IsRusher'],['Yards','PlayId']].sort_values('PlayId').drop('PlayId',axis = 1)\n",
    "train_x = np.hstack([rusher.drop('PlayId',axis = 1).values,defender_players,offender_players])\n",
    "train_y99 =(train_y + 99).reset_index(drop=True).Yards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def crps_eval(y_pred, dataset, is_higher_better=False):\n",
    "    labels = dataset.get_label()\n",
    "    labels = labels.astype('int')\n",
    "    y_true = np.zeros((len(labels),199))\n",
    "    for i, v in enumerate(labels):\n",
    "        y_true[i, v:] = 1\n",
    "    y_pred = y_pred.reshape(-1, 199, order='F')\n",
    "    y_pred = np.clip(y_pred.cumsum(axis=1), 0, 1)\n",
    "    return 'crps', np.mean((y_pred - y_true)**2), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "params = {'max_depth':5, 'lambda_l1': 1.4, 'lambda_l2': 1.2,\n",
    " 'num_leaves': 32, 'feature_fraction': 0.4,\n",
    " 'subsample': 0.4, 'min_child_samples': 15,\n",
    " 'learning_rate': 0.02,\n",
    " 'num_iterations': 10000, 'random_state': 42,\n",
    " 'objective': 'multiclass',\n",
    " 'min_gain_to_split':0.9,\n",
    " 'num_class':199,\n",
    " 'metric':'None'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's crps: 0.012676\tvalid_1's crps: 0.0133513\n",
      "[200]\ttraining's crps: 0.0115581\tvalid_1's crps: 0.0130596\n",
      "[300]\ttraining's crps: 0.0108587\tvalid_1's crps: 0.0129333\n",
      "[400]\ttraining's crps: 0.010403\tvalid_1's crps: 0.0128692\n",
      "[500]\ttraining's crps: 0.0100868\tvalid_1's crps: 0.012835\n",
      "[600]\ttraining's crps: 0.00985046\tvalid_1's crps: 0.0128183\n",
      "[700]\ttraining's crps: 0.00967157\tvalid_1's crps: 0.0128058\n",
      "[800]\ttraining's crps: 0.00953828\tvalid_1's crps: 0.0127976\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-01c6e8be79d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                               feval=crps_eval)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_train\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   2104\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2105\u001b[0m         \"\"\"\n\u001b[1;32m-> 2106\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   2606\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2607\u001b[0m                 \u001b[0mcur_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2608\u001b[1;33m             \u001b[0mfeval_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2609\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2610\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-c4b88d2830a2>\u001b[0m in \u001b[0;36mcrps_eval\u001b[1;34m(y_pred, dataset, is_higher_better)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m199\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'crps'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   3116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3117\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 3118\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   3119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         ret = um.true_divide(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "        tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "        vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "        dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "        dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "        model = lgb.train(params, dtrain,\n",
    "                              num_boost_round=100000,\n",
    "                              valid_sets=[dtrain,dvalid],\n",
    "                              early_stopping_rounds=10,\n",
    "                              verbose_eval=100,\n",
    "                              feval=crps_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012891320000000001\n",
      "0.01277846\n",
      "0.01278668\n",
      "0.012749759999999999\n",
      "0.01270946\n"
     ]
    }
   ],
   "source": [
    "#CV score\n",
    "# for leave out one feature importance compare\n",
    "print(np.mean([0.0129045,0.0128677,0.0127771,0.0127333,0.013174]))\n",
    "\n",
    "# 5 closest defense palyer drop 'New_Y','back_oriented_down_field',max\n",
    "print(np.mean([0.0128208, 0.0127364, 0.0126515, 0.0126222,0.0130614]))\n",
    "\n",
    "# all defense palyer\n",
    "print(np.mean([0.012802,0.0127486,0.0126934,0.0126226,0.0130668]))\n",
    "\n",
    "# 5 closest defender + 2 closest offender l1,l2 = 1.2\n",
    "print(np.mean([0.0127868,0.0127041,0.0126144,0.0125952,0.0130483]))\n",
    "\n",
    "# 6 closest defender + 2 closest offender with new feature\n",
    "print(np.mean([0.0127482, 0.0126271, 0.0126066, 0.0125627, 0.0130027]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Dense = rusher[['Dis_YardLine','PlayerAge','PlayerHeight','PlayerWeight', \\\n",
    "            'Orientation_std','Dir_std','New_X','New_Y','Horizontal Speed',\\\n",
    "            'Vertical Speed','S','A','Dis','GameClock',\\\n",
    "            'Distance','Max_Yards',\\\n",
    "            'Defense_X_std','Defense_Y_std','Defense_X_Removed2_std',\\\n",
    "            'Offense_Y_Removed2_std',\\\n",
    "            'min','std','mean','Max_Yards','dis_to_QB',\\\n",
    "            'HomeScoreBeforePlay','VisitorScoreBeforePlay',\\\n",
    "            \"DiffScoreBeforePlay_ob\",'Quarter','Down','Closet_Gap']]\n",
    "X_Dense = X_Dense.fillna(0)\n",
    "yards = train.loc[train['IsRusher'],['Yards','PlayId']].\\\n",
    "sort_values('PlayId').drop('PlayId',axis = 1).Yards\n",
    "\n",
    "y = np.zeros((yards.shape[0], 199))\n",
    "for idx, target in enumerate(list(yards)):\n",
    "    y[idx][99 + target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import re\n",
    "from keras.losses import binary_crossentropy\n",
    "from  keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import codecs\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CRPSCallback(Callback):\n",
    "    \n",
    "    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n",
    "        super(CRPSCallback, self).__init__()\n",
    "        self.validation = validation\n",
    "        self.predict_batch_size = predict_batch_size\n",
    "        self.include_on_batch = include_on_batch\n",
    "        \n",
    "        print('validation shape',len(self.validation))\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('CRPS_score_val' in self.params['metrics']):\n",
    "            self.params['metrics'].append('CRPS_score_val')\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if (self.include_on_batch):\n",
    "            logs['CRPS_score_val'] = float('-inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['CRPS_score_val'] = float('-inf')\n",
    "            \n",
    "        if (self.validation):\n",
    "            X_valid, y_valid = self.validation[0], self.validation[1]\n",
    "            y_pred = self.model.predict(X_valid)\n",
    "            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "            val_s = np.round(val_s, 6)\n",
    "            logs['CRPS_score_val'] = val_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_tr,y_tr,x_val,y_val):\n",
    "    inp = Input(shape = (x_tr.shape[1],))\n",
    "    x = Dense(1024, input_dim=X.shape[1], activation='relu')(inp)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    out = Dense(199, activation='softmax')(x)\n",
    "    model = Model(inp,out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n",
    "    #add lookahead\n",
    "#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n",
    "#     lookahead.inject(model) # add into model\n",
    "\n",
    "    \n",
    "    es = EarlyStopping(monitor='CRPS_score_val', \n",
    "                       mode='min',\n",
    "                       restore_best_weights=True, \n",
    "                       verbose=1, \n",
    "                       patience=15)\n",
    "\n",
    "    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n",
    "                                   save_best_only=True, verbose=1, save_weights_only=True)\n",
    "    \n",
    "    bsz = 1024\n",
    "    steps = x_tr.shape[0]/bsz\n",
    "    \n",
    "\n",
    "\n",
    "    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=100, batch_size=bsz,verbose=1)\n",
    "    model.load_weights(\"best_model.h5\")\n",
    "    \n",
    "    y_pred = model.predict(x_val)\n",
    "    y_valid = y_val\n",
    "    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n",
    "    crps = np.round(val_s, 6)\n",
    "\n",
    "    return model,crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/100\n",
      "18536/18536 [==============================] - ETA: 15s - loss: 5.79 - ETA: 9s - loss: 5.7910 - ETA: 6s - loss: 5.769 - ETA: 5s - loss: 5.778 - ETA: 4s - loss: 5.760 - ETA: 3s - loss: 5.752 - ETA: 3s - loss: 5.736 - ETA: 2s - loss: 5.722 - ETA: 2s - loss: 5.707 - ETA: 2s - loss: 5.692 - ETA: 1s - loss: 5.683 - ETA: 1s - loss: 5.674 - ETA: 1s - loss: 5.658 - ETA: 0s - loss: 5.649 - ETA: 0s - loss: 5.639 - ETA: 0s - loss: 5.627 - ETA: 0s - loss: 5.611 - ETA: 0s - loss: 5.601 - 4s 225us/step - loss: 5.6000\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08274, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 5.252 - ETA: 3s - loss: 5.280 - ETA: 2s - loss: 5.276 - ETA: 2s - loss: 5.246 - ETA: 2s - loss: 5.229 - ETA: 2s - loss: 5.219 - ETA: 2s - loss: 5.222 - ETA: 1s - loss: 5.214 - ETA: 1s - loss: 5.201 - ETA: 1s - loss: 5.198 - ETA: 1s - loss: 5.181 - ETA: 1s - loss: 5.172 - ETA: 0s - loss: 5.157 - ETA: 0s - loss: 5.147 - ETA: 0s - loss: 5.138 - ETA: 0s - loss: 5.127 - ETA: 0s - loss: 5.113 - ETA: 0s - loss: 5.095 - 3s 187us/step - loss: 5.0941\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08274 to 0.07791, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 4.852 - ETA: 3s - loss: 4.807 - ETA: 2s - loss: 4.830 - ETA: 2s - loss: 4.823 - ETA: 2s - loss: 4.802 - ETA: 2s - loss: 4.782 - ETA: 2s - loss: 4.769 - ETA: 1s - loss: 4.753 - ETA: 1s - loss: 4.750 - ETA: 1s - loss: 4.729 - ETA: 1s - loss: 4.721 - ETA: 1s - loss: 4.708 - ETA: 0s - loss: 4.704 - ETA: 0s - loss: 4.694 - ETA: 0s - loss: 4.683 - ETA: 0s - loss: 4.676 - ETA: 0s - loss: 4.663 - ETA: 0s - loss: 4.650 - 3s 185us/step - loss: 4.6524\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.07791 to 0.06669, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 4.363 - ETA: 3s - loss: 4.388 - ETA: 2s - loss: 4.392 - ETA: 2s - loss: 4.365 - ETA: 2s - loss: 4.368 - ETA: 2s - loss: 4.362 - ETA: 2s - loss: 4.347 - ETA: 1s - loss: 4.349 - ETA: 1s - loss: 4.340 - ETA: 1s - loss: 4.341 - ETA: 1s - loss: 4.333 - ETA: 1s - loss: 4.322 - ETA: 0s - loss: 4.308 - ETA: 0s - loss: 4.297 - ETA: 0s - loss: 4.294 - ETA: 0s - loss: 4.272 - ETA: 0s - loss: 4.262 - ETA: 0s - loss: 4.249 - 3s 186us/step - loss: 4.2479\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.06669 to 0.04770, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 4.022 - ETA: 3s - loss: 4.021 - ETA: 2s - loss: 4.015 - ETA: 2s - loss: 4.007 - ETA: 2s - loss: 3.990 - ETA: 2s - loss: 3.976 - ETA: 2s - loss: 3.976 - ETA: 1s - loss: 3.969 - ETA: 1s - loss: 3.963 - ETA: 1s - loss: 3.950 - ETA: 1s - loss: 3.945 - ETA: 1s - loss: 3.936 - ETA: 0s - loss: 3.928 - ETA: 0s - loss: 3.923 - ETA: 0s - loss: 3.910 - ETA: 0s - loss: 3.895 - ETA: 0s - loss: 3.878 - ETA: 0s - loss: 3.871 - 3s 187us/step - loss: 3.8717\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.04770 to 0.02890, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 3.683 - ETA: 3s - loss: 3.731 - ETA: 2s - loss: 3.716 - ETA: 2s - loss: 3.697 - ETA: 2s - loss: 3.674 - ETA: 2s - loss: 3.647 - ETA: 2s - loss: 3.641 - ETA: 1s - loss: 3.629 - ETA: 1s - loss: 3.609 - ETA: 1s - loss: 3.594 - ETA: 1s - loss: 3.588 - ETA: 1s - loss: 3.575 - ETA: 0s - loss: 3.573 - ETA: 0s - loss: 3.566 - ETA: 0s - loss: 3.551 - ETA: 0s - loss: 3.544 - ETA: 0s - loss: 3.535 - ETA: 0s - loss: 3.528 - 3s 186us/step - loss: 3.5285\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.02890 to 0.01916, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 3.487 - ETA: 3s - loss: 3.412 - ETA: 2s - loss: 3.357 - ETA: 2s - loss: 3.344 - ETA: 2s - loss: 3.337 - ETA: 2s - loss: 3.353 - ETA: 2s - loss: 3.365 - ETA: 1s - loss: 3.364 - ETA: 1s - loss: 3.353 - ETA: 1s - loss: 3.347 - ETA: 1s - loss: 3.344 - ETA: 1s - loss: 3.335 - ETA: 0s - loss: 3.320 - ETA: 0s - loss: 3.315 - ETA: 0s - loss: 3.299 - ETA: 0s - loss: 3.291 - ETA: 0s - loss: 3.290 - ETA: 0s - loss: 3.281 - 4s 189us/step - loss: 3.2822\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01916 to 0.01542, saving model to best_model.h5\n",
      "Epoch 8/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 3.132 - ETA: 3s - loss: 3.142 - ETA: 2s - loss: 3.092 - ETA: 2s - loss: 3.128 - ETA: 2s - loss: 3.122 - ETA: 2s - loss: 3.126 - ETA: 2s - loss: 3.114 - ETA: 1s - loss: 3.108 - ETA: 1s - loss: 3.111 - ETA: 1s - loss: 3.107 - ETA: 1s - loss: 3.107 - ETA: 1s - loss: 3.100 - ETA: 1s - loss: 3.099 - ETA: 0s - loss: 3.101 - ETA: 0s - loss: 3.097 - ETA: 0s - loss: 3.096 - ETA: 0s - loss: 3.095 - ETA: 0s - loss: 3.096 - 4s 191us/step - loss: 3.0953\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01542 to 0.01396, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.983 - ETA: 3s - loss: 2.989 - ETA: 2s - loss: 2.993 - ETA: 2s - loss: 2.979 - ETA: 2s - loss: 2.968 - ETA: 2s - loss: 2.971 - ETA: 2s - loss: 2.976 - ETA: 1s - loss: 2.965 - ETA: 1s - loss: 2.973 - ETA: 1s - loss: 2.972 - ETA: 1s - loss: 2.971 - ETA: 1s - loss: 2.974 - ETA: 0s - loss: 2.970 - ETA: 0s - loss: 2.974 - ETA: 0s - loss: 2.973 - ETA: 0s - loss: 2.972 - ETA: 0s - loss: 2.972 - ETA: 0s - loss: 2.968 - 3s 185us/step - loss: 2.9693\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01396 to 0.01350, saving model to best_model.h5\n",
      "Epoch 10/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.942 - ETA: 3s - loss: 2.964 - ETA: 2s - loss: 2.941 - ETA: 2s - loss: 2.939 - ETA: 2s - loss: 2.913 - ETA: 2s - loss: 2.910 - ETA: 2s - loss: 2.900 - ETA: 1s - loss: 2.905 - ETA: 1s - loss: 2.899 - ETA: 1s - loss: 2.902 - ETA: 1s - loss: 2.903 - ETA: 1s - loss: 2.905 - ETA: 0s - loss: 2.905 - ETA: 0s - loss: 2.903 - ETA: 0s - loss: 2.902 - ETA: 0s - loss: 2.902 - ETA: 0s - loss: 2.901 - ETA: 0s - loss: 2.904 - 3s 185us/step - loss: 2.9041\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01350 to 0.01330, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.911 - ETA: 3s - loss: 2.896 - ETA: 2s - loss: 2.875 - ETA: 2s - loss: 2.861 - ETA: 2s - loss: 2.865 - ETA: 2s - loss: 2.863 - ETA: 2s - loss: 2.865 - ETA: 1s - loss: 2.866 - ETA: 1s - loss: 2.866 - ETA: 1s - loss: 2.864 - ETA: 1s - loss: 2.860 - ETA: 1s - loss: 2.853 - ETA: 0s - loss: 2.852 - ETA: 0s - loss: 2.854 - ETA: 0s - loss: 2.850 - ETA: 0s - loss: 2.849 - ETA: 0s - loss: 2.846 - ETA: 0s - loss: 2.847 - 3s 185us/step - loss: 2.8480\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01330 to 0.01320, saving model to best_model.h5\n",
      "Epoch 12/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.834 - ETA: 3s - loss: 2.778 - ETA: 2s - loss: 2.803 - ETA: 2s - loss: 2.818 - ETA: 2s - loss: 2.810 - ETA: 2s - loss: 2.807 - ETA: 2s - loss: 2.810 - ETA: 1s - loss: 2.807 - ETA: 1s - loss: 2.806 - ETA: 1s - loss: 2.809 - ETA: 1s - loss: 2.808 - ETA: 1s - loss: 2.811 - ETA: 0s - loss: 2.815 - ETA: 0s - loss: 2.815 - ETA: 0s - loss: 2.814 - ETA: 0s - loss: 2.815 - ETA: 0s - loss: 2.816 - ETA: 0s - loss: 2.817 - 3s 184us/step - loss: 2.8180\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01320 to 0.01312, saving model to best_model.h5\n",
      "Epoch 13/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.831 - ETA: 3s - loss: 2.829 - ETA: 2s - loss: 2.850 - ETA: 2s - loss: 2.840 - ETA: 2s - loss: 2.817 - ETA: 2s - loss: 2.815 - ETA: 2s - loss: 2.826 - ETA: 1s - loss: 2.815 - ETA: 1s - loss: 2.820 - ETA: 1s - loss: 2.818 - ETA: 1s - loss: 2.808 - ETA: 1s - loss: 2.806 - ETA: 0s - loss: 2.804 - ETA: 0s - loss: 2.797 - ETA: 0s - loss: 2.796 - ETA: 0s - loss: 2.794 - ETA: 0s - loss: 2.796 - ETA: 0s - loss: 2.793 - 3s 184us/step - loss: 2.7940\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01312 to 0.01306, saving model to best_model.h5\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 3s - loss: 2.782 - ETA: 3s - loss: 2.787 - ETA: 2s - loss: 2.796 - ETA: 2s - loss: 2.799 - ETA: 2s - loss: 2.784 - ETA: 2s - loss: 2.778 - ETA: 2s - loss: 2.781 - ETA: 1s - loss: 2.781 - ETA: 1s - loss: 2.778 - ETA: 1s - loss: 2.780 - ETA: 1s - loss: 2.781 - ETA: 1s - loss: 2.787 - ETA: 0s - loss: 2.786 - ETA: 0s - loss: 2.782 - ETA: 0s - loss: 2.783 - ETA: 0s - loss: 2.780 - ETA: 0s - loss: 2.774 - ETA: 0s - loss: 2.773 - 3s 186us/step - loss: 2.7732\n",
      "\n",
      "Epoch 00014: CRPS_score_val improved from 0.01306 to 0.01304, saving model to best_model.h5\n",
      "Epoch 15/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.755 - ETA: 2s - loss: 2.772 - ETA: 2s - loss: 2.767 - ETA: 2s - loss: 2.759 - ETA: 2s - loss: 2.761 - ETA: 2s - loss: 2.756 - ETA: 2s - loss: 2.749 - ETA: 1s - loss: 2.753 - ETA: 1s - loss: 2.754 - ETA: 1s - loss: 2.747 - ETA: 1s - loss: 2.748 - ETA: 1s - loss: 2.739 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.754 - ETA: 0s - loss: 2.758 - ETA: 0s - loss: 2.756 - ETA: 0s - loss: 2.756 - 3s 183us/step - loss: 2.7584\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01304 to 0.01303, saving model to best_model.h5\n",
      "Epoch 16/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.753 - ETA: 2s - loss: 2.775 - ETA: 2s - loss: 2.779 - ETA: 2s - loss: 2.749 - ETA: 2s - loss: 2.752 - ETA: 2s - loss: 2.746 - ETA: 2s - loss: 2.752 - ETA: 1s - loss: 2.746 - ETA: 1s - loss: 2.743 - ETA: 1s - loss: 2.744 - ETA: 1s - loss: 2.747 - ETA: 1s - loss: 2.743 - ETA: 0s - loss: 2.744 - ETA: 0s - loss: 2.741 - ETA: 0s - loss: 2.743 - ETA: 0s - loss: 2.744 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.743 - 3s 183us/step - loss: 2.7445\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01303 to 0.01298, saving model to best_model.h5\n",
      "Epoch 17/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.745 - ETA: 2s - loss: 2.751 - ETA: 2s - loss: 2.734 - ETA: 2s - loss: 2.744 - ETA: 2s - loss: 2.732 - ETA: 2s - loss: 2.733 - ETA: 2s - loss: 2.736 - ETA: 1s - loss: 2.736 - ETA: 1s - loss: 2.740 - ETA: 1s - loss: 2.744 - ETA: 1s - loss: 2.744 - ETA: 1s - loss: 2.745 - ETA: 0s - loss: 2.741 - ETA: 0s - loss: 2.739 - ETA: 0s - loss: 2.739 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.738 - ETA: 0s - loss: 2.736 - 3s 184us/step - loss: 2.7369\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01298 to 0.01295, saving model to best_model.h5\n",
      "Epoch 18/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.805 - ETA: 3s - loss: 2.764 - ETA: 2s - loss: 2.739 - ETA: 2s - loss: 2.712 - ETA: 2s - loss: 2.715 - ETA: 2s - loss: 2.701 - ETA: 2s - loss: 2.710 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.709 - ETA: 1s - loss: 2.713 - ETA: 1s - loss: 2.716 - ETA: 1s - loss: 2.714 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.727 - ETA: 0s - loss: 2.727 - ETA: 0s - loss: 2.729 - 3s 184us/step - loss: 2.7284\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01295 to 0.01292, saving model to best_model.h5\n",
      "Epoch 19/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.750 - ETA: 2s - loss: 2.712 - ETA: 2s - loss: 2.710 - ETA: 2s - loss: 2.729 - ETA: 2s - loss: 2.715 - ETA: 2s - loss: 2.713 - ETA: 2s - loss: 2.704 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.704 - ETA: 1s - loss: 2.707 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.711 - ETA: 0s - loss: 2.718 - ETA: 0s - loss: 2.719 - ETA: 0s - loss: 2.717 - ETA: 0s - loss: 2.719 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.722 - 3s 184us/step - loss: 2.7216\n",
      "\n",
      "Epoch 00019: CRPS_score_val improved from 0.01292 to 0.01291, saving model to best_model.h5\n",
      "Epoch 20/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.754 - ETA: 3s - loss: 2.732 - ETA: 2s - loss: 2.724 - ETA: 2s - loss: 2.724 - ETA: 2s - loss: 2.725 - ETA: 2s - loss: 2.718 - ETA: 2s - loss: 2.725 - ETA: 1s - loss: 2.728 - ETA: 1s - loss: 2.724 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.718 - ETA: 1s - loss: 2.719 - ETA: 0s - loss: 2.718 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.713 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.712 - ETA: 0s - loss: 2.712 - 3s 185us/step - loss: 2.7114\n",
      "\n",
      "Epoch 00020: CRPS_score_val improved from 0.01291 to 0.01288, saving model to best_model.h5\n",
      "Epoch 21/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.652 - ETA: 2s - loss: 2.654 - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.672 - ETA: 2s - loss: 2.679 - ETA: 2s - loss: 2.689 - ETA: 2s - loss: 2.691 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.704 - ETA: 0s - loss: 2.704 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.700 - ETA: 0s - loss: 2.699 - ETA: 0s - loss: 2.701 - 3s 182us/step - loss: 2.7026\n",
      "\n",
      "Epoch 00021: CRPS_score_val improved from 0.01288 to 0.01288, saving model to best_model.h5\n",
      "Epoch 22/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.653 - ETA: 2s - loss: 2.647 - ETA: 2s - loss: 2.644 - ETA: 2s - loss: 2.670 - ETA: 2s - loss: 2.685 - ETA: 2s - loss: 2.700 - ETA: 2s - loss: 2.702 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.699 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.704 - ETA: 0s - loss: 2.700 - ETA: 0s - loss: 2.702 - ETA: 0s - loss: 2.700 - ETA: 0s - loss: 2.697 - ETA: 0s - loss: 2.698 - ETA: 0s - loss: 2.697 - 3s 184us/step - loss: 2.6972\n",
      "\n",
      "Epoch 00022: CRPS_score_val improved from 0.01288 to 0.01287, saving model to best_model.h5\n",
      "Epoch 23/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.582 - ETA: 2s - loss: 2.616 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.653 - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.668 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.671 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.682 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.689 - ETA: 0s - loss: 2.689 - 3s 186us/step - loss: 2.6892\n",
      "\n",
      "Epoch 00023: CRPS_score_val improved from 0.01287 to 0.01284, saving model to best_model.h5\n",
      "Epoch 24/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.677 - ETA: 3s - loss: 2.667 - ETA: 2s - loss: 2.676 - ETA: 2s - loss: 2.687 - ETA: 2s - loss: 2.680 - ETA: 2s - loss: 2.682 - ETA: 2s - loss: 2.682 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.674 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.679 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.677 - 3s 186us/step - loss: 2.6776\n",
      "\n",
      "Epoch 00024: CRPS_score_val improved from 0.01284 to 0.01282, saving model to best_model.h5\n",
      "Epoch 25/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.677 - ETA: 3s - loss: 2.647 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.660 - ETA: 2s - loss: 2.665 - ETA: 2s - loss: 2.672 - ETA: 2s - loss: 2.669 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.665 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.673 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.678 - 3s 185us/step - loss: 2.6791\n",
      "\n",
      "Epoch 00025: CRPS_score_val improved from 0.01282 to 0.01280, saving model to best_model.h5\n",
      "Epoch 26/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.621 - ETA: 3s - loss: 2.663 - ETA: 2s - loss: 2.658 - ETA: 2s - loss: 2.669 - ETA: 2s - loss: 2.673 - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.668 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.670 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.670 - 4s 190us/step - loss: 2.6703\n",
      "\n",
      "Epoch 00026: CRPS_score_val improved from 0.01280 to 0.01279, saving model to best_model.h5\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 3s - loss: 2.639 - ETA: 3s - loss: 2.636 - ETA: 2s - loss: 2.644 - ETA: 2s - loss: 2.646 - ETA: 2s - loss: 2.654 - ETA: 2s - loss: 2.662 - ETA: 2s - loss: 2.670 - ETA: 1s - loss: 2.667 - ETA: 1s - loss: 2.665 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.679 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.666 - 3s 186us/step - loss: 2.6672\n",
      "\n",
      "Epoch 00027: CRPS_score_val did not improve from 0.01279\n",
      "Epoch 28/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.636 - ETA: 3s - loss: 2.637 - ETA: 2s - loss: 2.629 - ETA: 2s - loss: 2.648 - ETA: 2s - loss: 2.648 - ETA: 2s - loss: 2.655 - ETA: 2s - loss: 2.654 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.657 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.659 - ETA: 0s - loss: 2.662 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.656 - 3s 186us/step - loss: 2.6571\n",
      "\n",
      "Epoch 00028: CRPS_score_val improved from 0.01279 to 0.01277, saving model to best_model.h5\n",
      "Epoch 29/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.654 - ETA: 3s - loss: 2.640 - ETA: 2s - loss: 2.631 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.650 - ETA: 2s - loss: 2.654 - ETA: 1s - loss: 2.659 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.661 - ETA: 1s - loss: 2.658 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.656 - 3s 185us/step - loss: 2.6563\n",
      "\n",
      "Epoch 00029: CRPS_score_val improved from 0.01277 to 0.01277, saving model to best_model.h5\n",
      "Epoch 30/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.639 - ETA: 3s - loss: 2.639 - ETA: 2s - loss: 2.649 - ETA: 2s - loss: 2.646 - ETA: 2s - loss: 2.647 - ETA: 2s - loss: 2.652 - ETA: 2s - loss: 2.654 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.657 - ETA: 1s - loss: 2.659 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.652 - 4s 189us/step - loss: 2.6529\n",
      "\n",
      "Epoch 00030: CRPS_score_val improved from 0.01277 to 0.01277, saving model to best_model.h5\n",
      "Epoch 31/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.559 - ETA: 2s - loss: 2.581 - ETA: 2s - loss: 2.599 - ETA: 2s - loss: 2.601 - ETA: 2s - loss: 2.607 - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.620 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.632 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.640 - 3s 185us/step - loss: 2.6404\n",
      "\n",
      "Epoch 00031: CRPS_score_val improved from 0.01277 to 0.01276, saving model to best_model.h5\n",
      "Epoch 32/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.660 - ETA: 2s - loss: 2.660 - ETA: 2s - loss: 2.650 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.633 - ETA: 2s - loss: 2.636 - ETA: 2s - loss: 2.634 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.639 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - 3s 187us/step - loss: 2.6370\n",
      "\n",
      "Epoch 00032: CRPS_score_val improved from 0.01276 to 0.01275, saving model to best_model.h5\n",
      "Epoch 33/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.697 - ETA: 3s - loss: 2.649 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.652 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.638 - ETA: 2s - loss: 2.641 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.632 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.640 - 4s 189us/step - loss: 2.6402\n",
      "\n",
      "Epoch 00033: CRPS_score_val improved from 0.01275 to 0.01274, saving model to best_model.h5\n",
      "Epoch 34/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.612 - ETA: 3s - loss: 2.603 - ETA: 2s - loss: 2.615 - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.610 - ETA: 2s - loss: 2.607 - ETA: 2s - loss: 2.605 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.609 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.622 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.633 - 3s 187us/step - loss: 2.6336\n",
      "\n",
      "Epoch 00034: CRPS_score_val improved from 0.01274 to 0.01273, saving model to best_model.h5\n",
      "Epoch 35/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.629 - ETA: 2s - loss: 2.600 - ETA: 2s - loss: 2.600 - ETA: 2s - loss: 2.612 - ETA: 2s - loss: 2.604 - ETA: 2s - loss: 2.604 - ETA: 2s - loss: 2.604 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.613 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.620 - 3s 182us/step - loss: 2.6203\n",
      "\n",
      "Epoch 00035: CRPS_score_val did not improve from 0.01273\n",
      "Epoch 36/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.607 - ETA: 3s - loss: 2.597 - ETA: 2s - loss: 2.601 - ETA: 2s - loss: 2.605 - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.616 - ETA: 2s - loss: 2.621 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.620 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.629 - 4s 190us/step - loss: 2.6299\n",
      "\n",
      "Epoch 00036: CRPS_score_val did not improve from 0.01273\n",
      "Epoch 37/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.621 - ETA: 3s - loss: 2.594 - ETA: 2s - loss: 2.597 - ETA: 2s - loss: 2.604 - ETA: 2s - loss: 2.599 - ETA: 2s - loss: 2.606 - ETA: 2s - loss: 2.609 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.619 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.623 - 3s 186us/step - loss: 2.6243\n",
      "\n",
      "Epoch 00037: CRPS_score_val did not improve from 0.01273\n",
      "Epoch 38/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.641 - ETA: 2s - loss: 2.619 - ETA: 2s - loss: 2.610 - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.623 - ETA: 2s - loss: 2.624 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.624 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.617 - 3s 185us/step - loss: 2.6175\n",
      "\n",
      "Epoch 00038: CRPS_score_val did not improve from 0.01273\n",
      "Epoch 39/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.563 - ETA: 3s - loss: 2.574 - ETA: 2s - loss: 2.595 - ETA: 2s - loss: 2.598 - ETA: 2s - loss: 2.611 - ETA: 2s - loss: 2.605 - ETA: 2s - loss: 2.591 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.600 - ETA: 1s - loss: 2.602 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.606 - 4s 189us/step - loss: 2.6065\n",
      "\n",
      "Epoch 00039: CRPS_score_val did not improve from 0.01273\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 3s - loss: 2.634 - ETA: 3s - loss: 2.617 - ETA: 2s - loss: 2.611 - ETA: 2s - loss: 2.611 - ETA: 2s - loss: 2.599 - ETA: 2s - loss: 2.611 - ETA: 2s - loss: 2.612 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.618 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.614 - 3s 187us/step - loss: 2.6151\n",
      "\n",
      "Epoch 00040: CRPS_score_val improved from 0.01273 to 0.01272, saving model to best_model.h5\n",
      "Epoch 41/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.646 - ETA: 3s - loss: 2.630 - ETA: 2s - loss: 2.610 - ETA: 2s - loss: 2.603 - ETA: 2s - loss: 2.609 - ETA: 2s - loss: 2.607 - ETA: 2s - loss: 2.603 - ETA: 1s - loss: 2.598 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.602 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.602 - 3s 185us/step - loss: 2.6031\n",
      "\n",
      "Epoch 00041: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 42/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.625 - ETA: 3s - loss: 2.604 - ETA: 2s - loss: 2.597 - ETA: 2s - loss: 2.613 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.609 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.600 - ETA: 1s - loss: 2.600 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.590 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.594 - 3s 185us/step - loss: 2.5959\n",
      "\n",
      "Epoch 00042: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 43/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.637 - ETA: 3s - loss: 2.609 - ETA: 2s - loss: 2.622 - ETA: 2s - loss: 2.613 - ETA: 2s - loss: 2.604 - ETA: 2s - loss: 2.592 - ETA: 2s - loss: 2.589 - ETA: 1s - loss: 2.589 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.595 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.601 - 3s 188us/step - loss: 2.6016\n",
      "\n",
      "Epoch 00043: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 44/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.537 - ETA: 3s - loss: 2.572 - ETA: 2s - loss: 2.578 - ETA: 2s - loss: 2.574 - ETA: 2s - loss: 2.575 - ETA: 2s - loss: 2.575 - ETA: 2s - loss: 2.581 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.585 - ETA: 1s - loss: 2.589 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.591 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.591 - 3s 184us/step - loss: 2.5923\n",
      "\n",
      "Epoch 00044: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 45/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.581 - ETA: 3s - loss: 2.580 - ETA: 2s - loss: 2.573 - ETA: 2s - loss: 2.579 - ETA: 2s - loss: 2.589 - ETA: 2s - loss: 2.581 - ETA: 2s - loss: 2.582 - ETA: 1s - loss: 2.585 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.590 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.586 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.582 - 3s 185us/step - loss: 2.5835\n",
      "\n",
      "Epoch 00045: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 46/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.615 - ETA: 3s - loss: 2.584 - ETA: 2s - loss: 2.565 - ETA: 2s - loss: 2.572 - ETA: 2s - loss: 2.575 - ETA: 2s - loss: 2.576 - ETA: 2s - loss: 2.577 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.583 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.584 - 3s 187us/step - loss: 2.5843\n",
      "\n",
      "Epoch 00046: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 47/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.589 - ETA: 3s - loss: 2.589 - ETA: 2s - loss: 2.604 - ETA: 2s - loss: 2.588 - ETA: 2s - loss: 2.584 - ETA: 2s - loss: 2.573 - ETA: 2s - loss: 2.578 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.571 - ETA: 1s - loss: 2.567 - ETA: 1s - loss: 2.570 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.578 - ETA: 0s - loss: 2.578 - ETA: 0s - loss: 2.581 - 3s 186us/step - loss: 2.5819\n",
      "\n",
      "Epoch 00047: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 48/100\n",
      "18536/18536 [==============================] - ETA: 4s - loss: 2.581 - ETA: 3s - loss: 2.589 - ETA: 3s - loss: 2.590 - ETA: 2s - loss: 2.584 - ETA: 2s - loss: 2.586 - ETA: 2s - loss: 2.580 - ETA: 2s - loss: 2.584 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.576 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.578 - ETA: 0s - loss: 2.578 - 3s 188us/step - loss: 2.5793\n",
      "\n",
      "Epoch 00048: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 49/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.544 - ETA: 3s - loss: 2.563 - ETA: 2s - loss: 2.554 - ETA: 2s - loss: 2.559 - ETA: 2s - loss: 2.564 - ETA: 2s - loss: 2.563 - ETA: 2s - loss: 2.573 - ETA: 1s - loss: 2.567 - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.569 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.575 - 3s 187us/step - loss: 2.5750\n",
      "\n",
      "Epoch 00049: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 50/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.556 - ETA: 2s - loss: 2.548 - ETA: 2s - loss: 2.551 - ETA: 2s - loss: 2.566 - ETA: 2s - loss: 2.572 - ETA: 2s - loss: 2.565 - ETA: 2s - loss: 2.566 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.567 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.557 - ETA: 0s - loss: 2.561 - ETA: 0s - loss: 2.562 - ETA: 0s - loss: 2.559 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.566 - 3s 186us/step - loss: 2.5667\n",
      "\n",
      "Epoch 00050: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 51/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.523 - ETA: 3s - loss: 2.527 - ETA: 2s - loss: 2.533 - ETA: 2s - loss: 2.538 - ETA: 2s - loss: 2.532 - ETA: 2s - loss: 2.538 - ETA: 2s - loss: 2.534 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.548 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.548 - ETA: 1s - loss: 2.551 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.559 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.565 - 3s 185us/step - loss: 2.5645\n",
      "\n",
      "Epoch 00051: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 52/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.567 - ETA: 3s - loss: 2.566 - ETA: 2s - loss: 2.557 - ETA: 2s - loss: 2.568 - ETA: 2s - loss: 2.564 - ETA: 2s - loss: 2.566 - ETA: 2s - loss: 2.563 - ETA: 1s - loss: 2.558 - ETA: 1s - loss: 2.556 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.553 - ETA: 1s - loss: 2.553 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.555 - 3s 185us/step - loss: 2.5557\n",
      "\n",
      "Epoch 00052: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 53/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.575 - ETA: 3s - loss: 2.567 - ETA: 2s - loss: 2.551 - ETA: 2s - loss: 2.548 - ETA: 2s - loss: 2.548 - ETA: 2s - loss: 2.534 - ETA: 2s - loss: 2.537 - ETA: 1s - loss: 2.543 - ETA: 1s - loss: 2.549 - ETA: 1s - loss: 2.549 - ETA: 1s - loss: 2.541 - ETA: 1s - loss: 2.541 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.548 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.548 - ETA: 0s - loss: 2.550 - 3s 185us/step - loss: 2.5510\n",
      "\n",
      "Epoch 00053: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 3s - loss: 2.526 - ETA: 2s - loss: 2.541 - ETA: 2s - loss: 2.538 - ETA: 2s - loss: 2.535 - ETA: 2s - loss: 2.536 - ETA: 2s - loss: 2.537 - ETA: 2s - loss: 2.536 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.545 - ETA: 1s - loss: 2.547 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.547 - 3s 184us/step - loss: 2.5464\n",
      "\n",
      "Epoch 00054: CRPS_score_val improved from 0.01272 to 0.01272, saving model to best_model.h5\n",
      "Epoch 55/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.561 - ETA: 3s - loss: 2.546 - ETA: 2s - loss: 2.549 - ETA: 2s - loss: 2.552 - ETA: 2s - loss: 2.553 - ETA: 2s - loss: 2.554 - ETA: 2s - loss: 2.557 - ETA: 1s - loss: 2.555 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.554 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.555 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.548 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.551 - 3s 187us/step - loss: 2.5513\n",
      "\n",
      "Epoch 00055: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 56/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.595 - ETA: 3s - loss: 2.549 - ETA: 2s - loss: 2.553 - ETA: 2s - loss: 2.553 - ETA: 2s - loss: 2.544 - ETA: 2s - loss: 2.543 - ETA: 2s - loss: 2.549 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.548 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.548 - ETA: 0s - loss: 2.548 - ETA: 0s - loss: 2.550 - 3s 187us/step - loss: 2.5500\n",
      "\n",
      "Epoch 00056: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 57/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.454 - ETA: 3s - loss: 2.489 - ETA: 2s - loss: 2.522 - ETA: 2s - loss: 2.545 - ETA: 2s - loss: 2.527 - ETA: 2s - loss: 2.531 - ETA: 2s - loss: 2.523 - ETA: 1s - loss: 2.527 - ETA: 1s - loss: 2.531 - ETA: 1s - loss: 2.533 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.537 - ETA: 0s - loss: 2.541 - ETA: 0s - loss: 2.541 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.541 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.537 - 3s 184us/step - loss: 2.5371\n",
      "\n",
      "Epoch 00057: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 58/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.484 - ETA: 3s - loss: 2.507 - ETA: 2s - loss: 2.505 - ETA: 2s - loss: 2.512 - ETA: 2s - loss: 2.513 - ETA: 2s - loss: 2.508 - ETA: 2s - loss: 2.511 - ETA: 1s - loss: 2.518 - ETA: 1s - loss: 2.526 - ETA: 1s - loss: 2.525 - ETA: 1s - loss: 2.524 - ETA: 1s - loss: 2.523 - ETA: 0s - loss: 2.526 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.527 - ETA: 0s - loss: 2.528 - 3s 185us/step - loss: 2.5291\n",
      "\n",
      "Epoch 00058: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 59/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.492 - ETA: 3s - loss: 2.486 - ETA: 2s - loss: 2.486 - ETA: 2s - loss: 2.501 - ETA: 2s - loss: 2.499 - ETA: 2s - loss: 2.504 - ETA: 2s - loss: 2.507 - ETA: 1s - loss: 2.507 - ETA: 1s - loss: 2.513 - ETA: 1s - loss: 2.512 - ETA: 1s - loss: 2.516 - ETA: 1s - loss: 2.515 - ETA: 0s - loss: 2.518 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.514 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.518 - 3s 186us/step - loss: 2.5184\n",
      "\n",
      "Epoch 00059: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 60/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.512 - ETA: 3s - loss: 2.475 - ETA: 2s - loss: 2.489 - ETA: 2s - loss: 2.488 - ETA: 2s - loss: 2.495 - ETA: 2s - loss: 2.500 - ETA: 2s - loss: 2.497 - ETA: 1s - loss: 2.495 - ETA: 1s - loss: 2.502 - ETA: 1s - loss: 2.507 - ETA: 1s - loss: 2.509 - ETA: 1s - loss: 2.518 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.517 - ETA: 0s - loss: 2.518 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.517 - 3s 184us/step - loss: 2.5185\n",
      "\n",
      "Epoch 00060: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 61/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.497 - ETA: 3s - loss: 2.493 - ETA: 2s - loss: 2.469 - ETA: 2s - loss: 2.483 - ETA: 2s - loss: 2.490 - ETA: 2s - loss: 2.495 - ETA: 2s - loss: 2.502 - ETA: 1s - loss: 2.508 - ETA: 1s - loss: 2.504 - ETA: 1s - loss: 2.506 - ETA: 1s - loss: 2.509 - ETA: 1s - loss: 2.512 - ETA: 0s - loss: 2.509 - ETA: 0s - loss: 2.508 - ETA: 0s - loss: 2.512 - ETA: 0s - loss: 2.515 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.517 - 3s 185us/step - loss: 2.5175\n",
      "\n",
      "Epoch 00061: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 62/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.490 - ETA: 2s - loss: 2.495 - ETA: 2s - loss: 2.520 - ETA: 2s - loss: 2.506 - ETA: 2s - loss: 2.505 - ETA: 2s - loss: 2.505 - ETA: 2s - loss: 2.510 - ETA: 1s - loss: 2.511 - ETA: 1s - loss: 2.508 - ETA: 1s - loss: 2.500 - ETA: 1s - loss: 2.498 - ETA: 1s - loss: 2.501 - ETA: 0s - loss: 2.502 - ETA: 0s - loss: 2.503 - ETA: 0s - loss: 2.503 - ETA: 0s - loss: 2.503 - ETA: 0s - loss: 2.505 - ETA: 0s - loss: 2.506 - 3s 185us/step - loss: 2.5077\n",
      "\n",
      "Epoch 00062: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 63/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.532 - ETA: 3s - loss: 2.522 - ETA: 2s - loss: 2.523 - ETA: 2s - loss: 2.525 - ETA: 2s - loss: 2.536 - ETA: 2s - loss: 2.525 - ETA: 2s - loss: 2.528 - ETA: 1s - loss: 2.520 - ETA: 1s - loss: 2.516 - ETA: 1s - loss: 2.517 - ETA: 1s - loss: 2.516 - ETA: 1s - loss: 2.514 - ETA: 0s - loss: 2.518 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.512 - ETA: 0s - loss: 2.515 - ETA: 0s - loss: 2.516 - 3s 185us/step - loss: 2.5161\n",
      "\n",
      "Epoch 00063: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 64/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.491 - ETA: 3s - loss: 2.501 - ETA: 2s - loss: 2.501 - ETA: 2s - loss: 2.505 - ETA: 2s - loss: 2.496 - ETA: 2s - loss: 2.494 - ETA: 2s - loss: 2.492 - ETA: 1s - loss: 2.492 - ETA: 1s - loss: 2.501 - ETA: 1s - loss: 2.498 - ETA: 1s - loss: 2.496 - ETA: 1s - loss: 2.496 - ETA: 0s - loss: 2.497 - ETA: 0s - loss: 2.496 - ETA: 0s - loss: 2.497 - ETA: 0s - loss: 2.500 - ETA: 0s - loss: 2.505 - ETA: 0s - loss: 2.505 - 3s 185us/step - loss: 2.5054\n",
      "\n",
      "Epoch 00064: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 65/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.487 - ETA: 3s - loss: 2.454 - ETA: 2s - loss: 2.479 - ETA: 2s - loss: 2.475 - ETA: 2s - loss: 2.482 - ETA: 2s - loss: 2.494 - ETA: 2s - loss: 2.500 - ETA: 1s - loss: 2.490 - ETA: 1s - loss: 2.493 - ETA: 1s - loss: 2.494 - ETA: 1s - loss: 2.494 - ETA: 1s - loss: 2.490 - ETA: 0s - loss: 2.491 - ETA: 0s - loss: 2.494 - ETA: 0s - loss: 2.493 - ETA: 0s - loss: 2.498 - ETA: 0s - loss: 2.501 - ETA: 0s - loss: 2.500 - 3s 185us/step - loss: 2.5029\n",
      "\n",
      "Epoch 00065: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 66/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.507 - ETA: 3s - loss: 2.500 - ETA: 2s - loss: 2.500 - ETA: 2s - loss: 2.503 - ETA: 2s - loss: 2.504 - ETA: 2s - loss: 2.499 - ETA: 2s - loss: 2.506 - ETA: 1s - loss: 2.503 - ETA: 1s - loss: 2.507 - ETA: 1s - loss: 2.507 - ETA: 1s - loss: 2.507 - ETA: 1s - loss: 2.508 - ETA: 0s - loss: 2.509 - ETA: 0s - loss: 2.503 - ETA: 0s - loss: 2.502 - ETA: 0s - loss: 2.502 - ETA: 0s - loss: 2.500 - ETA: 0s - loss: 2.504 - 3s 186us/step - loss: 2.5049\n",
      "\n",
      "Epoch 00066: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 67/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.477 - ETA: 3s - loss: 2.483 - ETA: 2s - loss: 2.487 - ETA: 2s - loss: 2.487 - ETA: 2s - loss: 2.489 - ETA: 2s - loss: 2.485 - ETA: 2s - loss: 2.488 - ETA: 1s - loss: 2.488 - ETA: 1s - loss: 2.490 - ETA: 1s - loss: 2.498 - ETA: 1s - loss: 2.498 - ETA: 1s - loss: 2.499 - ETA: 0s - loss: 2.501 - ETA: 0s - loss: 2.499 - ETA: 0s - loss: 2.502 - ETA: 0s - loss: 2.500 - ETA: 0s - loss: 2.500 - ETA: 0s - loss: 2.500 - 3s 186us/step - loss: 2.5003\n",
      "\n",
      "Epoch 00067: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 3s - loss: 2.561 - ETA: 3s - loss: 2.509 - ETA: 2s - loss: 2.490 - ETA: 2s - loss: 2.482 - ETA: 2s - loss: 2.470 - ETA: 2s - loss: 2.474 - ETA: 2s - loss: 2.485 - ETA: 1s - loss: 2.487 - ETA: 1s - loss: 2.489 - ETA: 1s - loss: 2.486 - ETA: 1s - loss: 2.490 - ETA: 1s - loss: 2.487 - ETA: 0s - loss: 2.479 - ETA: 0s - loss: 2.477 - ETA: 0s - loss: 2.480 - ETA: 0s - loss: 2.478 - ETA: 0s - loss: 2.480 - ETA: 0s - loss: 2.484 - 3s 186us/step - loss: 2.4845\n",
      "\n",
      "Epoch 00068: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 69/100\n",
      "18536/18536 [==============================] - ETA: 3s - loss: 2.421 - ETA: 3s - loss: 2.413 - ETA: 2s - loss: 2.444 - ETA: 2s - loss: 2.473 - ETA: 2s - loss: 2.472 - ETA: 2s - loss: 2.472 - ETA: 2s - loss: 2.474 - ETA: 1s - loss: 2.480 - ETA: 1s - loss: 2.476 - ETA: 1s - loss: 2.478 - ETA: 1s - loss: 2.479 - ETA: 1s - loss: 2.473 - ETA: 0s - loss: 2.476 - ETA: 0s - loss: 2.471 - ETA: 0s - loss: 2.469 - ETA: 0s - loss: 2.473 - ETA: 0s - loss: 2.472 - ETA: 0s - loss: 2.475 - 3s 187us/step - loss: 2.4754\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00069: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 00069: early stopping\n",
      "the 1 fold crps is 0.012720\n",
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/100\n",
      "18537/18537 [==============================] - ETA: 17s - loss: 5.87 - ETA: 10s - loss: 5.84 - ETA: 7s - loss: 5.8274 - ETA: 5s - loss: 5.817 - ETA: 4s - loss: 5.784 - ETA: 4s - loss: 5.769 - ETA: 3s - loss: 5.759 - ETA: 3s - loss: 5.746 - ETA: 2s - loss: 5.727 - ETA: 2s - loss: 5.714 - ETA: 1s - loss: 5.700 - ETA: 1s - loss: 5.687 - ETA: 1s - loss: 5.669 - ETA: 1s - loss: 5.658 - ETA: 0s - loss: 5.649 - ETA: 0s - loss: 5.635 - ETA: 0s - loss: 5.618 - ETA: 0s - loss: 5.607 - 4s 237us/step - loss: 5.6053\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08281, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 5.314 - ETA: 2s - loss: 5.277 - ETA: 2s - loss: 5.253 - ETA: 2s - loss: 5.259 - ETA: 2s - loss: 5.237 - ETA: 2s - loss: 5.228 - ETA: 2s - loss: 5.216 - ETA: 1s - loss: 5.201 - ETA: 1s - loss: 5.197 - ETA: 1s - loss: 5.184 - ETA: 1s - loss: 5.170 - ETA: 1s - loss: 5.166 - ETA: 0s - loss: 5.150 - ETA: 0s - loss: 5.144 - ETA: 0s - loss: 5.135 - ETA: 0s - loss: 5.124 - ETA: 0s - loss: 5.119 - ETA: 0s - loss: 5.111 - 3s 188us/step - loss: 5.1100\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08281 to 0.07758, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 4.827 - ETA: 3s - loss: 4.850 - ETA: 2s - loss: 4.868 - ETA: 2s - loss: 4.855 - ETA: 2s - loss: 4.841 - ETA: 2s - loss: 4.819 - ETA: 2s - loss: 4.814 - ETA: 1s - loss: 4.791 - ETA: 1s - loss: 4.774 - ETA: 1s - loss: 4.763 - ETA: 1s - loss: 4.757 - ETA: 1s - loss: 4.745 - ETA: 0s - loss: 4.733 - ETA: 0s - loss: 4.724 - ETA: 0s - loss: 4.711 - ETA: 0s - loss: 4.697 - ETA: 0s - loss: 4.686 - ETA: 0s - loss: 4.679 - 3s 189us/step - loss: 4.6790\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.07758 to 0.06586, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 4.363 - ETA: 3s - loss: 4.390 - ETA: 2s - loss: 4.367 - ETA: 2s - loss: 4.365 - ETA: 2s - loss: 4.371 - ETA: 2s - loss: 4.347 - ETA: 2s - loss: 4.342 - ETA: 1s - loss: 4.342 - ETA: 1s - loss: 4.326 - ETA: 1s - loss: 4.316 - ETA: 1s - loss: 4.306 - ETA: 1s - loss: 4.294 - ETA: 0s - loss: 4.284 - ETA: 0s - loss: 4.274 - ETA: 0s - loss: 4.258 - ETA: 0s - loss: 4.251 - ETA: 0s - loss: 4.242 - ETA: 0s - loss: 4.238 - 4s 189us/step - loss: 4.2363\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.06586 to 0.04473, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 4.034 - ETA: 3s - loss: 3.977 - ETA: 2s - loss: 4.026 - ETA: 2s - loss: 3.986 - ETA: 2s - loss: 3.988 - ETA: 2s - loss: 3.976 - ETA: 2s - loss: 3.984 - ETA: 1s - loss: 3.970 - ETA: 1s - loss: 3.965 - ETA: 1s - loss: 3.947 - ETA: 1s - loss: 3.941 - ETA: 1s - loss: 3.932 - ETA: 0s - loss: 3.925 - ETA: 0s - loss: 3.919 - ETA: 0s - loss: 3.907 - ETA: 0s - loss: 3.900 - ETA: 0s - loss: 3.892 - ETA: 0s - loss: 3.881 - 3s 188us/step - loss: 3.8820\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.04473 to 0.02669, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 3.651 - ETA: 3s - loss: 3.701 - ETA: 2s - loss: 3.644 - ETA: 2s - loss: 3.633 - ETA: 2s - loss: 3.640 - ETA: 2s - loss: 3.636 - ETA: 2s - loss: 3.636 - ETA: 1s - loss: 3.630 - ETA: 1s - loss: 3.621 - ETA: 1s - loss: 3.608 - ETA: 1s - loss: 3.607 - ETA: 1s - loss: 3.606 - ETA: 0s - loss: 3.597 - ETA: 0s - loss: 3.583 - ETA: 0s - loss: 3.569 - ETA: 0s - loss: 3.561 - ETA: 0s - loss: 3.556 - ETA: 0s - loss: 3.549 - 3s 188us/step - loss: 3.5486\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.02669 to 0.01815, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 3.411 - ETA: 3s - loss: 3.353 - ETA: 2s - loss: 3.364 - ETA: 2s - loss: 3.357 - ETA: 2s - loss: 3.336 - ETA: 2s - loss: 3.338 - ETA: 2s - loss: 3.331 - ETA: 1s - loss: 3.321 - ETA: 1s - loss: 3.323 - ETA: 1s - loss: 3.316 - ETA: 1s - loss: 3.322 - ETA: 1s - loss: 3.316 - ETA: 0s - loss: 3.313 - ETA: 0s - loss: 3.307 - ETA: 0s - loss: 3.311 - ETA: 0s - loss: 3.304 - ETA: 0s - loss: 3.298 - ETA: 0s - loss: 3.289 - 4s 191us/step - loss: 3.2886\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01815 to 0.01508, saving model to best_model.h5\n",
      "Epoch 8/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 3.175 - ETA: 3s - loss: 3.154 - ETA: 2s - loss: 3.144 - ETA: 2s - loss: 3.114 - ETA: 2s - loss: 3.104 - ETA: 2s - loss: 3.115 - ETA: 2s - loss: 3.112 - ETA: 1s - loss: 3.105 - ETA: 1s - loss: 3.091 - ETA: 1s - loss: 3.097 - ETA: 1s - loss: 3.091 - ETA: 1s - loss: 3.087 - ETA: 0s - loss: 3.092 - ETA: 0s - loss: 3.091 - ETA: 0s - loss: 3.091 - ETA: 0s - loss: 3.089 - ETA: 0s - loss: 3.087 - ETA: 0s - loss: 3.086 - 3s 186us/step - loss: 3.0865\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01508 to 0.01384, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 3.057 - ETA: 3s - loss: 3.004 - ETA: 2s - loss: 2.984 - ETA: 2s - loss: 2.988 - ETA: 2s - loss: 2.980 - ETA: 2s - loss: 2.986 - ETA: 2s - loss: 2.993 - ETA: 1s - loss: 2.984 - ETA: 1s - loss: 2.984 - ETA: 1s - loss: 2.986 - ETA: 1s - loss: 2.983 - ETA: 1s - loss: 2.977 - ETA: 0s - loss: 2.981 - ETA: 0s - loss: 2.983 - ETA: 0s - loss: 2.983 - ETA: 0s - loss: 2.979 - ETA: 0s - loss: 2.976 - ETA: 0s - loss: 2.971 - 3s 188us/step - loss: 2.9706\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01384 to 0.01341, saving model to best_model.h5\n",
      "Epoch 10/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.901 - ETA: 3s - loss: 2.910 - ETA: 2s - loss: 2.920 - ETA: 2s - loss: 2.910 - ETA: 2s - loss: 2.906 - ETA: 2s - loss: 2.896 - ETA: 2s - loss: 2.892 - ETA: 1s - loss: 2.897 - ETA: 1s - loss: 2.895 - ETA: 1s - loss: 2.906 - ETA: 1s - loss: 2.907 - ETA: 1s - loss: 2.907 - ETA: 0s - loss: 2.902 - ETA: 0s - loss: 2.903 - ETA: 0s - loss: 2.904 - ETA: 0s - loss: 2.902 - ETA: 0s - loss: 2.898 - ETA: 0s - loss: 2.897 - 4s 190us/step - loss: 2.8968\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01341 to 0.01323, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.816 - ETA: 3s - loss: 2.862 - ETA: 2s - loss: 2.863 - ETA: 2s - loss: 2.861 - ETA: 2s - loss: 2.853 - ETA: 2s - loss: 2.860 - ETA: 2s - loss: 2.857 - ETA: 1s - loss: 2.859 - ETA: 1s - loss: 2.861 - ETA: 1s - loss: 2.855 - ETA: 1s - loss: 2.853 - ETA: 1s - loss: 2.848 - ETA: 0s - loss: 2.854 - ETA: 0s - loss: 2.858 - ETA: 0s - loss: 2.852 - ETA: 0s - loss: 2.851 - ETA: 0s - loss: 2.851 - ETA: 0s - loss: 2.849 - 3s 188us/step - loss: 2.8484\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01323 to 0.01315, saving model to best_model.h5\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 3s - loss: 2.827 - ETA: 3s - loss: 2.797 - ETA: 2s - loss: 2.814 - ETA: 2s - loss: 2.823 - ETA: 2s - loss: 2.818 - ETA: 2s - loss: 2.797 - ETA: 2s - loss: 2.794 - ETA: 1s - loss: 2.804 - ETA: 1s - loss: 2.799 - ETA: 1s - loss: 2.801 - ETA: 1s - loss: 2.798 - ETA: 1s - loss: 2.797 - ETA: 0s - loss: 2.800 - ETA: 0s - loss: 2.798 - ETA: 0s - loss: 2.800 - ETA: 0s - loss: 2.801 - ETA: 0s - loss: 2.804 - ETA: 0s - loss: 2.809 - 3s 186us/step - loss: 2.8107\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01315 to 0.01310, saving model to best_model.h5\n",
      "Epoch 13/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.811 - ETA: 3s - loss: 2.784 - ETA: 2s - loss: 2.787 - ETA: 2s - loss: 2.789 - ETA: 2s - loss: 2.790 - ETA: 2s - loss: 2.800 - ETA: 2s - loss: 2.796 - ETA: 1s - loss: 2.797 - ETA: 1s - loss: 2.805 - ETA: 1s - loss: 2.806 - ETA: 1s - loss: 2.804 - ETA: 1s - loss: 2.801 - ETA: 0s - loss: 2.797 - ETA: 0s - loss: 2.799 - ETA: 0s - loss: 2.797 - ETA: 0s - loss: 2.798 - ETA: 0s - loss: 2.798 - ETA: 0s - loss: 2.797 - 3s 188us/step - loss: 2.7980\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01310 to 0.01304, saving model to best_model.h5\n",
      "Epoch 14/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.709 - ETA: 3s - loss: 2.730 - ETA: 2s - loss: 2.771 - ETA: 2s - loss: 2.761 - ETA: 2s - loss: 2.757 - ETA: 2s - loss: 2.754 - ETA: 2s - loss: 2.754 - ETA: 1s - loss: 2.762 - ETA: 1s - loss: 2.764 - ETA: 1s - loss: 2.766 - ETA: 1s - loss: 2.765 - ETA: 1s - loss: 2.770 - ETA: 0s - loss: 2.773 - ETA: 0s - loss: 2.774 - ETA: 0s - loss: 2.775 - ETA: 0s - loss: 2.776 - ETA: 0s - loss: 2.777 - ETA: 0s - loss: 2.777 - 3s 187us/step - loss: 2.7768\n",
      "\n",
      "Epoch 00014: CRPS_score_val improved from 0.01304 to 0.01301, saving model to best_model.h5\n",
      "Epoch 15/100\n",
      "18537/18537 [==============================] - ETA: 4s - loss: 2.784 - ETA: 3s - loss: 2.778 - ETA: 3s - loss: 2.771 - ETA: 2s - loss: 2.779 - ETA: 2s - loss: 2.784 - ETA: 2s - loss: 2.775 - ETA: 2s - loss: 2.762 - ETA: 1s - loss: 2.767 - ETA: 1s - loss: 2.768 - ETA: 1s - loss: 2.770 - ETA: 1s - loss: 2.768 - ETA: 1s - loss: 2.771 - ETA: 0s - loss: 2.769 - ETA: 0s - loss: 2.765 - ETA: 0s - loss: 2.766 - ETA: 0s - loss: 2.765 - ETA: 0s - loss: 2.764 - ETA: 0s - loss: 2.768 - 4s 189us/step - loss: 2.7682\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01301 to 0.01297, saving model to best_model.h5\n",
      "Epoch 16/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.659 - ETA: 3s - loss: 2.728 - ETA: 2s - loss: 2.756 - ETA: 2s - loss: 2.770 - ETA: 2s - loss: 2.752 - ETA: 2s - loss: 2.746 - ETA: 2s - loss: 2.743 - ETA: 1s - loss: 2.741 - ETA: 1s - loss: 2.740 - ETA: 1s - loss: 2.738 - ETA: 1s - loss: 2.741 - ETA: 1s - loss: 2.744 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.746 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.747 - 4s 190us/step - loss: 2.7469\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01297 to 0.01293, saving model to best_model.h5\n",
      "Epoch 17/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.660 - ETA: 3s - loss: 2.721 - ETA: 2s - loss: 2.728 - ETA: 2s - loss: 2.712 - ETA: 2s - loss: 2.700 - ETA: 2s - loss: 2.715 - ETA: 2s - loss: 2.728 - ETA: 1s - loss: 2.722 - ETA: 1s - loss: 2.721 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.724 - ETA: 1s - loss: 2.722 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.730 - ETA: 0s - loss: 2.731 - ETA: 0s - loss: 2.732 - ETA: 0s - loss: 2.732 - 3s 186us/step - loss: 2.7327\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01293 to 0.01290, saving model to best_model.h5\n",
      "Epoch 18/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.737 - ETA: 3s - loss: 2.727 - ETA: 3s - loss: 2.733 - ETA: 2s - loss: 2.741 - ETA: 2s - loss: 2.739 - ETA: 2s - loss: 2.732 - ETA: 2s - loss: 2.725 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.722 - ETA: 1s - loss: 2.721 - ETA: 1s - loss: 2.716 - ETA: 1s - loss: 2.719 - ETA: 0s - loss: 2.721 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.725 - ETA: 0s - loss: 2.722 - ETA: 0s - loss: 2.722 - 3s 189us/step - loss: 2.7229\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01290 to 0.01289, saving model to best_model.h5\n",
      "Epoch 19/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.726 - ETA: 3s - loss: 2.742 - ETA: 2s - loss: 2.729 - ETA: 2s - loss: 2.710 - ETA: 2s - loss: 2.717 - ETA: 2s - loss: 2.713 - ETA: 2s - loss: 2.717 - ETA: 1s - loss: 2.713 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.713 - ETA: 1s - loss: 2.714 - ETA: 1s - loss: 2.717 - ETA: 0s - loss: 2.712 - ETA: 0s - loss: 2.711 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.712 - ETA: 0s - loss: 2.713 - 3s 188us/step - loss: 2.7122\n",
      "\n",
      "Epoch 00019: CRPS_score_val improved from 0.01289 to 0.01286, saving model to best_model.h5\n",
      "Epoch 20/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.761 - ETA: 3s - loss: 2.731 - ETA: 2s - loss: 2.720 - ETA: 2s - loss: 2.708 - ETA: 2s - loss: 2.707 - ETA: 2s - loss: 2.701 - ETA: 2s - loss: 2.706 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.706 - ETA: 1s - loss: 2.707 - ETA: 1s - loss: 2.704 - ETA: 1s - loss: 2.703 - ETA: 0s - loss: 2.708 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.707 - 3s 188us/step - loss: 2.7069\n",
      "\n",
      "Epoch 00020: CRPS_score_val improved from 0.01286 to 0.01284, saving model to best_model.h5\n",
      "Epoch 21/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.746 - ETA: 3s - loss: 2.708 - ETA: 2s - loss: 2.706 - ETA: 2s - loss: 2.710 - ETA: 2s - loss: 2.717 - ETA: 2s - loss: 2.709 - ETA: 2s - loss: 2.709 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.703 - ETA: 0s - loss: 2.708 - ETA: 0s - loss: 2.709 - ETA: 0s - loss: 2.704 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.701 - ETA: 0s - loss: 2.701 - 3s 186us/step - loss: 2.7012\n",
      "\n",
      "Epoch 00021: CRPS_score_val improved from 0.01284 to 0.01282, saving model to best_model.h5\n",
      "Epoch 22/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.699 - ETA: 3s - loss: 2.695 - ETA: 3s - loss: 2.675 - ETA: 2s - loss: 2.682 - ETA: 2s - loss: 2.671 - ETA: 2s - loss: 2.674 - ETA: 2s - loss: 2.676 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.679 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.689 - ETA: 0s - loss: 2.687 - 3s 188us/step - loss: 2.6869\n",
      "\n",
      "Epoch 00022: CRPS_score_val did not improve from 0.01282\n",
      "Epoch 23/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.698 - ETA: 3s - loss: 2.703 - ETA: 2s - loss: 2.696 - ETA: 2s - loss: 2.704 - ETA: 2s - loss: 2.693 - ETA: 2s - loss: 2.684 - ETA: 2s - loss: 2.685 - ETA: 1s - loss: 2.686 - ETA: 1s - loss: 2.685 - ETA: 1s - loss: 2.686 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.690 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.695 - ETA: 0s - loss: 2.694 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.692 - ETA: 0s - loss: 2.689 - 3s 187us/step - loss: 2.6901\n",
      "\n",
      "Epoch 00023: CRPS_score_val improved from 0.01282 to 0.01280, saving model to best_model.h5\n",
      "Epoch 24/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.609 - ETA: 3s - loss: 2.624 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.641 - ETA: 2s - loss: 2.644 - ETA: 2s - loss: 2.657 - ETA: 2s - loss: 2.654 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.666 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.675 - 3s 187us/step - loss: 2.6745\n",
      "\n",
      "Epoch 00024: CRPS_score_val improved from 0.01280 to 0.01277, saving model to best_model.h5\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 3s - loss: 2.629 - ETA: 3s - loss: 2.626 - ETA: 3s - loss: 2.655 - ETA: 2s - loss: 2.652 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.653 - ETA: 2s - loss: 2.656 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.670 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.675 - 3s 188us/step - loss: 2.6751\n",
      "\n",
      "Epoch 00025: CRPS_score_val did not improve from 0.01277\n",
      "Epoch 26/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.672 - ETA: 3s - loss: 2.657 - ETA: 2s - loss: 2.653 - ETA: 2s - loss: 2.663 - ETA: 2s - loss: 2.658 - ETA: 2s - loss: 2.657 - ETA: 2s - loss: 2.658 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.663 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.661 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.663 - 3s 187us/step - loss: 2.6649\n",
      "\n",
      "Epoch 00026: CRPS_score_val did not improve from 0.01277\n",
      "Epoch 27/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.636 - ETA: 3s - loss: 2.688 - ETA: 2s - loss: 2.686 - ETA: 2s - loss: 2.682 - ETA: 2s - loss: 2.679 - ETA: 2s - loss: 2.686 - ETA: 2s - loss: 2.682 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.671 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.675 - ETA: 1s - loss: 2.672 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.661 - ETA: 0s - loss: 2.661 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.665 - 3s 188us/step - loss: 2.6650\n",
      "\n",
      "Epoch 00027: CRPS_score_val improved from 0.01277 to 0.01274, saving model to best_model.h5\n",
      "Epoch 28/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.670 - ETA: 3s - loss: 2.653 - ETA: 2s - loss: 2.682 - ETA: 2s - loss: 2.650 - ETA: 2s - loss: 2.637 - ETA: 2s - loss: 2.635 - ETA: 2s - loss: 2.633 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.647 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.657 - 3s 186us/step - loss: 2.6572\n",
      "\n",
      "Epoch 00028: CRPS_score_val did not improve from 0.01274\n",
      "Epoch 29/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.594 - ETA: 3s - loss: 2.622 - ETA: 3s - loss: 2.628 - ETA: 2s - loss: 2.627 - ETA: 2s - loss: 2.627 - ETA: 2s - loss: 2.626 - ETA: 2s - loss: 2.630 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.646 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.653 - ETA: 0s - loss: 2.653 - ETA: 0s - loss: 2.655 - 4s 190us/step - loss: 2.6548\n",
      "\n",
      "Epoch 00029: CRPS_score_val improved from 0.01274 to 0.01273, saving model to best_model.h5\n",
      "Epoch 30/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.708 - ETA: 3s - loss: 2.678 - ETA: 2s - loss: 2.682 - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.648 - ETA: 2s - loss: 2.656 - ETA: 2s - loss: 2.654 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.647 - ETA: 1s - loss: 2.647 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.642 - 3s 188us/step - loss: 2.6411\n",
      "\n",
      "Epoch 00030: CRPS_score_val improved from 0.01273 to 0.01272, saving model to best_model.h5\n",
      "Epoch 31/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.651 - ETA: 3s - loss: 2.655 - ETA: 2s - loss: 2.637 - ETA: 2s - loss: 2.641 - ETA: 2s - loss: 2.643 - ETA: 2s - loss: 2.637 - ETA: 2s - loss: 2.632 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.635 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.642 - 4s 189us/step - loss: 2.6429\n",
      "\n",
      "Epoch 00031: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 32/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.624 - ETA: 3s - loss: 2.631 - ETA: 2s - loss: 2.638 - ETA: 2s - loss: 2.646 - ETA: 2s - loss: 2.642 - ETA: 2s - loss: 2.641 - ETA: 2s - loss: 2.640 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.640 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - 4s 192us/step - loss: 2.6378\n",
      "\n",
      "Epoch 00032: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 33/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.621 - ETA: 3s - loss: 2.633 - ETA: 2s - loss: 2.633 - ETA: 2s - loss: 2.622 - ETA: 2s - loss: 2.622 - ETA: 2s - loss: 2.632 - ETA: 2s - loss: 2.633 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.638 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - 3s 187us/step - loss: 2.6375\n",
      "\n",
      "Epoch 00033: CRPS_score_val did not improve from 0.01272\n",
      "Epoch 34/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.595 - ETA: 3s - loss: 2.625 - ETA: 2s - loss: 2.639 - ETA: 2s - loss: 2.642 - ETA: 2s - loss: 2.633 - ETA: 2s - loss: 2.634 - ETA: 2s - loss: 2.626 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.625 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.633 - 3s 187us/step - loss: 2.6325\n",
      "\n",
      "Epoch 00034: CRPS_score_val improved from 0.01272 to 0.01271, saving model to best_model.h5\n",
      "Epoch 35/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.655 - ETA: 3s - loss: 2.634 - ETA: 2s - loss: 2.635 - ETA: 2s - loss: 2.633 - ETA: 2s - loss: 2.636 - ETA: 2s - loss: 2.636 - ETA: 2s - loss: 2.639 - ETA: 1s - loss: 2.647 - ETA: 1s - loss: 2.649 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.629 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.624 - 3s 188us/step - loss: 2.6246\n",
      "\n",
      "Epoch 00035: CRPS_score_val did not improve from 0.01271\n",
      "Epoch 36/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.632 - ETA: 3s - loss: 2.614 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.622 - ETA: 2s - loss: 2.629 - ETA: 2s - loss: 2.626 - ETA: 2s - loss: 2.615 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.619 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.619 - 3s 187us/step - loss: 2.6186\n",
      "\n",
      "Epoch 00036: CRPS_score_val did not improve from 0.01271\n",
      "Epoch 37/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.597 - ETA: 3s - loss: 2.624 - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.616 - ETA: 2s - loss: 2.618 - ETA: 2s - loss: 2.621 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.622 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.619 - 3s 186us/step - loss: 2.6193\n",
      "\n",
      "Epoch 00037: CRPS_score_val did not improve from 0.01271\n",
      "Epoch 38/100\n",
      "18537/18537 [==============================] - ETA: 4s - loss: 2.622 - ETA: 3s - loss: 2.612 - ETA: 3s - loss: 2.611 - ETA: 2s - loss: 2.595 - ETA: 2s - loss: 2.595 - ETA: 2s - loss: 2.593 - ETA: 2s - loss: 2.606 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.609 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.612 - 3s 188us/step - loss: 2.6122\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00038: CRPS_score_val did not improve from 0.01271\n",
      "Epoch 39/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.572 - ETA: 3s - loss: 2.592 - ETA: 2s - loss: 2.610 - ETA: 2s - loss: 2.604 - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.619 - ETA: 2s - loss: 2.618 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.613 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.609 - 3s 188us/step - loss: 2.6102\n",
      "\n",
      "Epoch 00039: CRPS_score_val did not improve from 0.01271\n",
      "Epoch 40/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.612 - ETA: 3s - loss: 2.600 - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.606 - ETA: 2s - loss: 2.603 - ETA: 2s - loss: 2.597 - ETA: 2s - loss: 2.606 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.601 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.595 - 3s 186us/step - loss: 2.5959\n",
      "\n",
      "Epoch 00040: CRPS_score_val did not improve from 0.01271\n",
      "Epoch 41/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.626 - ETA: 3s - loss: 2.621 - ETA: 2s - loss: 2.625 - ETA: 2s - loss: 2.619 - ETA: 2s - loss: 2.616 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.609 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.597 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.595 - 3s 186us/step - loss: 2.5960\n",
      "\n",
      "Epoch 00041: CRPS_score_val did not improve from 0.01271\n",
      "Epoch 42/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.627 - ETA: 3s - loss: 2.628 - ETA: 2s - loss: 2.610 - ETA: 2s - loss: 2.609 - ETA: 2s - loss: 2.610 - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.601 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.608 - ETA: 0s - loss: 2.607 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.607 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.602 - 3s 188us/step - loss: 2.6031\n",
      "\n",
      "Epoch 00042: CRPS_score_val did not improve from 0.01271\n",
      "Epoch 43/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.576 - ETA: 3s - loss: 2.614 - ETA: 2s - loss: 2.622 - ETA: 2s - loss: 2.631 - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.620 - ETA: 2s - loss: 2.614 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.609 - ETA: 1s - loss: 2.607 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.601 - 3s 186us/step - loss: 2.6016\n",
      "\n",
      "Epoch 00043: CRPS_score_val improved from 0.01271 to 0.01271, saving model to best_model.h5\n",
      "Epoch 44/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.552 - ETA: 3s - loss: 2.533 - ETA: 2s - loss: 2.568 - ETA: 2s - loss: 2.558 - ETA: 2s - loss: 2.562 - ETA: 2s - loss: 2.572 - ETA: 2s - loss: 2.574 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.581 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.581 - ETA: 0s - loss: 2.581 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.581 - 3s 188us/step - loss: 2.5828\n",
      "\n",
      "Epoch 00044: CRPS_score_val improved from 0.01271 to 0.01270, saving model to best_model.h5\n",
      "Epoch 45/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.619 - ETA: 3s - loss: 2.610 - ETA: 2s - loss: 2.586 - ETA: 2s - loss: 2.588 - ETA: 2s - loss: 2.598 - ETA: 2s - loss: 2.592 - ETA: 2s - loss: 2.592 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.598 - ETA: 1s - loss: 2.598 - ETA: 1s - loss: 2.597 - ETA: 1s - loss: 2.596 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.583 - 3s 187us/step - loss: 2.5838\n",
      "\n",
      "Epoch 00045: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 46/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.602 - ETA: 3s - loss: 2.584 - ETA: 2s - loss: 2.588 - ETA: 2s - loss: 2.582 - ETA: 2s - loss: 2.580 - ETA: 2s - loss: 2.588 - ETA: 2s - loss: 2.584 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.588 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.584 - ETA: 0s - loss: 2.579 - ETA: 0s - loss: 2.579 - ETA: 0s - loss: 2.576 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.575 - 3s 186us/step - loss: 2.5749\n",
      "\n",
      "Epoch 00046: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 47/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.596 - ETA: 3s - loss: 2.568 - ETA: 2s - loss: 2.561 - ETA: 2s - loss: 2.560 - ETA: 2s - loss: 2.559 - ETA: 2s - loss: 2.563 - ETA: 2s - loss: 2.563 - ETA: 1s - loss: 2.575 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.567 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.576 - 3s 187us/step - loss: 2.5778\n",
      "\n",
      "Epoch 00047: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 48/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.539 - ETA: 3s - loss: 2.540 - ETA: 2s - loss: 2.527 - ETA: 2s - loss: 2.534 - ETA: 2s - loss: 2.534 - ETA: 2s - loss: 2.552 - ETA: 2s - loss: 2.563 - ETA: 1s - loss: 2.569 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.581 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.577 - 3s 189us/step - loss: 2.5776\n",
      "\n",
      "Epoch 00048: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 49/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.531 - ETA: 3s - loss: 2.537 - ETA: 2s - loss: 2.545 - ETA: 2s - loss: 2.547 - ETA: 2s - loss: 2.553 - ETA: 2s - loss: 2.555 - ETA: 2s - loss: 2.562 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.567 - ETA: 1s - loss: 2.568 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.566 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.568 - 4s 190us/step - loss: 2.5687\n",
      "\n",
      "Epoch 00049: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 50/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.483 - ETA: 3s - loss: 2.515 - ETA: 2s - loss: 2.542 - ETA: 2s - loss: 2.554 - ETA: 2s - loss: 2.554 - ETA: 2s - loss: 2.559 - ETA: 2s - loss: 2.566 - ETA: 1s - loss: 2.569 - ETA: 1s - loss: 2.567 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.566 - ETA: 1s - loss: 2.566 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.566 - ETA: 0s - loss: 2.566 - 3s 189us/step - loss: 2.5661\n",
      "\n",
      "Epoch 00050: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 51/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.531 - ETA: 3s - loss: 2.538 - ETA: 2s - loss: 2.536 - ETA: 2s - loss: 2.553 - ETA: 2s - loss: 2.557 - ETA: 2s - loss: 2.567 - ETA: 2s - loss: 2.569 - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.562 - ETA: 1s - loss: 2.563 - ETA: 1s - loss: 2.560 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.557 - ETA: 0s - loss: 2.558 - 4s 189us/step - loss: 2.5585\n",
      "\n",
      "Epoch 00051: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 52/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.514 - ETA: 3s - loss: 2.504 - ETA: 2s - loss: 2.524 - ETA: 2s - loss: 2.527 - ETA: 2s - loss: 2.552 - ETA: 2s - loss: 2.551 - ETA: 2s - loss: 2.552 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.553 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.554 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.557 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.557 - 4s 190us/step - loss: 2.5569\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00052: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 53/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.542 - ETA: 3s - loss: 2.524 - ETA: 2s - loss: 2.530 - ETA: 2s - loss: 2.544 - ETA: 2s - loss: 2.538 - ETA: 2s - loss: 2.539 - ETA: 2s - loss: 2.531 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.536 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.543 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.545 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.548 - ETA: 0s - loss: 2.549 - 3s 188us/step - loss: 2.5494\n",
      "\n",
      "Epoch 00053: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 54/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.571 - ETA: 3s - loss: 2.559 - ETA: 2s - loss: 2.561 - ETA: 2s - loss: 2.555 - ETA: 2s - loss: 2.549 - ETA: 2s - loss: 2.546 - ETA: 2s - loss: 2.541 - ETA: 1s - loss: 2.541 - ETA: 1s - loss: 2.537 - ETA: 1s - loss: 2.533 - ETA: 1s - loss: 2.539 - ETA: 1s - loss: 2.538 - ETA: 0s - loss: 2.541 - ETA: 0s - loss: 2.539 - ETA: 0s - loss: 2.539 - ETA: 0s - loss: 2.539 - ETA: 0s - loss: 2.538 - ETA: 0s - loss: 2.539 - 3s 187us/step - loss: 2.5395\n",
      "\n",
      "Epoch 00054: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 55/100\n",
      "18537/18537 [==============================] - ETA: 4s - loss: 2.517 - ETA: 3s - loss: 2.516 - ETA: 3s - loss: 2.520 - ETA: 2s - loss: 2.525 - ETA: 2s - loss: 2.527 - ETA: 2s - loss: 2.527 - ETA: 2s - loss: 2.528 - ETA: 2s - loss: 2.534 - ETA: 1s - loss: 2.531 - ETA: 1s - loss: 2.533 - ETA: 1s - loss: 2.529 - ETA: 1s - loss: 2.526 - ETA: 0s - loss: 2.529 - ETA: 0s - loss: 2.527 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.533 - ETA: 0s - loss: 2.537 - 4s 192us/step - loss: 2.5376\n",
      "\n",
      "Epoch 00055: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 56/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.547 - ETA: 3s - loss: 2.520 - ETA: 2s - loss: 2.506 - ETA: 2s - loss: 2.526 - ETA: 2s - loss: 2.536 - ETA: 2s - loss: 2.528 - ETA: 2s - loss: 2.525 - ETA: 1s - loss: 2.526 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.529 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.529 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.535 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.535 - ETA: 0s - loss: 2.535 - ETA: 0s - loss: 2.537 - 3s 187us/step - loss: 2.5375\n",
      "\n",
      "Epoch 00056: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 57/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.473 - ETA: 3s - loss: 2.481 - ETA: 2s - loss: 2.470 - ETA: 2s - loss: 2.479 - ETA: 2s - loss: 2.489 - ETA: 2s - loss: 2.497 - ETA: 2s - loss: 2.505 - ETA: 1s - loss: 2.516 - ETA: 1s - loss: 2.522 - ETA: 1s - loss: 2.519 - ETA: 1s - loss: 2.520 - ETA: 1s - loss: 2.519 - ETA: 0s - loss: 2.524 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.533 - ETA: 0s - loss: 2.534 - ETA: 0s - loss: 2.535 - ETA: 0s - loss: 2.535 - 3s 187us/step - loss: 2.5344\n",
      "\n",
      "Epoch 00057: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 58/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.495 - ETA: 3s - loss: 2.504 - ETA: 2s - loss: 2.516 - ETA: 2s - loss: 2.528 - ETA: 2s - loss: 2.531 - ETA: 2s - loss: 2.527 - ETA: 2s - loss: 2.519 - ETA: 1s - loss: 2.521 - ETA: 1s - loss: 2.523 - ETA: 1s - loss: 2.523 - ETA: 1s - loss: 2.522 - ETA: 1s - loss: 2.523 - ETA: 0s - loss: 2.524 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.526 - ETA: 0s - loss: 2.528 - ETA: 0s - loss: 2.529 - 4s 190us/step - loss: 2.5289\n",
      "\n",
      "Epoch 00058: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 59/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.547 - ETA: 3s - loss: 2.524 - ETA: 3s - loss: 2.534 - ETA: 2s - loss: 2.535 - ETA: 2s - loss: 2.528 - ETA: 2s - loss: 2.522 - ETA: 2s - loss: 2.528 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.523 - ETA: 1s - loss: 2.526 - ETA: 1s - loss: 2.521 - ETA: 1s - loss: 2.525 - ETA: 0s - loss: 2.523 - ETA: 0s - loss: 2.524 - ETA: 0s - loss: 2.527 - ETA: 0s - loss: 2.527 - ETA: 0s - loss: 2.526 - ETA: 0s - loss: 2.526 - 4s 190us/step - loss: 2.5268\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00059: CRPS_score_val did not improve from 0.01270\n",
      "Epoch 00059: early stopping\n",
      "the 2 fold crps is 0.012703\n",
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/100\n",
      "18537/18537 [==============================] - ETA: 16s - loss: 5.88 - ETA: 9s - loss: 5.8406 - ETA: 7s - loss: 5.820 - ETA: 5s - loss: 5.809 - ETA: 4s - loss: 5.800 - ETA: 4s - loss: 5.784 - ETA: 3s - loss: 5.768 - ETA: 3s - loss: 5.752 - ETA: 2s - loss: 5.742 - ETA: 2s - loss: 5.730 - ETA: 1s - loss: 5.717 - ETA: 1s - loss: 5.703 - ETA: 1s - loss: 5.686 - ETA: 1s - loss: 5.676 - ETA: 0s - loss: 5.664 - ETA: 0s - loss: 5.652 - ETA: 0s - loss: 5.637 - ETA: 0s - loss: 5.621 - 4s 239us/step - loss: 5.6208\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08281, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 5.309 - ETA: 3s - loss: 5.290 - ETA: 3s - loss: 5.269 - ETA: 2s - loss: 5.267 - ETA: 2s - loss: 5.247 - ETA: 2s - loss: 5.236 - ETA: 2s - loss: 5.224 - ETA: 1s - loss: 5.213 - ETA: 1s - loss: 5.215 - ETA: 1s - loss: 5.203 - ETA: 1s - loss: 5.188 - ETA: 1s - loss: 5.177 - ETA: 1s - loss: 5.162 - ETA: 0s - loss: 5.149 - ETA: 0s - loss: 5.140 - ETA: 0s - loss: 5.131 - ETA: 0s - loss: 5.117 - ETA: 0s - loss: 5.105 - 4s 194us/step - loss: 5.1044\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08281 to 0.07760, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 4.865 - ETA: 3s - loss: 4.864 - ETA: 3s - loss: 4.861 - ETA: 2s - loss: 4.824 - ETA: 2s - loss: 4.818 - ETA: 2s - loss: 4.815 - ETA: 2s - loss: 4.798 - ETA: 2s - loss: 4.789 - ETA: 1s - loss: 4.770 - ETA: 1s - loss: 4.764 - ETA: 1s - loss: 4.745 - ETA: 1s - loss: 4.730 - ETA: 1s - loss: 4.712 - ETA: 0s - loss: 4.705 - ETA: 0s - loss: 4.691 - ETA: 0s - loss: 4.679 - ETA: 0s - loss: 4.674 - ETA: 0s - loss: 4.661 - 4s 198us/step - loss: 4.6604\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.07760 to 0.06561, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 4.437 - ETA: 3s - loss: 4.403 - ETA: 3s - loss: 4.368 - ETA: 2s - loss: 4.335 - ETA: 2s - loss: 4.335 - ETA: 2s - loss: 4.333 - ETA: 2s - loss: 4.318 - ETA: 2s - loss: 4.327 - ETA: 1s - loss: 4.308 - ETA: 1s - loss: 4.301 - ETA: 1s - loss: 4.293 - ETA: 1s - loss: 4.282 - ETA: 1s - loss: 4.273 - ETA: 0s - loss: 4.269 - ETA: 0s - loss: 4.264 - ETA: 0s - loss: 4.254 - ETA: 0s - loss: 4.244 - ETA: 0s - loss: 4.239 - 4s 195us/step - loss: 4.2385\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.06561 to 0.04559, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 3.984 - ETA: 3s - loss: 3.948 - ETA: 2s - loss: 3.970 - ETA: 2s - loss: 3.982 - ETA: 2s - loss: 3.981 - ETA: 2s - loss: 3.976 - ETA: 2s - loss: 3.966 - ETA: 1s - loss: 3.957 - ETA: 1s - loss: 3.951 - ETA: 1s - loss: 3.932 - ETA: 1s - loss: 3.919 - ETA: 1s - loss: 3.909 - ETA: 1s - loss: 3.895 - ETA: 0s - loss: 3.881 - ETA: 0s - loss: 3.873 - ETA: 0s - loss: 3.863 - ETA: 0s - loss: 3.863 - ETA: 0s - loss: 3.854 - 4s 194us/step - loss: 3.8525\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.04559 to 0.02888, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 3.660 - ETA: 3s - loss: 3.690 - ETA: 3s - loss: 3.665 - ETA: 2s - loss: 3.635 - ETA: 2s - loss: 3.634 - ETA: 2s - loss: 3.630 - ETA: 2s - loss: 3.624 - ETA: 2s - loss: 3.612 - ETA: 1s - loss: 3.606 - ETA: 1s - loss: 3.600 - ETA: 1s - loss: 3.592 - ETA: 1s - loss: 3.592 - ETA: 1s - loss: 3.587 - ETA: 0s - loss: 3.583 - ETA: 0s - loss: 3.573 - ETA: 0s - loss: 3.563 - ETA: 0s - loss: 3.553 - ETA: 0s - loss: 3.540 - 4s 196us/step - loss: 3.5388\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.02888 to 0.01970, saving model to best_model.h5\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 3s - loss: 3.297 - ETA: 3s - loss: 3.340 - ETA: 2s - loss: 3.370 - ETA: 2s - loss: 3.357 - ETA: 2s - loss: 3.327 - ETA: 2s - loss: 3.331 - ETA: 2s - loss: 3.326 - ETA: 1s - loss: 3.330 - ETA: 1s - loss: 3.325 - ETA: 1s - loss: 3.323 - ETA: 1s - loss: 3.316 - ETA: 1s - loss: 3.313 - ETA: 1s - loss: 3.302 - ETA: 0s - loss: 3.296 - ETA: 0s - loss: 3.294 - ETA: 0s - loss: 3.284 - ETA: 0s - loss: 3.275 - ETA: 0s - loss: 3.264 - 4s 194us/step - loss: 3.2632\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01970 to 0.01554, saving model to best_model.h5\n",
      "Epoch 8/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 3.162 - ETA: 3s - loss: 3.171 - ETA: 3s - loss: 3.157 - ETA: 2s - loss: 3.133 - ETA: 2s - loss: 3.141 - ETA: 2s - loss: 3.129 - ETA: 2s - loss: 3.122 - ETA: 2s - loss: 3.117 - ETA: 1s - loss: 3.114 - ETA: 1s - loss: 3.118 - ETA: 1s - loss: 3.114 - ETA: 1s - loss: 3.108 - ETA: 1s - loss: 3.102 - ETA: 0s - loss: 3.101 - ETA: 0s - loss: 3.102 - ETA: 0s - loss: 3.095 - ETA: 0s - loss: 3.089 - ETA: 0s - loss: 3.083 - 4s 194us/step - loss: 3.0826\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01554 to 0.01405, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.991 - ETA: 3s - loss: 2.982 - ETA: 3s - loss: 3.011 - ETA: 2s - loss: 3.010 - ETA: 2s - loss: 3.020 - ETA: 2s - loss: 3.013 - ETA: 2s - loss: 3.015 - ETA: 2s - loss: 3.004 - ETA: 1s - loss: 3.002 - ETA: 1s - loss: 2.986 - ETA: 1s - loss: 2.993 - ETA: 1s - loss: 2.993 - ETA: 1s - loss: 2.992 - ETA: 0s - loss: 2.991 - ETA: 0s - loss: 2.987 - ETA: 0s - loss: 2.980 - ETA: 0s - loss: 2.978 - ETA: 0s - loss: 2.973 - 4s 195us/step - loss: 2.9744\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01405 to 0.01335, saving model to best_model.h5\n",
      "Epoch 10/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.956 - ETA: 3s - loss: 2.924 - ETA: 3s - loss: 2.925 - ETA: 2s - loss: 2.920 - ETA: 2s - loss: 2.911 - ETA: 2s - loss: 2.909 - ETA: 2s - loss: 2.912 - ETA: 2s - loss: 2.907 - ETA: 1s - loss: 2.916 - ETA: 1s - loss: 2.912 - ETA: 1s - loss: 2.906 - ETA: 1s - loss: 2.904 - ETA: 1s - loss: 2.901 - ETA: 0s - loss: 2.903 - ETA: 0s - loss: 2.902 - ETA: 0s - loss: 2.900 - ETA: 0s - loss: 2.901 - ETA: 0s - loss: 2.901 - 4s 196us/step - loss: 2.9017\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01335 to 0.01319, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "18537/18537 [==============================] - ETA: 4s - loss: 2.844 - ETA: 3s - loss: 2.854 - ETA: 3s - loss: 2.838 - ETA: 2s - loss: 2.853 - ETA: 2s - loss: 2.843 - ETA: 2s - loss: 2.841 - ETA: 2s - loss: 2.843 - ETA: 2s - loss: 2.844 - ETA: 1s - loss: 2.849 - ETA: 1s - loss: 2.846 - ETA: 1s - loss: 2.850 - ETA: 1s - loss: 2.848 - ETA: 1s - loss: 2.852 - ETA: 0s - loss: 2.849 - ETA: 0s - loss: 2.846 - ETA: 0s - loss: 2.848 - ETA: 0s - loss: 2.851 - ETA: 0s - loss: 2.849 - 4s 196us/step - loss: 2.8505\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01319 to 0.01303, saving model to best_model.h5\n",
      "Epoch 12/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.883 - ETA: 3s - loss: 2.835 - ETA: 2s - loss: 2.836 - ETA: 2s - loss: 2.841 - ETA: 2s - loss: 2.844 - ETA: 2s - loss: 2.848 - ETA: 2s - loss: 2.846 - ETA: 1s - loss: 2.843 - ETA: 1s - loss: 2.842 - ETA: 1s - loss: 2.832 - ETA: 1s - loss: 2.827 - ETA: 1s - loss: 2.833 - ETA: 0s - loss: 2.834 - ETA: 0s - loss: 2.831 - ETA: 0s - loss: 2.826 - ETA: 0s - loss: 2.823 - ETA: 0s - loss: 2.822 - ETA: 0s - loss: 2.821 - 4s 192us/step - loss: 2.8219\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01303 to 0.01297, saving model to best_model.h5\n",
      "Epoch 13/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.830 - ETA: 3s - loss: 2.800 - ETA: 2s - loss: 2.797 - ETA: 2s - loss: 2.809 - ETA: 2s - loss: 2.809 - ETA: 2s - loss: 2.813 - ETA: 2s - loss: 2.803 - ETA: 1s - loss: 2.796 - ETA: 1s - loss: 2.796 - ETA: 1s - loss: 2.793 - ETA: 1s - loss: 2.794 - ETA: 1s - loss: 2.794 - ETA: 0s - loss: 2.792 - ETA: 0s - loss: 2.797 - ETA: 0s - loss: 2.798 - ETA: 0s - loss: 2.798 - ETA: 0s - loss: 2.799 - ETA: 0s - loss: 2.802 - 4s 193us/step - loss: 2.8030\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01297 to 0.01292, saving model to best_model.h5\n",
      "Epoch 14/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.766 - ETA: 3s - loss: 2.794 - ETA: 2s - loss: 2.806 - ETA: 2s - loss: 2.799 - ETA: 2s - loss: 2.806 - ETA: 2s - loss: 2.803 - ETA: 2s - loss: 2.800 - ETA: 1s - loss: 2.792 - ETA: 1s - loss: 2.788 - ETA: 1s - loss: 2.788 - ETA: 1s - loss: 2.786 - ETA: 1s - loss: 2.785 - ETA: 0s - loss: 2.783 - ETA: 0s - loss: 2.783 - ETA: 0s - loss: 2.782 - ETA: 0s - loss: 2.781 - ETA: 0s - loss: 2.779 - ETA: 0s - loss: 2.777 - 4s 194us/step - loss: 2.7781\n",
      "\n",
      "Epoch 00014: CRPS_score_val improved from 0.01292 to 0.01288, saving model to best_model.h5\n",
      "Epoch 15/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.744 - ETA: 3s - loss: 2.759 - ETA: 2s - loss: 2.750 - ETA: 2s - loss: 2.772 - ETA: 2s - loss: 2.772 - ETA: 2s - loss: 2.760 - ETA: 2s - loss: 2.768 - ETA: 1s - loss: 2.763 - ETA: 1s - loss: 2.766 - ETA: 1s - loss: 2.765 - ETA: 1s - loss: 2.765 - ETA: 1s - loss: 2.761 - ETA: 1s - loss: 2.759 - ETA: 0s - loss: 2.763 - ETA: 0s - loss: 2.762 - ETA: 0s - loss: 2.761 - ETA: 0s - loss: 2.760 - ETA: 0s - loss: 2.763 - 4s 193us/step - loss: 2.7636\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01288 to 0.01283, saving model to best_model.h5\n",
      "Epoch 16/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.712 - ETA: 3s - loss: 2.758 - ETA: 2s - loss: 2.751 - ETA: 2s - loss: 2.753 - ETA: 2s - loss: 2.750 - ETA: 2s - loss: 2.751 - ETA: 2s - loss: 2.745 - ETA: 1s - loss: 2.753 - ETA: 1s - loss: 2.754 - ETA: 1s - loss: 2.753 - ETA: 1s - loss: 2.750 - ETA: 1s - loss: 2.754 - ETA: 0s - loss: 2.756 - ETA: 0s - loss: 2.756 - ETA: 0s - loss: 2.757 - ETA: 0s - loss: 2.759 - ETA: 0s - loss: 2.751 - ETA: 0s - loss: 2.750 - 4s 193us/step - loss: 2.7503\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01283 to 0.01282, saving model to best_model.h5\n",
      "Epoch 17/100\n",
      "18537/18537 [==============================] - ETA: 4s - loss: 2.738 - ETA: 3s - loss: 2.754 - ETA: 3s - loss: 2.733 - ETA: 2s - loss: 2.739 - ETA: 2s - loss: 2.726 - ETA: 2s - loss: 2.720 - ETA: 2s - loss: 2.726 - ETA: 2s - loss: 2.726 - ETA: 1s - loss: 2.731 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.731 - ETA: 1s - loss: 2.730 - ETA: 0s - loss: 2.729 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.730 - ETA: 0s - loss: 2.735 - 4s 196us/step - loss: 2.7359\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01282 to 0.01280, saving model to best_model.h5\n",
      "Epoch 18/100\n",
      "18537/18537 [==============================] - ETA: 4s - loss: 2.816 - ETA: 3s - loss: 2.761 - ETA: 3s - loss: 2.757 - ETA: 2s - loss: 2.746 - ETA: 2s - loss: 2.737 - ETA: 2s - loss: 2.735 - ETA: 2s - loss: 2.737 - ETA: 2s - loss: 2.754 - ETA: 1s - loss: 2.743 - ETA: 1s - loss: 2.744 - ETA: 1s - loss: 2.740 - ETA: 1s - loss: 2.744 - ETA: 1s - loss: 2.738 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.732 - ETA: 0s - loss: 2.731 - ETA: 0s - loss: 2.731 - ETA: 0s - loss: 2.730 - 4s 195us/step - loss: 2.7304\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01280 to 0.01277, saving model to best_model.h5\n",
      "Epoch 19/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.721 - ETA: 3s - loss: 2.712 - ETA: 2s - loss: 2.715 - ETA: 2s - loss: 2.731 - ETA: 2s - loss: 2.742 - ETA: 2s - loss: 2.730 - ETA: 2s - loss: 2.726 - ETA: 1s - loss: 2.731 - ETA: 1s - loss: 2.734 - ETA: 1s - loss: 2.726 - ETA: 1s - loss: 2.725 - ETA: 1s - loss: 2.727 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.727 - ETA: 0s - loss: 2.724 - ETA: 0s - loss: 2.720 - ETA: 0s - loss: 2.718 - ETA: 0s - loss: 2.719 - 4s 191us/step - loss: 2.7190\n",
      "\n",
      "Epoch 00019: CRPS_score_val improved from 0.01277 to 0.01276, saving model to best_model.h5\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 3s - loss: 2.775 - ETA: 3s - loss: 2.760 - ETA: 2s - loss: 2.735 - ETA: 2s - loss: 2.740 - ETA: 2s - loss: 2.721 - ETA: 2s - loss: 2.725 - ETA: 2s - loss: 2.720 - ETA: 1s - loss: 2.723 - ETA: 1s - loss: 2.715 - ETA: 1s - loss: 2.717 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.718 - ETA: 0s - loss: 2.719 - ETA: 0s - loss: 2.718 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.713 - ETA: 0s - loss: 2.713 - ETA: 0s - loss: 2.711 - 4s 192us/step - loss: 2.7110\n",
      "\n",
      "Epoch 00020: CRPS_score_val improved from 0.01276 to 0.01273, saving model to best_model.h5\n",
      "Epoch 21/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.722 - ETA: 3s - loss: 2.713 - ETA: 2s - loss: 2.736 - ETA: 2s - loss: 2.732 - ETA: 2s - loss: 2.726 - ETA: 2s - loss: 2.728 - ETA: 2s - loss: 2.735 - ETA: 1s - loss: 2.728 - ETA: 1s - loss: 2.723 - ETA: 1s - loss: 2.715 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.710 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.709 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.706 - 4s 192us/step - loss: 2.7061\n",
      "\n",
      "Epoch 00021: CRPS_score_val improved from 0.01273 to 0.01272, saving model to best_model.h5\n",
      "Epoch 22/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.703 - ETA: 3s - loss: 2.667 - ETA: 2s - loss: 2.670 - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.664 - ETA: 2s - loss: 2.668 - ETA: 2s - loss: 2.664 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.674 - ETA: 1s - loss: 2.679 - ETA: 0s - loss: 2.683 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.696 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.692 - 4s 193us/step - loss: 2.6920\n",
      "\n",
      "Epoch 00022: CRPS_score_val improved from 0.01272 to 0.01271, saving model to best_model.h5\n",
      "Epoch 23/100\n",
      "18537/18537 [==============================] - ETA: 4s - loss: 2.715 - ETA: 3s - loss: 2.712 - ETA: 3s - loss: 2.691 - ETA: 2s - loss: 2.693 - ETA: 2s - loss: 2.687 - ETA: 2s - loss: 2.686 - ETA: 2s - loss: 2.693 - ETA: 2s - loss: 2.691 - ETA: 1s - loss: 2.688 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.686 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.693 - ETA: 0s - loss: 2.698 - ETA: 0s - loss: 2.696 - 4s 198us/step - loss: 2.6959\n",
      "\n",
      "Epoch 00023: CRPS_score_val improved from 0.01271 to 0.01269, saving model to best_model.h5\n",
      "Epoch 24/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.680 - ETA: 3s - loss: 2.691 - ETA: 2s - loss: 2.686 - ETA: 2s - loss: 2.679 - ETA: 2s - loss: 2.682 - ETA: 2s - loss: 2.682 - ETA: 2s - loss: 2.685 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.688 - ETA: 1s - loss: 2.685 - ETA: 1s - loss: 2.684 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.681 - 4s 192us/step - loss: 2.6816\n",
      "\n",
      "Epoch 00024: CRPS_score_val improved from 0.01269 to 0.01268, saving model to best_model.h5\n",
      "Epoch 25/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.682 - ETA: 3s - loss: 2.708 - ETA: 3s - loss: 2.695 - ETA: 2s - loss: 2.683 - ETA: 2s - loss: 2.673 - ETA: 2s - loss: 2.669 - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.664 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.678 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.681 - 4s 195us/step - loss: 2.6821\n",
      "\n",
      "Epoch 00025: CRPS_score_val improved from 0.01268 to 0.01268, saving model to best_model.h5\n",
      "Epoch 26/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.688 - ETA: 3s - loss: 2.703 - ETA: 2s - loss: 2.709 - ETA: 2s - loss: 2.703 - ETA: 2s - loss: 2.685 - ETA: 2s - loss: 2.682 - ETA: 2s - loss: 2.685 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.678 - ETA: 1s - loss: 2.674 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.668 - 4s 195us/step - loss: 2.6701\n",
      "\n",
      "Epoch 00026: CRPS_score_val improved from 0.01268 to 0.01266, saving model to best_model.h5\n",
      "Epoch 27/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.649 - ETA: 3s - loss: 2.659 - ETA: 3s - loss: 2.653 - ETA: 2s - loss: 2.659 - ETA: 2s - loss: 2.678 - ETA: 2s - loss: 2.685 - ETA: 2s - loss: 2.677 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.671 - ETA: 1s - loss: 2.674 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.672 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.666 - ETA: 0s - loss: 2.667 - 4s 195us/step - loss: 2.6670\n",
      "\n",
      "Epoch 00027: CRPS_score_val did not improve from 0.01266\n",
      "Epoch 28/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.652 - ETA: 3s - loss: 2.619 - ETA: 3s - loss: 2.656 - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.659 - ETA: 2s - loss: 2.658 - ETA: 2s - loss: 2.657 - ETA: 2s - loss: 2.663 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.661 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.661 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.662 - 4s 197us/step - loss: 2.6623\n",
      "\n",
      "Epoch 00028: CRPS_score_val did not improve from 0.01266\n",
      "Epoch 29/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.598 - ETA: 3s - loss: 2.657 - ETA: 3s - loss: 2.668 - ETA: 2s - loss: 2.650 - ETA: 2s - loss: 2.653 - ETA: 2s - loss: 2.652 - ETA: 2s - loss: 2.648 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.649 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.661 - ETA: 0s - loss: 2.662 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.659 - 4s 194us/step - loss: 2.6590\n",
      "\n",
      "Epoch 00029: CRPS_score_val improved from 0.01266 to 0.01265, saving model to best_model.h5\n",
      "Epoch 30/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.601 - ETA: 3s - loss: 2.620 - ETA: 2s - loss: 2.623 - ETA: 2s - loss: 2.626 - ETA: 2s - loss: 2.623 - ETA: 2s - loss: 2.623 - ETA: 2s - loss: 2.632 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.649 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.653 - 4s 193us/step - loss: 2.6529\n",
      "\n",
      "Epoch 00030: CRPS_score_val improved from 0.01265 to 0.01264, saving model to best_model.h5\n",
      "Epoch 31/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.614 - ETA: 3s - loss: 2.632 - ETA: 2s - loss: 2.634 - ETA: 2s - loss: 2.642 - ETA: 2s - loss: 2.633 - ETA: 2s - loss: 2.631 - ETA: 2s - loss: 2.641 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.650 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.648 - 4s 193us/step - loss: 2.6477\n",
      "\n",
      "Epoch 00031: CRPS_score_val improved from 0.01264 to 0.01264, saving model to best_model.h5\n",
      "Epoch 32/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.697 - ETA: 3s - loss: 2.657 - ETA: 2s - loss: 2.667 - ETA: 2s - loss: 2.653 - ETA: 2s - loss: 2.664 - ETA: 2s - loss: 2.664 - ETA: 2s - loss: 2.655 - ETA: 2s - loss: 2.656 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.649 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.642 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.640 - 4s 198us/step - loss: 2.6401\n",
      "\n",
      "Epoch 00032: CRPS_score_val improved from 0.01264 to 0.01262, saving model to best_model.h5\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 3s - loss: 2.640 - ETA: 3s - loss: 2.623 - ETA: 3s - loss: 2.649 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.636 - ETA: 2s - loss: 2.631 - ETA: 2s - loss: 2.616 - ETA: 2s - loss: 2.617 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.635 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.639 - 4s 195us/step - loss: 2.6416\n",
      "\n",
      "Epoch 00033: CRPS_score_val improved from 0.01262 to 0.01261, saving model to best_model.h5\n",
      "Epoch 34/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.644 - ETA: 3s - loss: 2.598 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.621 - ETA: 2s - loss: 2.621 - ETA: 2s - loss: 2.624 - ETA: 2s - loss: 2.620 - ETA: 2s - loss: 2.624 - ETA: 1s - loss: 2.623 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.624 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.631 - 4s 195us/step - loss: 2.6324\n",
      "\n",
      "Epoch 00034: CRPS_score_val did not improve from 0.01261\n",
      "Epoch 35/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.593 - ETA: 3s - loss: 2.624 - ETA: 3s - loss: 2.614 - ETA: 2s - loss: 2.632 - ETA: 2s - loss: 2.629 - ETA: 2s - loss: 2.623 - ETA: 2s - loss: 2.611 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.638 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.629 - 4s 195us/step - loss: 2.6296\n",
      "\n",
      "Epoch 00035: CRPS_score_val improved from 0.01261 to 0.01261, saving model to best_model.h5\n",
      "Epoch 36/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.661 - ETA: 3s - loss: 2.639 - ETA: 3s - loss: 2.634 - ETA: 2s - loss: 2.636 - ETA: 2s - loss: 2.619 - ETA: 2s - loss: 2.628 - ETA: 2s - loss: 2.630 - ETA: 2s - loss: 2.628 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.637 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.629 - 4s 197us/step - loss: 2.6295\n",
      "\n",
      "Epoch 00036: CRPS_score_val did not improve from 0.01261\n",
      "Epoch 37/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.627 - ETA: 3s - loss: 2.646 - ETA: 2s - loss: 2.646 - ETA: 2s - loss: 2.650 - ETA: 2s - loss: 2.644 - ETA: 2s - loss: 2.637 - ETA: 2s - loss: 2.631 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.629 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.622 - 4s 194us/step - loss: 2.6221\n",
      "\n",
      "Epoch 00037: CRPS_score_val improved from 0.01261 to 0.01261, saving model to best_model.h5\n",
      "Epoch 38/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.630 - ETA: 3s - loss: 2.641 - ETA: 3s - loss: 2.636 - ETA: 2s - loss: 2.641 - ETA: 2s - loss: 2.637 - ETA: 2s - loss: 2.637 - ETA: 2s - loss: 2.636 - ETA: 2s - loss: 2.635 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.621 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.617 - 4s 198us/step - loss: 2.6177\n",
      "\n",
      "Epoch 00038: CRPS_score_val did not improve from 0.01261\n",
      "Epoch 39/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.651 - ETA: 3s - loss: 2.643 - ETA: 3s - loss: 2.628 - ETA: 2s - loss: 2.626 - ETA: 2s - loss: 2.612 - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.622 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.617 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.619 - 4s 197us/step - loss: 2.6193\n",
      "\n",
      "Epoch 00039: CRPS_score_val did not improve from 0.01261\n",
      "Epoch 40/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.641 - ETA: 3s - loss: 2.608 - ETA: 3s - loss: 2.610 - ETA: 2s - loss: 2.620 - ETA: 2s - loss: 2.625 - ETA: 2s - loss: 2.618 - ETA: 2s - loss: 2.621 - ETA: 2s - loss: 2.623 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.607 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.611 - 4s 197us/step - loss: 2.6111\n",
      "\n",
      "Epoch 00040: CRPS_score_val did not improve from 0.01261\n",
      "Epoch 41/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.628 - ETA: 3s - loss: 2.639 - ETA: 3s - loss: 2.654 - ETA: 2s - loss: 2.642 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.637 - ETA: 2s - loss: 2.625 - ETA: 2s - loss: 2.624 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.606 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.605 - 4s 197us/step - loss: 2.6051\n",
      "\n",
      "Epoch 00041: CRPS_score_val did not improve from 0.01261\n",
      "Epoch 42/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.576 - ETA: 3s - loss: 2.604 - ETA: 3s - loss: 2.608 - ETA: 2s - loss: 2.602 - ETA: 2s - loss: 2.606 - ETA: 2s - loss: 2.605 - ETA: 2s - loss: 2.601 - ETA: 2s - loss: 2.606 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.607 - ETA: 0s - loss: 2.607 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.606 - 4s 197us/step - loss: 2.6060\n",
      "\n",
      "Epoch 00042: CRPS_score_val improved from 0.01261 to 0.01260, saving model to best_model.h5\n",
      "Epoch 43/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.657 - ETA: 3s - loss: 2.634 - ETA: 2s - loss: 2.615 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.623 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.609 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.598 - ETA: 1s - loss: 2.591 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.595 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.592 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.598 - 4s 195us/step - loss: 2.5980\n",
      "\n",
      "Epoch 00043: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 44/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.603 - ETA: 3s - loss: 2.604 - ETA: 2s - loss: 2.595 - ETA: 2s - loss: 2.609 - ETA: 2s - loss: 2.604 - ETA: 2s - loss: 2.601 - ETA: 2s - loss: 2.601 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.606 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.602 - 4s 194us/step - loss: 2.6017\n",
      "\n",
      "Epoch 00044: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 45/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.613 - ETA: 3s - loss: 2.584 - ETA: 3s - loss: 2.582 - ETA: 2s - loss: 2.573 - ETA: 2s - loss: 2.577 - ETA: 2s - loss: 2.578 - ETA: 2s - loss: 2.587 - ETA: 2s - loss: 2.591 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.583 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.588 - 4s 196us/step - loss: 2.5889\n",
      "\n",
      "Epoch 00045: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 46/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.577 - ETA: 3s - loss: 2.567 - ETA: 3s - loss: 2.567 - ETA: 2s - loss: 2.572 - ETA: 2s - loss: 2.577 - ETA: 2s - loss: 2.586 - ETA: 2s - loss: 2.591 - ETA: 2s - loss: 2.585 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.588 - ETA: 1s - loss: 2.592 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.589 - 4s 198us/step - loss: 2.5880\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00046: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 47/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.541 - ETA: 3s - loss: 2.575 - ETA: 3s - loss: 2.574 - ETA: 2s - loss: 2.571 - ETA: 2s - loss: 2.585 - ETA: 2s - loss: 2.584 - ETA: 2s - loss: 2.584 - ETA: 2s - loss: 2.578 - ETA: 1s - loss: 2.572 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.573 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.584 - 4s 197us/step - loss: 2.5847\n",
      "\n",
      "Epoch 00047: CRPS_score_val improved from 0.01260 to 0.01260, saving model to best_model.h5\n",
      "Epoch 48/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.647 - ETA: 3s - loss: 2.601 - ETA: 3s - loss: 2.594 - ETA: 2s - loss: 2.586 - ETA: 2s - loss: 2.583 - ETA: 2s - loss: 2.593 - ETA: 2s - loss: 2.590 - ETA: 2s - loss: 2.585 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.571 - ETA: 1s - loss: 2.570 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.573 - 4s 197us/step - loss: 2.5742\n",
      "\n",
      "Epoch 00048: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 49/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.543 - ETA: 3s - loss: 2.537 - ETA: 2s - loss: 2.567 - ETA: 2s - loss: 2.572 - ETA: 2s - loss: 2.571 - ETA: 2s - loss: 2.572 - ETA: 2s - loss: 2.576 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.559 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.569 - ETA: 1s - loss: 2.567 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.571 - 4s 195us/step - loss: 2.5704\n",
      "\n",
      "Epoch 00049: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 50/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.551 - ETA: 3s - loss: 2.546 - ETA: 3s - loss: 2.548 - ETA: 2s - loss: 2.567 - ETA: 2s - loss: 2.559 - ETA: 2s - loss: 2.560 - ETA: 2s - loss: 2.558 - ETA: 2s - loss: 2.561 - ETA: 1s - loss: 2.560 - ETA: 1s - loss: 2.558 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.559 - ETA: 1s - loss: 2.565 - ETA: 0s - loss: 2.562 - ETA: 0s - loss: 2.562 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.563 - 4s 195us/step - loss: 2.5639\n",
      "\n",
      "Epoch 00050: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 51/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.638 - ETA: 3s - loss: 2.606 - ETA: 3s - loss: 2.585 - ETA: 2s - loss: 2.570 - ETA: 2s - loss: 2.560 - ETA: 2s - loss: 2.557 - ETA: 2s - loss: 2.557 - ETA: 2s - loss: 2.560 - ETA: 1s - loss: 2.568 - ETA: 1s - loss: 2.566 - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.566 - ETA: 1s - loss: 2.564 - ETA: 0s - loss: 2.562 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.562 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.568 - 4s 198us/step - loss: 2.5698\n",
      "\n",
      "Epoch 00051: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 52/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.587 - ETA: 3s - loss: 2.552 - ETA: 3s - loss: 2.544 - ETA: 2s - loss: 2.546 - ETA: 2s - loss: 2.555 - ETA: 2s - loss: 2.557 - ETA: 2s - loss: 2.557 - ETA: 2s - loss: 2.554 - ETA: 1s - loss: 2.559 - ETA: 1s - loss: 2.559 - ETA: 1s - loss: 2.562 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.565 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.566 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.560 - 4s 195us/step - loss: 2.5596\n",
      "\n",
      "Epoch 00052: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 53/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.515 - ETA: 3s - loss: 2.565 - ETA: 2s - loss: 2.539 - ETA: 2s - loss: 2.548 - ETA: 2s - loss: 2.556 - ETA: 2s - loss: 2.550 - ETA: 2s - loss: 2.558 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.555 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.554 - ETA: 1s - loss: 2.556 - ETA: 1s - loss: 2.558 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.559 - ETA: 0s - loss: 2.559 - ETA: 0s - loss: 2.561 - ETA: 0s - loss: 2.559 - 4s 195us/step - loss: 2.5597\n",
      "\n",
      "Epoch 00053: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 54/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.508 - ETA: 3s - loss: 2.535 - ETA: 3s - loss: 2.550 - ETA: 2s - loss: 2.542 - ETA: 2s - loss: 2.540 - ETA: 2s - loss: 2.549 - ETA: 2s - loss: 2.537 - ETA: 2s - loss: 2.535 - ETA: 1s - loss: 2.534 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.542 - ETA: 1s - loss: 2.539 - ETA: 1s - loss: 2.537 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.548 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.550 - 4s 197us/step - loss: 2.5511\n",
      "\n",
      "Epoch 00054: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 55/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.499 - ETA: 3s - loss: 2.521 - ETA: 3s - loss: 2.522 - ETA: 2s - loss: 2.532 - ETA: 2s - loss: 2.532 - ETA: 2s - loss: 2.543 - ETA: 2s - loss: 2.545 - ETA: 2s - loss: 2.541 - ETA: 1s - loss: 2.546 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.548 - ETA: 1s - loss: 2.546 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.555 - 4s 195us/step - loss: 2.5570\n",
      "\n",
      "Epoch 00055: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 56/100\n",
      "18537/18537 [==============================] - ETA: 4s - loss: 2.596 - ETA: 3s - loss: 2.585 - ETA: 3s - loss: 2.560 - ETA: 2s - loss: 2.567 - ETA: 2s - loss: 2.566 - ETA: 2s - loss: 2.560 - ETA: 2s - loss: 2.562 - ETA: 2s - loss: 2.557 - ETA: 1s - loss: 2.555 - ETA: 1s - loss: 2.554 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.550 - ETA: 1s - loss: 2.548 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.548 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.544 - 4s 196us/step - loss: 2.5456\n",
      "\n",
      "Epoch 00056: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 57/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.508 - ETA: 3s - loss: 2.507 - ETA: 3s - loss: 2.517 - ETA: 2s - loss: 2.525 - ETA: 2s - loss: 2.531 - ETA: 2s - loss: 2.536 - ETA: 2s - loss: 2.536 - ETA: 2s - loss: 2.536 - ETA: 1s - loss: 2.536 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.546 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.538 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.538 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.536 - 4s 197us/step - loss: 2.5362\n",
      "\n",
      "Epoch 00057: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 58/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.497 - ETA: 3s - loss: 2.509 - ETA: 3s - loss: 2.509 - ETA: 2s - loss: 2.513 - ETA: 2s - loss: 2.514 - ETA: 2s - loss: 2.506 - ETA: 2s - loss: 2.512 - ETA: 2s - loss: 2.517 - ETA: 1s - loss: 2.531 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.536 - ETA: 1s - loss: 2.532 - ETA: 1s - loss: 2.528 - ETA: 0s - loss: 2.530 - ETA: 0s - loss: 2.534 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.533 - ETA: 0s - loss: 2.537 - 4s 195us/step - loss: 2.5369\n",
      "\n",
      "Epoch 00058: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 59/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.567 - ETA: 3s - loss: 2.528 - ETA: 3s - loss: 2.526 - ETA: 2s - loss: 2.536 - ETA: 2s - loss: 2.541 - ETA: 2s - loss: 2.535 - ETA: 2s - loss: 2.543 - ETA: 2s - loss: 2.545 - ETA: 1s - loss: 2.550 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.537 - ETA: 0s - loss: 2.533 - ETA: 0s - loss: 2.533 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.535 - 4s 195us/step - loss: 2.5358\n",
      "\n",
      "Epoch 00059: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 60/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.492 - ETA: 3s - loss: 2.516 - ETA: 3s - loss: 2.500 - ETA: 2s - loss: 2.505 - ETA: 2s - loss: 2.501 - ETA: 2s - loss: 2.507 - ETA: 2s - loss: 2.505 - ETA: 2s - loss: 2.505 - ETA: 1s - loss: 2.513 - ETA: 1s - loss: 2.518 - ETA: 1s - loss: 2.525 - ETA: 1s - loss: 2.526 - ETA: 1s - loss: 2.530 - ETA: 0s - loss: 2.527 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.532 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.531 - 4s 197us/step - loss: 2.5314\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00060: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 61/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.482 - ETA: 3s - loss: 2.480 - ETA: 3s - loss: 2.487 - ETA: 2s - loss: 2.495 - ETA: 2s - loss: 2.493 - ETA: 2s - loss: 2.497 - ETA: 2s - loss: 2.503 - ETA: 1s - loss: 2.504 - ETA: 1s - loss: 2.505 - ETA: 1s - loss: 2.511 - ETA: 1s - loss: 2.511 - ETA: 1s - loss: 2.506 - ETA: 1s - loss: 2.509 - ETA: 0s - loss: 2.516 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.520 - ETA: 0s - loss: 2.521 - ETA: 0s - loss: 2.521 - 4s 194us/step - loss: 2.5207\n",
      "\n",
      "Epoch 00061: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 62/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.519 - ETA: 3s - loss: 2.534 - ETA: 3s - loss: 2.531 - ETA: 2s - loss: 2.523 - ETA: 2s - loss: 2.513 - ETA: 2s - loss: 2.506 - ETA: 2s - loss: 2.498 - ETA: 2s - loss: 2.503 - ETA: 1s - loss: 2.503 - ETA: 1s - loss: 2.508 - ETA: 1s - loss: 2.513 - ETA: 1s - loss: 2.508 - ETA: 1s - loss: 2.509 - ETA: 0s - loss: 2.512 - ETA: 0s - loss: 2.519 - ETA: 0s - loss: 2.520 - ETA: 0s - loss: 2.517 - ETA: 0s - loss: 2.516 - 4s 195us/step - loss: 2.5160\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00062: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 00062: early stopping\n",
      "the 3 fold crps is 0.012602\n",
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/100\n",
      "18537/18537 [==============================] - ETA: 16s - loss: 5.80 - ETA: 9s - loss: 5.7981 - ETA: 6s - loss: 5.790 - ETA: 5s - loss: 5.777 - ETA: 4s - loss: 5.766 - ETA: 3s - loss: 5.760 - ETA: 3s - loss: 5.743 - ETA: 2s - loss: 5.732 - ETA: 2s - loss: 5.710 - ETA: 1s - loss: 5.697 - ETA: 1s - loss: 5.682 - ETA: 1s - loss: 5.668 - ETA: 1s - loss: 5.657 - ETA: 0s - loss: 5.641 - ETA: 0s - loss: 5.626 - ETA: 0s - loss: 5.614 - ETA: 0s - loss: 5.598 - ETA: 0s - loss: 5.586 - 4s 198us/step - loss: 5.5853\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08303, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 5.269 - ETA: 2s - loss: 5.231 - ETA: 2s - loss: 5.209 - ETA: 2s - loss: 5.194 - ETA: 2s - loss: 5.184 - ETA: 1s - loss: 5.168 - ETA: 1s - loss: 5.159 - ETA: 1s - loss: 5.150 - ETA: 1s - loss: 5.137 - ETA: 1s - loss: 5.131 - ETA: 1s - loss: 5.122 - ETA: 0s - loss: 5.110 - ETA: 0s - loss: 5.108 - ETA: 0s - loss: 5.095 - ETA: 0s - loss: 5.088 - ETA: 0s - loss: 5.074 - ETA: 0s - loss: 5.058 - ETA: 0s - loss: 5.054 - 3s 151us/step - loss: 5.0539\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08303 to 0.07722, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 4.852 - ETA: 2s - loss: 4.852 - ETA: 2s - loss: 4.819 - ETA: 2s - loss: 4.803 - ETA: 2s - loss: 4.786 - ETA: 1s - loss: 4.771 - ETA: 1s - loss: 4.748 - ETA: 1s - loss: 4.739 - ETA: 1s - loss: 4.731 - ETA: 1s - loss: 4.725 - ETA: 1s - loss: 4.715 - ETA: 0s - loss: 4.701 - ETA: 0s - loss: 4.687 - ETA: 0s - loss: 4.667 - ETA: 0s - loss: 4.655 - ETA: 0s - loss: 4.649 - ETA: 0s - loss: 4.644 - ETA: 0s - loss: 4.634 - 3s 151us/step - loss: 4.6328\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.07722 to 0.06581, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 4.248 - ETA: 2s - loss: 4.323 - ETA: 2s - loss: 4.355 - ETA: 2s - loss: 4.342 - ETA: 1s - loss: 4.335 - ETA: 1s - loss: 4.316 - ETA: 1s - loss: 4.318 - ETA: 1s - loss: 4.286 - ETA: 1s - loss: 4.272 - ETA: 1s - loss: 4.272 - ETA: 1s - loss: 4.264 - ETA: 0s - loss: 4.259 - ETA: 0s - loss: 4.253 - ETA: 0s - loss: 4.249 - ETA: 0s - loss: 4.244 - ETA: 0s - loss: 4.237 - ETA: 0s - loss: 4.227 - ETA: 0s - loss: 4.216 - 3s 151us/step - loss: 4.2151\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.06581 to 0.04620, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 4.013 - ETA: 2s - loss: 3.971 - ETA: 2s - loss: 3.968 - ETA: 2s - loss: 3.955 - ETA: 1s - loss: 3.942 - ETA: 1s - loss: 3.949 - ETA: 1s - loss: 3.944 - ETA: 1s - loss: 3.935 - ETA: 1s - loss: 3.927 - ETA: 1s - loss: 3.929 - ETA: 1s - loss: 3.925 - ETA: 0s - loss: 3.927 - ETA: 0s - loss: 3.921 - ETA: 0s - loss: 3.910 - ETA: 0s - loss: 3.898 - ETA: 0s - loss: 3.891 - ETA: 0s - loss: 3.883 - ETA: 0s - loss: 3.872 - 3s 150us/step - loss: 3.8719\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.04620 to 0.02821, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.586 - ETA: 2s - loss: 3.625 - ETA: 2s - loss: 3.669 - ETA: 2s - loss: 3.636 - ETA: 2s - loss: 3.640 - ETA: 1s - loss: 3.649 - ETA: 1s - loss: 3.654 - ETA: 1s - loss: 3.659 - ETA: 1s - loss: 3.647 - ETA: 1s - loss: 3.626 - ETA: 1s - loss: 3.622 - ETA: 0s - loss: 3.607 - ETA: 0s - loss: 3.597 - ETA: 0s - loss: 3.596 - ETA: 0s - loss: 3.583 - ETA: 0s - loss: 3.572 - ETA: 0s - loss: 3.571 - ETA: 0s - loss: 3.563 - 3s 151us/step - loss: 3.5617\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.02821 to 0.01901, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.359 - ETA: 2s - loss: 3.367 - ETA: 2s - loss: 3.354 - ETA: 2s - loss: 3.331 - ETA: 2s - loss: 3.343 - ETA: 1s - loss: 3.330 - ETA: 1s - loss: 3.329 - ETA: 1s - loss: 3.334 - ETA: 1s - loss: 3.339 - ETA: 1s - loss: 3.330 - ETA: 1s - loss: 3.337 - ETA: 0s - loss: 3.329 - ETA: 0s - loss: 3.318 - ETA: 0s - loss: 3.311 - ETA: 0s - loss: 3.309 - ETA: 0s - loss: 3.300 - ETA: 0s - loss: 3.301 - ETA: 0s - loss: 3.294 - 3s 151us/step - loss: 3.2941\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01901 to 0.01494, saving model to best_model.h5\n",
      "Epoch 8/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.175 - ETA: 2s - loss: 3.179 - ETA: 2s - loss: 3.147 - ETA: 2s - loss: 3.172 - ETA: 1s - loss: 3.155 - ETA: 1s - loss: 3.151 - ETA: 1s - loss: 3.154 - ETA: 1s - loss: 3.143 - ETA: 1s - loss: 3.139 - ETA: 1s - loss: 3.136 - ETA: 1s - loss: 3.134 - ETA: 0s - loss: 3.134 - ETA: 0s - loss: 3.128 - ETA: 0s - loss: 3.123 - ETA: 0s - loss: 3.119 - ETA: 0s - loss: 3.120 - ETA: 0s - loss: 3.110 - ETA: 0s - loss: 3.108 - 3s 150us/step - loss: 3.1082\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01494 to 0.01372, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.021 - ETA: 2s - loss: 3.016 - ETA: 2s - loss: 2.991 - ETA: 2s - loss: 2.997 - ETA: 2s - loss: 3.005 - ETA: 1s - loss: 3.002 - ETA: 1s - loss: 3.003 - ETA: 1s - loss: 3.010 - ETA: 1s - loss: 3.001 - ETA: 1s - loss: 2.998 - ETA: 1s - loss: 2.995 - ETA: 0s - loss: 2.991 - ETA: 0s - loss: 2.996 - ETA: 0s - loss: 2.995 - ETA: 0s - loss: 2.995 - ETA: 0s - loss: 2.988 - ETA: 0s - loss: 2.987 - ETA: 0s - loss: 2.985 - 3s 151us/step - loss: 2.9853\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01372 to 0.01326, saving model to best_model.h5\n",
      "Epoch 10/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.954 - ETA: 2s - loss: 2.951 - ETA: 2s - loss: 2.953 - ETA: 2s - loss: 2.930 - ETA: 2s - loss: 2.927 - ETA: 1s - loss: 2.940 - ETA: 1s - loss: 2.933 - ETA: 1s - loss: 2.935 - ETA: 1s - loss: 2.940 - ETA: 1s - loss: 2.942 - ETA: 1s - loss: 2.942 - ETA: 0s - loss: 2.934 - ETA: 0s - loss: 2.929 - ETA: 0s - loss: 2.926 - ETA: 0s - loss: 2.922 - ETA: 0s - loss: 2.921 - ETA: 0s - loss: 2.924 - ETA: 0s - loss: 2.919 - 3s 154us/step - loss: 2.9176\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01326 to 0.01309, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.825 - ETA: 2s - loss: 2.850 - ETA: 2s - loss: 2.854 - ETA: 2s - loss: 2.861 - ETA: 1s - loss: 2.852 - ETA: 1s - loss: 2.853 - ETA: 1s - loss: 2.854 - ETA: 1s - loss: 2.861 - ETA: 1s - loss: 2.862 - ETA: 1s - loss: 2.857 - ETA: 1s - loss: 2.855 - ETA: 0s - loss: 2.851 - ETA: 0s - loss: 2.860 - ETA: 0s - loss: 2.856 - ETA: 0s - loss: 2.850 - ETA: 0s - loss: 2.853 - ETA: 0s - loss: 2.853 - ETA: 0s - loss: 2.855 - 3s 149us/step - loss: 2.8553\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01309 to 0.01299, saving model to best_model.h5\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 2.814 - ETA: 2s - loss: 2.823 - ETA: 2s - loss: 2.805 - ETA: 2s - loss: 2.817 - ETA: 1s - loss: 2.838 - ETA: 1s - loss: 2.828 - ETA: 1s - loss: 2.818 - ETA: 1s - loss: 2.833 - ETA: 1s - loss: 2.829 - ETA: 1s - loss: 2.826 - ETA: 1s - loss: 2.820 - ETA: 0s - loss: 2.824 - ETA: 0s - loss: 2.826 - ETA: 0s - loss: 2.828 - ETA: 0s - loss: 2.828 - ETA: 0s - loss: 2.824 - ETA: 0s - loss: 2.821 - ETA: 0s - loss: 2.822 - 3s 150us/step - loss: 2.8216\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01299 to 0.01290, saving model to best_model.h5\n",
      "Epoch 13/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.792 - ETA: 2s - loss: 2.806 - ETA: 2s - loss: 2.799 - ETA: 2s - loss: 2.814 - ETA: 1s - loss: 2.806 - ETA: 1s - loss: 2.803 - ETA: 1s - loss: 2.801 - ETA: 1s - loss: 2.796 - ETA: 1s - loss: 2.799 - ETA: 1s - loss: 2.799 - ETA: 1s - loss: 2.801 - ETA: 0s - loss: 2.798 - ETA: 0s - loss: 2.802 - ETA: 0s - loss: 2.798 - ETA: 0s - loss: 2.800 - ETA: 0s - loss: 2.802 - ETA: 0s - loss: 2.801 - ETA: 0s - loss: 2.799 - 3s 149us/step - loss: 2.7999\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01290 to 0.01287, saving model to best_model.h5\n",
      "Epoch 14/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.791 - ETA: 2s - loss: 2.756 - ETA: 2s - loss: 2.749 - ETA: 2s - loss: 2.752 - ETA: 2s - loss: 2.760 - ETA: 1s - loss: 2.768 - ETA: 1s - loss: 2.784 - ETA: 1s - loss: 2.787 - ETA: 1s - loss: 2.780 - ETA: 1s - loss: 2.782 - ETA: 1s - loss: 2.778 - ETA: 0s - loss: 2.777 - ETA: 0s - loss: 2.782 - ETA: 0s - loss: 2.776 - ETA: 0s - loss: 2.778 - ETA: 0s - loss: 2.778 - ETA: 0s - loss: 2.773 - ETA: 0s - loss: 2.772 - 3s 152us/step - loss: 2.7728\n",
      "\n",
      "Epoch 00014: CRPS_score_val improved from 0.01287 to 0.01285, saving model to best_model.h5\n",
      "Epoch 15/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.733 - ETA: 2s - loss: 2.756 - ETA: 2s - loss: 2.761 - ETA: 2s - loss: 2.755 - ETA: 1s - loss: 2.752 - ETA: 1s - loss: 2.756 - ETA: 1s - loss: 2.754 - ETA: 1s - loss: 2.755 - ETA: 1s - loss: 2.753 - ETA: 1s - loss: 2.760 - ETA: 1s - loss: 2.753 - ETA: 0s - loss: 2.754 - ETA: 0s - loss: 2.756 - ETA: 0s - loss: 2.756 - ETA: 0s - loss: 2.756 - ETA: 0s - loss: 2.755 - ETA: 0s - loss: 2.755 - ETA: 0s - loss: 2.756 - 3s 148us/step - loss: 2.7569\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01285 to 0.01281, saving model to best_model.h5\n",
      "Epoch 16/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.802 - ETA: 2s - loss: 2.785 - ETA: 2s - loss: 2.773 - ETA: 2s - loss: 2.767 - ETA: 1s - loss: 2.747 - ETA: 1s - loss: 2.752 - ETA: 1s - loss: 2.753 - ETA: 1s - loss: 2.749 - ETA: 1s - loss: 2.751 - ETA: 1s - loss: 2.745 - ETA: 1s - loss: 2.742 - ETA: 0s - loss: 2.746 - ETA: 0s - loss: 2.747 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.743 - ETA: 0s - loss: 2.743 - ETA: 0s - loss: 2.745 - ETA: 0s - loss: 2.743 - 3s 149us/step - loss: 2.7430\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01281 to 0.01279, saving model to best_model.h5\n",
      "Epoch 17/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.755 - ETA: 2s - loss: 2.740 - ETA: 2s - loss: 2.719 - ETA: 2s - loss: 2.713 - ETA: 2s - loss: 2.719 - ETA: 1s - loss: 2.715 - ETA: 1s - loss: 2.719 - ETA: 1s - loss: 2.727 - ETA: 1s - loss: 2.729 - ETA: 1s - loss: 2.734 - ETA: 1s - loss: 2.736 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.741 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.735 - 3s 150us/step - loss: 2.7368\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01279 to 0.01275, saving model to best_model.h5\n",
      "Epoch 18/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.633 - ETA: 2s - loss: 2.696 - ETA: 2s - loss: 2.731 - ETA: 2s - loss: 2.730 - ETA: 2s - loss: 2.721 - ETA: 1s - loss: 2.728 - ETA: 1s - loss: 2.740 - ETA: 1s - loss: 2.738 - ETA: 1s - loss: 2.732 - ETA: 1s - loss: 2.730 - ETA: 1s - loss: 2.726 - ETA: 0s - loss: 2.724 - ETA: 0s - loss: 2.724 - ETA: 0s - loss: 2.722 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.724 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.724 - 3s 153us/step - loss: 2.7249\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01275 to 0.01274, saving model to best_model.h5\n",
      "Epoch 19/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.704 - ETA: 2s - loss: 2.678 - ETA: 2s - loss: 2.677 - ETA: 2s - loss: 2.692 - ETA: 2s - loss: 2.695 - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.704 - ETA: 1s - loss: 2.704 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.704 - ETA: 0s - loss: 2.704 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.708 - ETA: 0s - loss: 2.708 - 3s 151us/step - loss: 2.7090\n",
      "\n",
      "Epoch 00019: CRPS_score_val improved from 0.01274 to 0.01274, saving model to best_model.h5\n",
      "Epoch 20/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.660 - ETA: 2s - loss: 2.672 - ETA: 2s - loss: 2.696 - ETA: 2s - loss: 2.684 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.707 - ETA: 1s - loss: 2.714 - ETA: 1s - loss: 2.710 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.711 - ETA: 1s - loss: 2.709 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.704 - ETA: 0s - loss: 2.705 - 3s 149us/step - loss: 2.7059\n",
      "\n",
      "Epoch 00020: CRPS_score_val improved from 0.01274 to 0.01270, saving model to best_model.h5\n",
      "Epoch 21/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.675 - ETA: 2s - loss: 2.657 - ETA: 2s - loss: 2.693 - ETA: 2s - loss: 2.696 - ETA: 2s - loss: 2.691 - ETA: 1s - loss: 2.693 - ETA: 1s - loss: 2.691 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.692 - ETA: 1s - loss: 2.694 - ETA: 1s - loss: 2.697 - ETA: 0s - loss: 2.697 - ETA: 0s - loss: 2.704 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.702 - ETA: 0s - loss: 2.706 - ETA: 0s - loss: 2.702 - ETA: 0s - loss: 2.698 - 3s 151us/step - loss: 2.6986\n",
      "\n",
      "Epoch 00021: CRPS_score_val improved from 0.01270 to 0.01269, saving model to best_model.h5\n",
      "Epoch 22/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.694 - ETA: 2s - loss: 2.708 - ETA: 2s - loss: 2.709 - ETA: 2s - loss: 2.704 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.703 - ETA: 1s - loss: 2.704 - ETA: 1s - loss: 2.697 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.691 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.690 - ETA: 0s - loss: 2.692 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.693 - ETA: 0s - loss: 2.691 - 3s 150us/step - loss: 2.6923\n",
      "\n",
      "Epoch 00022: CRPS_score_val improved from 0.01269 to 0.01268, saving model to best_model.h5\n",
      "Epoch 23/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.690 - ETA: 2s - loss: 2.706 - ETA: 2s - loss: 2.702 - ETA: 2s - loss: 2.689 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.686 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.683 - 3s 151us/step - loss: 2.6832\n",
      "\n",
      "Epoch 00023: CRPS_score_val improved from 0.01268 to 0.01266, saving model to best_model.h5\n",
      "Epoch 24/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.703 - ETA: 2s - loss: 2.717 - ETA: 2s - loss: 2.687 - ETA: 2s - loss: 2.692 - ETA: 2s - loss: 2.677 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.681 - ETA: 1s - loss: 2.674 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.679 - 3s 151us/step - loss: 2.6785\n",
      "\n",
      "Epoch 00024: CRPS_score_val improved from 0.01266 to 0.01264, saving model to best_model.h5\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 2.695 - ETA: 2s - loss: 2.695 - ETA: 2s - loss: 2.703 - ETA: 2s - loss: 2.705 - ETA: 2s - loss: 2.691 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.677 - ETA: 1s - loss: 2.679 - ETA: 1s - loss: 2.678 - ETA: 1s - loss: 2.676 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.671 - 3s 152us/step - loss: 2.6716\n",
      "\n",
      "Epoch 00025: CRPS_score_val improved from 0.01264 to 0.01263, saving model to best_model.h5\n",
      "Epoch 26/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.675 - ETA: 2s - loss: 2.656 - ETA: 2s - loss: 2.672 - ETA: 2s - loss: 2.659 - ETA: 2s - loss: 2.660 - ETA: 1s - loss: 2.671 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.665 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.674 - ETA: 1s - loss: 2.675 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.668 - 3s 151us/step - loss: 2.6689\n",
      "\n",
      "Epoch 00026: CRPS_score_val did not improve from 0.01263\n",
      "Epoch 27/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.694 - ETA: 2s - loss: 2.692 - ETA: 2s - loss: 2.693 - ETA: 2s - loss: 2.688 - ETA: 2s - loss: 2.685 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.667 - ETA: 1s - loss: 2.664 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.668 - 3s 150us/step - loss: 2.6680\n",
      "\n",
      "Epoch 00027: CRPS_score_val improved from 0.01263 to 0.01261, saving model to best_model.h5\n",
      "Epoch 28/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.629 - ETA: 2s - loss: 2.641 - ETA: 2s - loss: 2.664 - ETA: 2s - loss: 2.667 - ETA: 2s - loss: 2.657 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.653 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.658 - 3s 150us/step - loss: 2.6580\n",
      "\n",
      "Epoch 00028: CRPS_score_val improved from 0.01261 to 0.01260, saving model to best_model.h5\n",
      "Epoch 29/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.634 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.650 - ETA: 2s - loss: 2.643 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.646 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.654 - 3s 149us/step - loss: 2.6552\n",
      "\n",
      "Epoch 00029: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 30/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.665 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.650 - ETA: 2s - loss: 2.638 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.640 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.650 - 3s 150us/step - loss: 2.6510\n",
      "\n",
      "Epoch 00030: CRPS_score_val did not improve from 0.01260\n",
      "Epoch 31/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.619 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.649 - ETA: 2s - loss: 2.653 - ETA: 2s - loss: 2.646 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.649 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.644 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.643 - 3s 150us/step - loss: 2.6436\n",
      "\n",
      "Epoch 00031: CRPS_score_val improved from 0.01260 to 0.01259, saving model to best_model.h5\n",
      "Epoch 32/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.636 - ETA: 2s - loss: 2.634 - ETA: 2s - loss: 2.634 - ETA: 1s - loss: 2.647 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.649 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.643 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.641 - 3s 150us/step - loss: 2.6406\n",
      "\n",
      "Epoch 00032: CRPS_score_val improved from 0.01259 to 0.01259, saving model to best_model.h5\n",
      "Epoch 33/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.620 - ETA: 2s - loss: 2.644 - ETA: 2s - loss: 2.620 - ETA: 2s - loss: 2.615 - ETA: 2s - loss: 2.624 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.632 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.637 - 3s 150us/step - loss: 2.6369\n",
      "\n",
      "Epoch 00033: CRPS_score_val improved from 0.01259 to 0.01258, saving model to best_model.h5\n",
      "Epoch 34/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.599 - ETA: 2s - loss: 2.643 - ETA: 2s - loss: 2.638 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.638 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.623 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.629 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.628 - 3s 150us/step - loss: 2.6287\n",
      "\n",
      "Epoch 00034: CRPS_score_val did not improve from 0.01258\n",
      "Epoch 35/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.609 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.622 - ETA: 2s - loss: 2.627 - ETA: 2s - loss: 2.624 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.621 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.626 - 3s 151us/step - loss: 2.6267\n",
      "\n",
      "Epoch 00035: CRPS_score_val improved from 0.01258 to 0.01257, saving model to best_model.h5\n",
      "Epoch 36/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.596 - ETA: 2s - loss: 2.601 - ETA: 2s - loss: 2.592 - ETA: 2s - loss: 2.606 - ETA: 1s - loss: 2.607 - ETA: 1s - loss: 2.609 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.619 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.624 - 3s 149us/step - loss: 2.6256\n",
      "\n",
      "Epoch 00036: CRPS_score_val did not improve from 0.01257\n",
      "Epoch 37/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.594 - ETA: 2s - loss: 2.621 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.643 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.624 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.624 - 3s 150us/step - loss: 2.6238\n",
      "\n",
      "Epoch 00037: CRPS_score_val improved from 0.01257 to 0.01256, saving model to best_model.h5\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 2.553 - ETA: 2s - loss: 2.567 - ETA: 2s - loss: 2.591 - ETA: 2s - loss: 2.590 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.604 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.612 - ETA: 0s - loss: 2.608 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.615 - 3s 151us/step - loss: 2.6160\n",
      "\n",
      "Epoch 00038: CRPS_score_val improved from 0.01256 to 0.01256, saving model to best_model.h5\n",
      "Epoch 39/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.582 - ETA: 2s - loss: 2.589 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.606 - ETA: 2s - loss: 2.607 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.597 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.603 - 3s 150us/step - loss: 2.6031\n",
      "\n",
      "Epoch 00039: CRPS_score_val improved from 0.01256 to 0.01255, saving model to best_model.h5\n",
      "Epoch 40/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.524 - ETA: 2s - loss: 2.572 - ETA: 2s - loss: 2.584 - ETA: 2s - loss: 2.572 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.572 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.599 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.602 - 3s 150us/step - loss: 2.6035\n",
      "\n",
      "Epoch 00040: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 41/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.606 - ETA: 2s - loss: 2.582 - ETA: 2s - loss: 2.569 - ETA: 2s - loss: 2.575 - ETA: 2s - loss: 2.584 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.587 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.599 - 3s 152us/step - loss: 2.6010\n",
      "\n",
      "Epoch 00041: CRPS_score_val improved from 0.01255 to 0.01255, saving model to best_model.h5\n",
      "Epoch 42/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.550 - ETA: 2s - loss: 2.574 - ETA: 2s - loss: 2.587 - ETA: 2s - loss: 2.581 - ETA: 2s - loss: 2.580 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.585 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.593 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.593 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.594 - 3s 151us/step - loss: 2.5946\n",
      "\n",
      "Epoch 00042: CRPS_score_val improved from 0.01255 to 0.01255, saving model to best_model.h5\n",
      "Epoch 43/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.564 - ETA: 2s - loss: 2.586 - ETA: 2s - loss: 2.618 - ETA: 2s - loss: 2.620 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.609 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.597 - ETA: 1s - loss: 2.601 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.592 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.591 - 3s 150us/step - loss: 2.5918\n",
      "\n",
      "Epoch 00043: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 44/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.588 - ETA: 2s - loss: 2.598 - ETA: 2s - loss: 2.601 - ETA: 2s - loss: 2.602 - ETA: 2s - loss: 2.608 - ETA: 1s - loss: 2.600 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.590 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.587 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.586 - ETA: 0s - loss: 2.590 - 3s 150us/step - loss: 2.5901\n",
      "\n",
      "Epoch 00044: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 45/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.579 - ETA: 2s - loss: 2.573 - ETA: 2s - loss: 2.585 - ETA: 2s - loss: 2.581 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.587 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.589 - ETA: 0s - loss: 2.588 - ETA: 0s - loss: 2.585 - 3s 150us/step - loss: 2.5851\n",
      "\n",
      "Epoch 00045: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 46/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.598 - ETA: 2s - loss: 2.588 - ETA: 2s - loss: 2.579 - ETA: 2s - loss: 2.582 - ETA: 2s - loss: 2.585 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.578 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.579 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.578 - 3s 150us/step - loss: 2.5779\n",
      "\n",
      "Epoch 00046: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 47/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.579 - ETA: 2s - loss: 2.564 - ETA: 2s - loss: 2.574 - ETA: 2s - loss: 2.586 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.575 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.567 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.576 - ETA: 0s - loss: 2.577 - 3s 149us/step - loss: 2.5775\n",
      "\n",
      "Epoch 00047: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 48/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.554 - ETA: 2s - loss: 2.565 - ETA: 2s - loss: 2.568 - ETA: 2s - loss: 2.565 - ETA: 2s - loss: 2.562 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.562 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.567 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.572 - 3s 151us/step - loss: 2.5723\n",
      "\n",
      "Epoch 00048: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 49/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.573 - ETA: 2s - loss: 2.557 - ETA: 2s - loss: 2.535 - ETA: 2s - loss: 2.555 - ETA: 1s - loss: 2.548 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.556 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.558 - ETA: 1s - loss: 2.560 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.564 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.565 - 3s 151us/step - loss: 2.5652\n",
      "\n",
      "Epoch 00049: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 50/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.547 - ETA: 2s - loss: 2.539 - ETA: 2s - loss: 2.536 - ETA: 2s - loss: 2.528 - ETA: 2s - loss: 2.525 - ETA: 1s - loss: 2.526 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.559 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.566 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.561 - ETA: 0s - loss: 2.562 - 3s 150us/step - loss: 2.5627\n",
      "\n",
      "Epoch 00050: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 51/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.538 - ETA: 2s - loss: 2.500 - ETA: 2s - loss: 2.517 - ETA: 2s - loss: 2.535 - ETA: 1s - loss: 2.545 - ETA: 1s - loss: 2.538 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.539 - ETA: 1s - loss: 2.548 - ETA: 1s - loss: 2.545 - ETA: 1s - loss: 2.545 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.557 - 3s 151us/step - loss: 2.5580\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00051: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 52/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.555 - ETA: 2s - loss: 2.564 - ETA: 2s - loss: 2.575 - ETA: 2s - loss: 2.580 - ETA: 2s - loss: 2.569 - ETA: 1s - loss: 2.559 - ETA: 1s - loss: 2.553 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.556 - ETA: 1s - loss: 2.559 - ETA: 1s - loss: 2.560 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.562 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.553 - 3s 152us/step - loss: 2.5531\n",
      "\n",
      "Epoch 00052: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 53/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.603 - ETA: 2s - loss: 2.566 - ETA: 2s - loss: 2.567 - ETA: 2s - loss: 2.575 - ETA: 2s - loss: 2.563 - ETA: 1s - loss: 2.567 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.565 - ETA: 1s - loss: 2.563 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.552 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.554 - 3s 151us/step - loss: 2.5542\n",
      "\n",
      "Epoch 00053: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 54/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.541 - ETA: 2s - loss: 2.534 - ETA: 2s - loss: 2.546 - ETA: 2s - loss: 2.546 - ETA: 2s - loss: 2.546 - ETA: 1s - loss: 2.548 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.541 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.541 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.543 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.539 - ETA: 0s - loss: 2.541 - 3s 153us/step - loss: 2.5424\n",
      "\n",
      "Epoch 00054: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 55/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.528 - ETA: 2s - loss: 2.518 - ETA: 2s - loss: 2.517 - ETA: 2s - loss: 2.532 - ETA: 1s - loss: 2.533 - ETA: 1s - loss: 2.541 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.545 - ETA: 1s - loss: 2.550 - ETA: 1s - loss: 2.546 - ETA: 1s - loss: 2.542 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.546 - ETA: 0s - loss: 2.543 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.544 - 3s 150us/step - loss: 2.5430\n",
      "\n",
      "Epoch 00055: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 56/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.615 - ETA: 2s - loss: 2.572 - ETA: 2s - loss: 2.561 - ETA: 2s - loss: 2.546 - ETA: 2s - loss: 2.546 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.542 - ETA: 1s - loss: 2.546 - ETA: 1s - loss: 2.545 - ETA: 1s - loss: 2.540 - ETA: 1s - loss: 2.545 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.548 - 3s 153us/step - loss: 2.5489\n",
      "\n",
      "Epoch 00056: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 57/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.531 - ETA: 2s - loss: 2.484 - ETA: 2s - loss: 2.506 - ETA: 2s - loss: 2.514 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.531 - ETA: 1s - loss: 2.527 - ETA: 1s - loss: 2.536 - ETA: 1s - loss: 2.536 - ETA: 1s - loss: 2.538 - ETA: 1s - loss: 2.540 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.539 - ETA: 0s - loss: 2.539 - ETA: 0s - loss: 2.538 - ETA: 0s - loss: 2.535 - ETA: 0s - loss: 2.534 - 3s 149us/step - loss: 2.5347\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00057: CRPS_score_val did not improve from 0.01255\n",
      "Epoch 00057: early stopping\n",
      "the 4 fold crps is 0.012546\n",
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/100\n",
      "18537/18537 [==============================] - ETA: 15s - loss: 5.81 - ETA: 8s - loss: 5.8373 - ETA: 6s - loss: 5.814 - ETA: 4s - loss: 5.798 - ETA: 4s - loss: 5.794 - ETA: 3s - loss: 5.785 - ETA: 2s - loss: 5.772 - ETA: 2s - loss: 5.753 - ETA: 2s - loss: 5.733 - ETA: 1s - loss: 5.726 - ETA: 1s - loss: 5.710 - ETA: 1s - loss: 5.696 - ETA: 1s - loss: 5.679 - ETA: 0s - loss: 5.661 - ETA: 0s - loss: 5.650 - ETA: 0s - loss: 5.642 - ETA: 0s - loss: 5.631 - ETA: 0s - loss: 5.612 - 4s 195us/step - loss: 5.6113\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08292, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 5.295 - ETA: 2s - loss: 5.262 - ETA: 2s - loss: 5.254 - ETA: 2s - loss: 5.250 - ETA: 2s - loss: 5.231 - ETA: 1s - loss: 5.222 - ETA: 1s - loss: 5.218 - ETA: 1s - loss: 5.204 - ETA: 1s - loss: 5.192 - ETA: 1s - loss: 5.178 - ETA: 1s - loss: 5.165 - ETA: 0s - loss: 5.155 - ETA: 0s - loss: 5.135 - ETA: 0s - loss: 5.125 - ETA: 0s - loss: 5.116 - ETA: 0s - loss: 5.109 - ETA: 0s - loss: 5.100 - ETA: 0s - loss: 5.085 - 3s 158us/step - loss: 5.0840\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08292 to 0.07729, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 4.884 - ETA: 2s - loss: 4.841 - ETA: 2s - loss: 4.818 - ETA: 2s - loss: 4.808 - ETA: 2s - loss: 4.792 - ETA: 1s - loss: 4.779 - ETA: 1s - loss: 4.757 - ETA: 1s - loss: 4.742 - ETA: 1s - loss: 4.722 - ETA: 1s - loss: 4.705 - ETA: 1s - loss: 4.707 - ETA: 0s - loss: 4.694 - ETA: 0s - loss: 4.690 - ETA: 0s - loss: 4.685 - ETA: 0s - loss: 4.670 - ETA: 0s - loss: 4.659 - ETA: 0s - loss: 4.644 - ETA: 0s - loss: 4.635 - 3s 154us/step - loss: 4.6321\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.07729 to 0.06492, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 4.480 - ETA: 2s - loss: 4.414 - ETA: 2s - loss: 4.423 - ETA: 2s - loss: 4.412 - ETA: 2s - loss: 4.404 - ETA: 1s - loss: 4.387 - ETA: 1s - loss: 4.392 - ETA: 1s - loss: 4.364 - ETA: 1s - loss: 4.349 - ETA: 1s - loss: 4.335 - ETA: 1s - loss: 4.325 - ETA: 0s - loss: 4.314 - ETA: 0s - loss: 4.312 - ETA: 0s - loss: 4.297 - ETA: 0s - loss: 4.277 - ETA: 0s - loss: 4.267 - ETA: 0s - loss: 4.258 - ETA: 0s - loss: 4.248 - 3s 155us/step - loss: 4.2465\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.06492 to 0.04523, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 4.009 - ETA: 2s - loss: 4.045 - ETA: 2s - loss: 4.021 - ETA: 2s - loss: 3.993 - ETA: 2s - loss: 4.022 - ETA: 1s - loss: 4.003 - ETA: 1s - loss: 3.994 - ETA: 1s - loss: 4.001 - ETA: 1s - loss: 3.989 - ETA: 1s - loss: 3.973 - ETA: 1s - loss: 3.965 - ETA: 0s - loss: 3.948 - ETA: 0s - loss: 3.928 - ETA: 0s - loss: 3.913 - ETA: 0s - loss: 3.899 - ETA: 0s - loss: 3.889 - ETA: 0s - loss: 3.880 - ETA: 0s - loss: 3.875 - 3s 154us/step - loss: 3.8741\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.04523 to 0.02793, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.633 - ETA: 2s - loss: 3.609 - ETA: 2s - loss: 3.617 - ETA: 2s - loss: 3.629 - ETA: 2s - loss: 3.639 - ETA: 1s - loss: 3.633 - ETA: 1s - loss: 3.627 - ETA: 1s - loss: 3.613 - ETA: 1s - loss: 3.596 - ETA: 1s - loss: 3.584 - ETA: 1s - loss: 3.574 - ETA: 0s - loss: 3.570 - ETA: 0s - loss: 3.560 - ETA: 0s - loss: 3.555 - ETA: 0s - loss: 3.547 - ETA: 0s - loss: 3.536 - ETA: 0s - loss: 3.530 - ETA: 0s - loss: 3.527 - 3s 155us/step - loss: 3.5261\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.02793 to 0.01927, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 3.336 - ETA: 2s - loss: 3.346 - ETA: 2s - loss: 3.341 - ETA: 2s - loss: 3.323 - ETA: 2s - loss: 3.312 - ETA: 1s - loss: 3.314 - ETA: 1s - loss: 3.309 - ETA: 1s - loss: 3.313 - ETA: 1s - loss: 3.302 - ETA: 1s - loss: 3.301 - ETA: 1s - loss: 3.291 - ETA: 0s - loss: 3.289 - ETA: 0s - loss: 3.286 - ETA: 0s - loss: 3.283 - ETA: 0s - loss: 3.275 - ETA: 0s - loss: 3.268 - ETA: 0s - loss: 3.259 - ETA: 0s - loss: 3.251 - 3s 156us/step - loss: 3.2529\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01927 to 0.01579, saving model to best_model.h5\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 3.116 - ETA: 2s - loss: 3.120 - ETA: 2s - loss: 3.117 - ETA: 2s - loss: 3.130 - ETA: 2s - loss: 3.115 - ETA: 1s - loss: 3.121 - ETA: 1s - loss: 3.104 - ETA: 1s - loss: 3.101 - ETA: 1s - loss: 3.100 - ETA: 1s - loss: 3.101 - ETA: 1s - loss: 3.098 - ETA: 0s - loss: 3.097 - ETA: 0s - loss: 3.094 - ETA: 0s - loss: 3.090 - ETA: 0s - loss: 3.094 - ETA: 0s - loss: 3.095 - ETA: 0s - loss: 3.088 - ETA: 0s - loss: 3.078 - 3s 156us/step - loss: 3.0802\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01579 to 0.01439, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.999 - ETA: 2s - loss: 2.973 - ETA: 2s - loss: 2.969 - ETA: 2s - loss: 2.953 - ETA: 2s - loss: 2.973 - ETA: 1s - loss: 2.982 - ETA: 1s - loss: 2.976 - ETA: 1s - loss: 2.981 - ETA: 1s - loss: 2.982 - ETA: 1s - loss: 2.979 - ETA: 1s - loss: 2.972 - ETA: 0s - loss: 2.973 - ETA: 0s - loss: 2.976 - ETA: 0s - loss: 2.972 - ETA: 0s - loss: 2.977 - ETA: 0s - loss: 2.976 - ETA: 0s - loss: 2.973 - ETA: 0s - loss: 2.970 - 3s 156us/step - loss: 2.9696\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01439 to 0.01377, saving model to best_model.h5\n",
      "Epoch 10/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.965 - ETA: 2s - loss: 3.000 - ETA: 2s - loss: 2.968 - ETA: 2s - loss: 2.955 - ETA: 2s - loss: 2.939 - ETA: 1s - loss: 2.941 - ETA: 1s - loss: 2.922 - ETA: 1s - loss: 2.921 - ETA: 1s - loss: 2.924 - ETA: 1s - loss: 2.925 - ETA: 1s - loss: 2.919 - ETA: 0s - loss: 2.915 - ETA: 0s - loss: 2.916 - ETA: 0s - loss: 2.911 - ETA: 0s - loss: 2.910 - ETA: 0s - loss: 2.901 - ETA: 0s - loss: 2.900 - ETA: 0s - loss: 2.899 - 3s 155us/step - loss: 2.8986\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01377 to 0.01350, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.848 - ETA: 2s - loss: 2.864 - ETA: 2s - loss: 2.855 - ETA: 2s - loss: 2.865 - ETA: 2s - loss: 2.862 - ETA: 1s - loss: 2.854 - ETA: 1s - loss: 2.860 - ETA: 1s - loss: 2.859 - ETA: 1s - loss: 2.856 - ETA: 1s - loss: 2.856 - ETA: 1s - loss: 2.852 - ETA: 0s - loss: 2.846 - ETA: 0s - loss: 2.846 - ETA: 0s - loss: 2.849 - ETA: 0s - loss: 2.852 - ETA: 0s - loss: 2.848 - ETA: 0s - loss: 2.846 - ETA: 0s - loss: 2.845 - 3s 156us/step - loss: 2.8455\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01350 to 0.01341, saving model to best_model.h5\n",
      "Epoch 12/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.825 - ETA: 2s - loss: 2.824 - ETA: 2s - loss: 2.847 - ETA: 2s - loss: 2.832 - ETA: 2s - loss: 2.842 - ETA: 1s - loss: 2.831 - ETA: 1s - loss: 2.837 - ETA: 1s - loss: 2.829 - ETA: 1s - loss: 2.834 - ETA: 1s - loss: 2.830 - ETA: 1s - loss: 2.824 - ETA: 0s - loss: 2.821 - ETA: 0s - loss: 2.817 - ETA: 0s - loss: 2.815 - ETA: 0s - loss: 2.811 - ETA: 0s - loss: 2.810 - ETA: 0s - loss: 2.810 - ETA: 0s - loss: 2.806 - 3s 153us/step - loss: 2.8059\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01341 to 0.01336, saving model to best_model.h5\n",
      "Epoch 13/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.787 - ETA: 2s - loss: 2.805 - ETA: 2s - loss: 2.800 - ETA: 2s - loss: 2.795 - ETA: 2s - loss: 2.802 - ETA: 1s - loss: 2.801 - ETA: 1s - loss: 2.798 - ETA: 1s - loss: 2.779 - ETA: 1s - loss: 2.783 - ETA: 1s - loss: 2.780 - ETA: 1s - loss: 2.778 - ETA: 0s - loss: 2.781 - ETA: 0s - loss: 2.783 - ETA: 0s - loss: 2.783 - ETA: 0s - loss: 2.785 - ETA: 0s - loss: 2.787 - ETA: 0s - loss: 2.788 - ETA: 0s - loss: 2.784 - 3s 158us/step - loss: 2.7848\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01336 to 0.01332, saving model to best_model.h5\n",
      "Epoch 14/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.783 - ETA: 2s - loss: 2.774 - ETA: 2s - loss: 2.782 - ETA: 2s - loss: 2.789 - ETA: 2s - loss: 2.779 - ETA: 1s - loss: 2.775 - ETA: 1s - loss: 2.772 - ETA: 1s - loss: 2.765 - ETA: 1s - loss: 2.774 - ETA: 1s - loss: 2.775 - ETA: 1s - loss: 2.770 - ETA: 0s - loss: 2.771 - ETA: 0s - loss: 2.770 - ETA: 0s - loss: 2.768 - ETA: 0s - loss: 2.767 - ETA: 0s - loss: 2.768 - ETA: 0s - loss: 2.768 - ETA: 0s - loss: 2.768 - 3s 156us/step - loss: 2.7681\n",
      "\n",
      "Epoch 00014: CRPS_score_val improved from 0.01332 to 0.01328, saving model to best_model.h5\n",
      "Epoch 15/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.776 - ETA: 2s - loss: 2.756 - ETA: 2s - loss: 2.776 - ETA: 2s - loss: 2.784 - ETA: 2s - loss: 2.780 - ETA: 1s - loss: 2.771 - ETA: 1s - loss: 2.763 - ETA: 1s - loss: 2.769 - ETA: 1s - loss: 2.774 - ETA: 1s - loss: 2.772 - ETA: 1s - loss: 2.764 - ETA: 0s - loss: 2.754 - ETA: 0s - loss: 2.747 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.747 - ETA: 0s - loss: 2.749 - ETA: 0s - loss: 2.747 - ETA: 0s - loss: 2.746 - 3s 157us/step - loss: 2.7470\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01328 to 0.01326, saving model to best_model.h5\n",
      "Epoch 16/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.710 - ETA: 2s - loss: 2.741 - ETA: 2s - loss: 2.740 - ETA: 2s - loss: 2.738 - ETA: 2s - loss: 2.751 - ETA: 1s - loss: 2.750 - ETA: 1s - loss: 2.739 - ETA: 1s - loss: 2.736 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.735 - ETA: 1s - loss: 2.741 - ETA: 0s - loss: 2.739 - ETA: 0s - loss: 2.732 - ETA: 0s - loss: 2.738 - ETA: 0s - loss: 2.741 - ETA: 0s - loss: 2.738 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.737 - 3s 159us/step - loss: 2.7383\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01326 to 0.01321, saving model to best_model.h5\n",
      "Epoch 17/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.685 - ETA: 2s - loss: 2.709 - ETA: 2s - loss: 2.715 - ETA: 2s - loss: 2.720 - ETA: 2s - loss: 2.710 - ETA: 2s - loss: 2.721 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.718 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.723 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.727 - ETA: 0s - loss: 2.728 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.729 - ETA: 0s - loss: 2.727 - 3s 160us/step - loss: 2.7268\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01321 to 0.01320, saving model to best_model.h5\n",
      "Epoch 18/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.759 - ETA: 2s - loss: 2.745 - ETA: 2s - loss: 2.757 - ETA: 2s - loss: 2.737 - ETA: 2s - loss: 2.739 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.727 - ETA: 1s - loss: 2.723 - ETA: 1s - loss: 2.725 - ETA: 1s - loss: 2.722 - ETA: 1s - loss: 2.721 - ETA: 0s - loss: 2.719 - ETA: 0s - loss: 2.721 - ETA: 0s - loss: 2.717 - ETA: 0s - loss: 2.717 - ETA: 0s - loss: 2.716 - ETA: 0s - loss: 2.716 - ETA: 0s - loss: 2.716 - 3s 157us/step - loss: 2.7179\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01320 to 0.01317, saving model to best_model.h5\n",
      "Epoch 19/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.670 - ETA: 2s - loss: 2.705 - ETA: 2s - loss: 2.711 - ETA: 2s - loss: 2.709 - ETA: 2s - loss: 2.699 - ETA: 1s - loss: 2.701 - ETA: 1s - loss: 2.706 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.714 - ETA: 1s - loss: 2.707 - ETA: 0s - loss: 2.708 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.711 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.713 - 3s 156us/step - loss: 2.7135\n",
      "\n",
      "Epoch 00019: CRPS_score_val improved from 0.01317 to 0.01316, saving model to best_model.h5\n",
      "Epoch 20/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.720 - ETA: 2s - loss: 2.688 - ETA: 2s - loss: 2.694 - ETA: 2s - loss: 2.692 - ETA: 2s - loss: 2.695 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.697 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.700 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.701 - ETA: 0s - loss: 2.707 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.702 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.704 - 3s 158us/step - loss: 2.7039\n",
      "\n",
      "Epoch 00020: CRPS_score_val improved from 0.01316 to 0.01315, saving model to best_model.h5\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 2.698 - ETA: 2s - loss: 2.690 - ETA: 2s - loss: 2.688 - ETA: 2s - loss: 2.697 - ETA: 2s - loss: 2.704 - ETA: 1s - loss: 2.692 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.697 - ETA: 1s - loss: 2.690 - ETA: 1s - loss: 2.689 - ETA: 0s - loss: 2.689 - ETA: 0s - loss: 2.690 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.694 - ETA: 0s - loss: 2.694 - ETA: 0s - loss: 2.694 - ETA: 0s - loss: 2.695 - 3s 156us/step - loss: 2.6962\n",
      "\n",
      "Epoch 00021: CRPS_score_val improved from 0.01315 to 0.01313, saving model to best_model.h5\n",
      "Epoch 22/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.662 - ETA: 2s - loss: 2.658 - ETA: 2s - loss: 2.679 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.687 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.683 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.686 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.682 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.686 - 3s 157us/step - loss: 2.6869\n",
      "\n",
      "Epoch 00022: CRPS_score_val improved from 0.01313 to 0.01311, saving model to best_model.h5\n",
      "Epoch 23/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.706 - ETA: 2s - loss: 2.678 - ETA: 2s - loss: 2.671 - ETA: 2s - loss: 2.678 - ETA: 2s - loss: 2.669 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.667 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.669 - ETA: 0s - loss: 2.675 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.678 - ETA: 0s - loss: 2.679 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.680 - ETA: 0s - loss: 2.680 - 3s 156us/step - loss: 2.6823\n",
      "\n",
      "Epoch 00023: CRPS_score_val improved from 0.01311 to 0.01308, saving model to best_model.h5\n",
      "Epoch 24/100\n",
      "18537/18537 [==============================] - ETA: 3s - loss: 2.706 - ETA: 2s - loss: 2.660 - ETA: 2s - loss: 2.679 - ETA: 2s - loss: 2.688 - ETA: 2s - loss: 2.674 - ETA: 1s - loss: 2.667 - ETA: 1s - loss: 2.661 - ETA: 1s - loss: 2.665 - ETA: 1s - loss: 2.665 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.666 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.671 - 3s 162us/step - loss: 2.6726\n",
      "\n",
      "Epoch 00024: CRPS_score_val improved from 0.01308 to 0.01307, saving model to best_model.h5\n",
      "Epoch 25/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.691 - ETA: 2s - loss: 2.666 - ETA: 2s - loss: 2.679 - ETA: 2s - loss: 2.677 - ETA: 2s - loss: 2.686 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.669 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.673 - 3s 157us/step - loss: 2.6733\n",
      "\n",
      "Epoch 00025: CRPS_score_val did not improve from 0.01307\n",
      "Epoch 26/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.692 - ETA: 2s - loss: 2.701 - ETA: 2s - loss: 2.675 - ETA: 2s - loss: 2.664 - ETA: 2s - loss: 2.663 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.661 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.663 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.662 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.667 - 3s 156us/step - loss: 2.6673\n",
      "\n",
      "Epoch 00026: CRPS_score_val did not improve from 0.01307\n",
      "Epoch 27/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.638 - ETA: 2s - loss: 2.621 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.647 - ETA: 2s - loss: 2.642 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.655 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.660 - 3s 156us/step - loss: 2.6611\n",
      "\n",
      "Epoch 00027: CRPS_score_val did not improve from 0.01307\n",
      "Epoch 28/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.635 - ETA: 2s - loss: 2.630 - ETA: 2s - loss: 2.647 - ETA: 2s - loss: 2.633 - ETA: 2s - loss: 2.635 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.650 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.652 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.657 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.659 - 3s 164us/step - loss: 2.6602\n",
      "\n",
      "Epoch 00028: CRPS_score_val improved from 0.01307 to 0.01305, saving model to best_model.h5\n",
      "Epoch 29/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.608 - ETA: 2s - loss: 2.637 - ETA: 2s - loss: 2.652 - ETA: 2s - loss: 2.642 - ETA: 2s - loss: 2.645 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.639 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.648 - ETA: 1s - loss: 2.643 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.643 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.649 - 3s 156us/step - loss: 2.6498\n",
      "\n",
      "Epoch 00029: CRPS_score_val did not improve from 0.01305\n",
      "Epoch 30/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.649 - ETA: 2s - loss: 2.649 - ETA: 2s - loss: 2.625 - ETA: 2s - loss: 2.634 - ETA: 2s - loss: 2.642 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.646 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.652 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.653 - 3s 155us/step - loss: 2.6525\n",
      "\n",
      "Epoch 00030: CRPS_score_val improved from 0.01305 to 0.01303, saving model to best_model.h5\n",
      "Epoch 31/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.643 - ETA: 2s - loss: 2.653 - ETA: 2s - loss: 2.630 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.625 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.642 - ETA: 1s - loss: 2.649 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.639 - 3s 156us/step - loss: 2.6402\n",
      "\n",
      "Epoch 00031: CRPS_score_val improved from 0.01303 to 0.01303, saving model to best_model.h5\n",
      "Epoch 32/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.625 - ETA: 2s - loss: 2.635 - ETA: 2s - loss: 2.644 - ETA: 2s - loss: 2.645 - ETA: 2s - loss: 2.638 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.635 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.639 - 3s 160us/step - loss: 2.6405\n",
      "\n",
      "Epoch 00032: CRPS_score_val improved from 0.01303 to 0.01302, saving model to best_model.h5\n",
      "Epoch 33/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.679 - ETA: 2s - loss: 2.655 - ETA: 2s - loss: 2.644 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.629 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.632 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.634 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.637 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.631 - 3s 156us/step - loss: 2.6324\n",
      "\n",
      "Epoch 00033: CRPS_score_val did not improve from 0.01302\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 2.615 - ETA: 2s - loss: 2.633 - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.613 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.619 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.627 - 3s 156us/step - loss: 2.6281\n",
      "\n",
      "Epoch 00034: CRPS_score_val improved from 0.01302 to 0.01300, saving model to best_model.h5\n",
      "Epoch 35/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.597 - ETA: 2s - loss: 2.623 - ETA: 2s - loss: 2.631 - ETA: 2s - loss: 2.641 - ETA: 2s - loss: 2.631 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.634 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.630 - 3s 157us/step - loss: 2.6315\n",
      "\n",
      "Epoch 00035: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 36/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.665 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.646 - ETA: 2s - loss: 2.640 - ETA: 2s - loss: 2.636 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.623 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.618 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.621 - 3s 158us/step - loss: 2.6226\n",
      "\n",
      "Epoch 00036: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 37/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.620 - ETA: 2s - loss: 2.619 - ETA: 2s - loss: 2.596 - ETA: 2s - loss: 2.599 - ETA: 2s - loss: 2.600 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.606 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.614 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.617 - 3s 156us/step - loss: 2.6177\n",
      "\n",
      "Epoch 00037: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 38/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.664 - ETA: 2s - loss: 2.617 - ETA: 2s - loss: 2.626 - ETA: 2s - loss: 2.623 - ETA: 2s - loss: 2.620 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.621 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.610 - ETA: 0s - loss: 2.611 - ETA: 0s - loss: 2.610 - 3s 156us/step - loss: 2.6111\n",
      "\n",
      "Epoch 00038: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 39/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.594 - ETA: 2s - loss: 2.572 - ETA: 2s - loss: 2.571 - ETA: 2s - loss: 2.581 - ETA: 2s - loss: 2.587 - ETA: 1s - loss: 2.598 - ETA: 1s - loss: 2.601 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.597 - ETA: 1s - loss: 2.597 - ETA: 1s - loss: 2.599 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.607 - ETA: 0s - loss: 2.607 - 3s 157us/step - loss: 2.6075\n",
      "\n",
      "Epoch 00039: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 40/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.664 - ETA: 2s - loss: 2.649 - ETA: 2s - loss: 2.619 - ETA: 2s - loss: 2.596 - ETA: 2s - loss: 2.601 - ETA: 2s - loss: 2.603 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.591 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.594 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.602 - 3s 161us/step - loss: 2.6038\n",
      "\n",
      "Epoch 00040: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 41/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.582 - ETA: 2s - loss: 2.606 - ETA: 2s - loss: 2.597 - ETA: 2s - loss: 2.583 - ETA: 2s - loss: 2.591 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.589 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.603 - ETA: 1s - loss: 2.599 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.596 - 3s 155us/step - loss: 2.5962\n",
      "\n",
      "Epoch 00041: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 42/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.620 - ETA: 2s - loss: 2.603 - ETA: 2s - loss: 2.584 - ETA: 2s - loss: 2.594 - ETA: 2s - loss: 2.587 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.597 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.600 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.598 - 3s 157us/step - loss: 2.5969\n",
      "\n",
      "Epoch 00042: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 43/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.556 - ETA: 2s - loss: 2.570 - ETA: 2s - loss: 2.570 - ETA: 2s - loss: 2.574 - ETA: 2s - loss: 2.576 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.595 - ETA: 1s - loss: 2.592 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.599 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.594 - ETA: 0s - loss: 2.592 - ETA: 0s - loss: 2.590 - 3s 158us/step - loss: 2.5919\n",
      "\n",
      "Epoch 00043: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 44/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.637 - ETA: 2s - loss: 2.613 - ETA: 2s - loss: 2.610 - ETA: 2s - loss: 2.598 - ETA: 2s - loss: 2.590 - ETA: 2s - loss: 2.588 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.580 - ETA: 0s - loss: 2.581 - ETA: 0s - loss: 2.579 - ETA: 0s - loss: 2.579 - ETA: 0s - loss: 2.581 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.585 - 3s 159us/step - loss: 2.5858\n",
      "\n",
      "Epoch 00044: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 45/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.567 - ETA: 2s - loss: 2.566 - ETA: 2s - loss: 2.593 - ETA: 2s - loss: 2.580 - ETA: 2s - loss: 2.585 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.576 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.576 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.579 - 3s 158us/step - loss: 2.5799\n",
      "\n",
      "Epoch 00045: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 46/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.561 - ETA: 2s - loss: 2.570 - ETA: 2s - loss: 2.578 - ETA: 2s - loss: 2.577 - ETA: 2s - loss: 2.571 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.562 - ETA: 1s - loss: 2.558 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.558 - ETA: 1s - loss: 2.563 - ETA: 0s - loss: 2.561 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.566 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.574 - 3s 157us/step - loss: 2.5736\n",
      "\n",
      "Epoch 00046: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 47/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.614 - ETA: 2s - loss: 2.618 - ETA: 2s - loss: 2.597 - ETA: 2s - loss: 2.577 - ETA: 2s - loss: 2.570 - ETA: 1s - loss: 2.563 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.573 - ETA: 1s - loss: 2.576 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.575 - 3s 157us/step - loss: 2.5770\n",
      "\n",
      "Epoch 00047: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18537/18537 [==============================] - ETA: 2s - loss: 2.550 - ETA: 2s - loss: 2.551 - ETA: 2s - loss: 2.551 - ETA: 2s - loss: 2.561 - ETA: 2s - loss: 2.554 - ETA: 2s - loss: 2.561 - ETA: 1s - loss: 2.560 - ETA: 1s - loss: 2.560 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.560 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.560 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.557 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.569 - 3s 160us/step - loss: 2.5695\n",
      "\n",
      "Epoch 00048: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 49/100\n",
      "18537/18537 [==============================] - ETA: 2s - loss: 2.511 - ETA: 2s - loss: 2.554 - ETA: 2s - loss: 2.569 - ETA: 2s - loss: 2.552 - ETA: 2s - loss: 2.560 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.558 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.569 - ETA: 1s - loss: 2.573 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.566 - 3s 156us/step - loss: 2.5665\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00049: CRPS_score_val did not improve from 0.01300\n",
      "Epoch 00049: early stopping\n",
      "the 5 fold crps is 0.012998\n",
      "mean crps is 0.012714\n"
     ]
    }
   ],
   "source": [
    "d = defender[['PlayId','S','A','Horizontal Speed','Vertical Speed']].fillna(0)\n",
    "d = [d.drop('PlayId',axis = 1).iloc[np.arange(k, len(d), 6)].reset_index(drop = True) for k in range(6)]\n",
    "d = np.hstack([t.values for t in d])\n",
    "\n",
    "\n",
    "\n",
    "X = np.hstack([X_Dense,d])\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import time\n",
    "\n",
    "losses = []\n",
    "models = []\n",
    "crps_csv = []\n",
    "\n",
    "s_time = time.time()\n",
    "\n",
    "\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n",
    "        print(\"-----------\")\n",
    "        print(\"-----------\")\n",
    "        tr_x,tr_y = X[tr_inds],y[tr_inds]\n",
    "        val_x,val_y = X[val_inds],y[val_inds]\n",
    "        model,crps = get_model(tr_x,tr_y,val_x,val_y)\n",
    "        models.append(model)\n",
    "        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n",
    "        crps_csv.append(crps)\n",
    " \n",
    "print(\"mean crps is %f\"%np.mean(crps_csv))\n",
    "\n",
    "\n",
    "def predict(x_te):\n",
    "    model_num = len(models)\n",
    "    for k,m in enumerate(models):\n",
    "        if k==0:\n",
    "            y_pred = m.predict(x_te,batch_size=1024)\n",
    "        else:\n",
    "            y_pred+=m.predict(x_te,batch_size=1024)\n",
    "            \n",
    "    y_pred = y_pred / model_num\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
