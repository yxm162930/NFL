{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import datetime, tqdm\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "pd.set_option('max_columns', 100)\n",
    "#from kaggle.competitions import nflrush\n",
    "from sklearn.model_selection import KFold, RepeatedKFold,GroupKFold\n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense,Dropout, PReLU, BatchNormalization, ELU, GaussianNoise, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import keras.backend as K\n",
    "import lightgbm as lgb\n",
    "#note： \n",
    "#1. As a result it might not be worthwhile to use features related to game clock/quarter of the game。\n",
    "#2. There is no relationships between number of rushes before and running yards gained。\n",
    "#3. rushing success larger depends on defender in box, or defender that are close to offensive lineman and attempt \n",
    "#   to counter the blocking.\n",
    "#4. highly drafted player has the same average rushing yards as the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\38980\\OneDrive\\Desktop\\study\\kaggle\\NFL\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team abbreviations correct\n",
    "def data_clean(df):\n",
    "#correct name   \n",
    "    df.loc[df['PossessionTeam'] == 'ARZ', 'PossessionTeam'] = 'ARI'\n",
    "    df.loc[df['PossessionTeam'] == 'BLT', 'PossessionTeam'] = 'BAL'\n",
    "    df.loc[df['PossessionTeam'] == 'CLV', 'PossessionTeam'] = 'CLE'\n",
    "    df.loc[df['PossessionTeam'] == 'HST', 'PossessionTeam'] = 'HOU'\n",
    "    df.loc[df['FieldPosition'] == 'ARZ', 'FieldPosition'] = 'ARI'\n",
    "    df.loc[df['FieldPosition'] == 'BLT', 'FieldPosition'] = 'BAL'\n",
    "    df.loc[df['FieldPosition'] == 'CLV', 'FieldPosition'] = 'CLE'\n",
    "    df.loc[df['FieldPosition'] == 'HST', 'FieldPosition'] = 'HOU'\n",
    "\n",
    "    df.loc[df['Season'] == 2017, 'S'] = (df.loc[df['Season'] == 2017, 'S'] - 2.4355) / 1.2930 * 1.4551 + 2.7570\n",
    "\n",
    "\n",
    "# offense time and defence time\n",
    "    df['TeamOnOffense'] = \"home\"\n",
    "    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    df['IsOnOffense'] = df.Team == df.TeamOnOffense # Is player on offense?\n",
    "    \n",
    "#time\n",
    "    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    seconds_in_year = 60*60*24*365.25\n",
    "    df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "    df['GameClock'] = df['GameClock'].apply(lambda x: float(x.split(\":\")[0]) + float(x.split(\":\")[1])/60)\n",
    "    df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "#player height\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "\n",
    "#weather\n",
    "    def map_weather(txt):\n",
    "        ans = 1\n",
    "        if pd.isna(txt):\n",
    "            return 0\n",
    "        if 'partly' in txt:\n",
    "            ans*=0.5\n",
    "        if 'climate controlled' in txt or 'indoor' in txt:\n",
    "            return ans*3\n",
    "        if 'sunny' in txt or 'sun' in txt:\n",
    "            return ans*2\n",
    "        if 'clear' in txt:\n",
    "            return ans\n",
    "        if 'cloudy' in txt:\n",
    "            return -ans\n",
    "        if 'rain' in txt or 'rainy' in txt:\n",
    "            return -2*ans\n",
    "        if 'snow' in txt:\n",
    "            return -3*ans\n",
    "        return 0\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    df['Cleaned_GameWeather'] = df['Cleaned_GameWeather'].apply(map_weather)\n",
    "\n",
    "#diff Score    \n",
    "    df[\"DiffScoreBeforePlay_ob\"] = (df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"])\n",
    "    df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]] = - df.loc[df['Team'] == 'away',[\"DiffScoreBeforePlay_ob\"]]\n",
    "\n",
    "#left to right\n",
    "    df['New_X'] = df['X']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_X'] = 120 - df.loc[df['PlayDirection'] == 'left','X']\n",
    "    df['New_Y'] = df['Y']\n",
    "    df.loc[df['PlayDirection'] == 'left','New_Y'] = 160/3 - df.loc[df['PlayDirection'] == 'left','Y']\n",
    "    df['Orientation_std'] = df['Orientation']\n",
    "    #df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std'] = 360 - df.loc[(df['Season'] > 2017)&(df['PlayDirection'] == 'left'), 'Orientation_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Orientation_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Orientation_std'], 360)\n",
    "    df['Dir_std'] = df['Dir']\n",
    "    #df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = 360 - df.loc[df['PlayDirection'] == 'left', 'Dir_std']\n",
    "    df.loc[df['PlayDirection'] == 'left', 'Dir_std'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Dir_std'], 360)\n",
    "    df['YardLine_std'] = 100 - df['YardLine']\n",
    "    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine_std'\n",
    "         ] = df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "          'YardLine']\n",
    "    df[\"Orientation_sin\"] = df[\"Orientation_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Orientation_cos\"] = df[\"Orientation_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_sin\"] = df[\"Dir_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    df[\"Dir_cos\"] = df[\"Dir_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "\n",
    "#distance and S\n",
    "    \n",
    "    #distance to yardline\n",
    "    df['Dis_YardLine'] = df['New_X'] - df['YardLine_std'] - 10\n",
    "    \n",
    "    #distance to rusher\n",
    "    def Distance(x1,x2,y1,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "    def Degree(x1,x2,y1,y2):\n",
    "        try:\n",
    "            tan = (y1-y2)/(x1-x2)\n",
    "        except:\n",
    "            tan = 0\n",
    "        degree = 90 - math.atan(tan)/(2*np.pi)*360\n",
    "        return degree\n",
    "    df['IsRusher'] = (df['NflId'] == df['NflIdRusher'])\n",
    "    Rusher =df.loc[df['IsRusher'],['PlayId','New_X','New_Y','Dir_std','S']].rename(columns={\"New_X\":\"Rusher_X\",\"New_Y\":\"Rusher_Y\",'PossessionTeam':'Offense_Team','Dir_std':'Rusher_Dir_std','S':'Rusher_Speed'})\n",
    "    df = df.merge(Rusher,how = 'left',on = 'PlayId')\n",
    "    df['Distance_to_Rusher'] = df[[\"New_X\",\"Rusher_X\",\"New_Y\",\"Rusher_Y\"]].apply(lambda x: Distance(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_to_Rusher'] = df[[\"New_X\",\"Rusher_X\",\"New_Y\",\"Rusher_Y\"]].apply(lambda x: Degree(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df['Degree_Diff'] = df['Degree_to_Rusher'] - df['Rusher_Dir_std']\n",
    "    df['Degree_Diff2'] = 270 - (90-df['Degree_to_Rusher']) - df['Dir_std']\n",
    "    df['Speed_Ratio'] =  (df['Rusher_Speed']+0.01)/(df['S']+0.01)\n",
    "\n",
    "# speed\n",
    "    df['Horizontal Speed'] = df['S']*df[\"Dir_sin\"]\n",
    "    df['Vertical Speed'] = df['S']*df[\"Dir_cos\"]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:71: RuntimeWarning: invalid value encountered in remainder\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:74: RuntimeWarning: invalid value encountered in remainder\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "train = data_clean(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayId</th>\n",
       "      <th>Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170907000118</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170907000189</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170907000516</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170907000917</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170907001077</td>\n",
       "      <td>1.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20170907001156</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20170907001488</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20170907001509</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20170907001530</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20170907001605</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20170907001715</td>\n",
       "      <td>0.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20170907002648</td>\n",
       "      <td>2.206667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20170907002829</td>\n",
       "      <td>2.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20170907002900</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20170907003444</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20170907003465</td>\n",
       "      <td>1.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20170907003507</td>\n",
       "      <td>4.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20170907004046</td>\n",
       "      <td>2.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20170907004182</td>\n",
       "      <td>1.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20170907004465</td>\n",
       "      <td>1.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20170907004721</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20170910000221</td>\n",
       "      <td>1.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20170910000242</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20170910000263</td>\n",
       "      <td>1.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20170910000358</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20170910001020</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20170910001102</td>\n",
       "      <td>1.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20170910001123</td>\n",
       "      <td>1.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20170910001522</td>\n",
       "      <td>1.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20170910001622</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11617</th>\n",
       "      <td>20181230150105</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>20181230150181</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11619</th>\n",
       "      <td>20181230150371</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11620</th>\n",
       "      <td>20181230150440</td>\n",
       "      <td>1.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11621</th>\n",
       "      <td>20181230150528</td>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11622</th>\n",
       "      <td>20181230150550</td>\n",
       "      <td>1.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11623</th>\n",
       "      <td>20181230150618</td>\n",
       "      <td>1.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11624</th>\n",
       "      <td>20181230150826</td>\n",
       "      <td>2.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11625</th>\n",
       "      <td>20181230150927</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11626</th>\n",
       "      <td>20181230151022</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11627</th>\n",
       "      <td>20181230151427</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11628</th>\n",
       "      <td>20181230151537</td>\n",
       "      <td>2.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11629</th>\n",
       "      <td>20181230151672</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11630</th>\n",
       "      <td>20181230151746</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11631</th>\n",
       "      <td>20181230152303</td>\n",
       "      <td>1.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11632</th>\n",
       "      <td>20181230152535</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11633</th>\n",
       "      <td>20181230152582</td>\n",
       "      <td>2.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11634</th>\n",
       "      <td>20181230152720</td>\n",
       "      <td>1.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11635</th>\n",
       "      <td>20181230152792</td>\n",
       "      <td>3.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11636</th>\n",
       "      <td>20181230153023</td>\n",
       "      <td>1.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11637</th>\n",
       "      <td>20181230153136</td>\n",
       "      <td>1.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11638</th>\n",
       "      <td>20181230153158</td>\n",
       "      <td>1.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11639</th>\n",
       "      <td>20181230153420</td>\n",
       "      <td>2.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11640</th>\n",
       "      <td>20181230153515</td>\n",
       "      <td>1.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11641</th>\n",
       "      <td>20181230153631</td>\n",
       "      <td>1.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11642</th>\n",
       "      <td>20181230153866</td>\n",
       "      <td>2.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11643</th>\n",
       "      <td>20181230153888</td>\n",
       "      <td>1.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11644</th>\n",
       "      <td>20181230153910</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11645</th>\n",
       "      <td>20181230154035</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11646</th>\n",
       "      <td>20181230154157</td>\n",
       "      <td>1.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PlayId       Gap\n",
       "0      20170907000118  1.200000\n",
       "1      20170907000189  0.460000\n",
       "2      20170907000516  0.600000\n",
       "3      20170907000917  0.630000\n",
       "4      20170907001077  1.460000\n",
       "5      20170907001156  0.930000\n",
       "6      20170907001488  0.410000\n",
       "7      20170907001509  2.250000\n",
       "8      20170907001530  0.910000\n",
       "9      20170907001605  0.130000\n",
       "10     20170907001715  0.370000\n",
       "11     20170907002648  2.206667\n",
       "12     20170907002829  2.530000\n",
       "13     20170907002900  0.930000\n",
       "14     20170907003444  0.610000\n",
       "15     20170907003465  1.630000\n",
       "16     20170907003507  4.070000\n",
       "17     20170907004046  2.080000\n",
       "18     20170907004182  1.360000\n",
       "19     20170907004465  1.540000\n",
       "20     20170907004721  0.640000\n",
       "21     20170910000221  1.690000\n",
       "22     20170910000242  0.330000\n",
       "23     20170910000263  1.990000\n",
       "24     20170910000358  1.000000\n",
       "25     20170910001020  0.470000\n",
       "26     20170910001102  1.230000\n",
       "27     20170910001123  1.130000\n",
       "28     20170910001522  1.260000\n",
       "29     20170910001622  1.050000\n",
       "...               ...       ...\n",
       "11617  20181230150105  0.340000\n",
       "11618  20181230150181  0.460000\n",
       "11619  20181230150371  0.410000\n",
       "11620  20181230150440  1.410000\n",
       "11621  20181230150528  1.040000\n",
       "11622  20181230150550  1.030000\n",
       "11623  20181230150618  1.260000\n",
       "11624  20181230150826  2.190000\n",
       "11625  20181230150927  0.510000\n",
       "11626  20181230151022  0.280000\n",
       "11627  20181230151427  0.870000\n",
       "11628  20181230151537  2.720000\n",
       "11629  20181230151672  0.520000\n",
       "11630  20181230151746  0.170000\n",
       "11631  20181230152303  1.540000\n",
       "11632  20181230152535  0.790000\n",
       "11633  20181230152582  2.060000\n",
       "11634  20181230152720  1.460000\n",
       "11635  20181230152792  3.010000\n",
       "11636  20181230153023  1.660000\n",
       "11637  20181230153136  1.210000\n",
       "11638  20181230153158  1.560000\n",
       "11639  20181230153420  2.130000\n",
       "11640  20181230153515  1.060000\n",
       "11641  20181230153631  1.010000\n",
       "11642  20181230153866  2.290000\n",
       "11643  20181230153888  1.890000\n",
       "11644  20181230153910  0.900000\n",
       "11645  20181230154035  0.640000\n",
       "11646  20181230154157  1.010000\n",
       "\n",
       "[23157 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = train.drop(train[(train['Position'].isin(['FS','S','SS'])) & (train['Distance_to_Rusher']>15)].index)\n",
    "temp = temp.merge(train.loc[train['IsRusher'],['PlayId','Dir_std']]\\\n",
    "                  .rename(columns={'Dir_std':'Rusher_Dir'}), on = 'PlayId',how = 'left')\n",
    "\n",
    "#temp2 = temp.loc[(temp['IsOnOffense'])]\n",
    "temp = temp.loc[(~temp['IsOnOffense'])]\n",
    "\n",
    "\n",
    "op_up = temp[((temp['Rusher_Dir']<90)|(temp['Rusher_Dir']>270))&(temp['New_Y']>=temp['Rusher_Y'])]\n",
    "op_up = op_up.sort_values(['PlayId','New_Y'])\n",
    "op_up[['Next_Y','Next_X']] = op_up[['New_Y','New_X']].shift(1,axis = 0)\n",
    "op_up['Gap'] = op_up['New_Y'] - op_up['Next_Y']\n",
    "op_up[['PlayId','New_Y','Next_Y','Gap']]\n",
    "op_up = op_up[op_up['Gap'] > 0]\n",
    "closest_op_up = op_up[['PlayId','Gap']].groupby('PlayId').head(1).reset_index()\n",
    "best_up = op_up[['PlayId','Gap']].groupby('PlayId').max().reset_index()\n",
    "def_num_up = op_up[['PlayId','Gap']].rename(columns={'Gap': 'num_def'}).groupby('PlayId').count().reset_index()\n",
    "\n",
    "op_down = temp[(~((temp['Rusher_Dir']<90)|(temp['Rusher_Dir']>270)))&(temp['New_Y']<temp['Rusher_Y'])]\n",
    "op_down = op_down.sort_values(['PlayId','New_Y'])\n",
    "op_down[['Next_Y','Next_X']] = op_down[['New_Y','New_X']].shift(1,axis = 0)\n",
    "op_down['Gap'] = op_down['New_Y'] - op_down['Next_Y']\n",
    "op_down[['PlayId','New_Y','Next_Y','Gap']]\n",
    "closest_op_down = op_down[['PlayId','Gap']].groupby('PlayId').tail(1).reset_index()\n",
    "best_down = op_down[['PlayId','Gap']].groupby('PlayId').max().reset_index()\n",
    "def_num_down = op_down[['PlayId','Gap']].rename(columns={'Gap': 'num_def'}).groupby('PlayId').count().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "closest_op = closest_op_up.append(closest_op_down)\n",
    "best = best_up.append(best_down)\n",
    "closest_op[['PlayId','Gap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PlayId</th>\n",
       "      <th>Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>74330</td>\n",
       "      <td>20171012000641</td>\n",
       "      <td>-17.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>104774</td>\n",
       "      <td>20171029001345</td>\n",
       "      <td>-17.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>115313</td>\n",
       "      <td>20171030000776</td>\n",
       "      <td>-11.323333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>150422</td>\n",
       "      <td>20171119071455</td>\n",
       "      <td>-7.046667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>169975</td>\n",
       "      <td>20171127001488</td>\n",
       "      <td>-14.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>179772</td>\n",
       "      <td>20171203081200</td>\n",
       "      <td>-15.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>222285</td>\n",
       "      <td>20171224031478</td>\n",
       "      <td>-14.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5926</th>\n",
       "      <td>246186</td>\n",
       "      <td>20171231124047</td>\n",
       "      <td>-13.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6245</th>\n",
       "      <td>259490</td>\n",
       "      <td>20180909092856</td>\n",
       "      <td>-10.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>269096</td>\n",
       "      <td>20180916043849</td>\n",
       "      <td>-17.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>277106</td>\n",
       "      <td>20180917000823</td>\n",
       "      <td>-22.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7540</th>\n",
       "      <td>314009</td>\n",
       "      <td>20181007072579</td>\n",
       "      <td>-15.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7860</th>\n",
       "      <td>328383</td>\n",
       "      <td>20181014080144</td>\n",
       "      <td>-7.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8243</th>\n",
       "      <td>344417</td>\n",
       "      <td>20181021102529</td>\n",
       "      <td>-19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8335</th>\n",
       "      <td>348620</td>\n",
       "      <td>20181028011355</td>\n",
       "      <td>-14.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449</th>\n",
       "      <td>353391</td>\n",
       "      <td>20181028061350</td>\n",
       "      <td>-20.593333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8660</th>\n",
       "      <td>362065</td>\n",
       "      <td>20181104013560</td>\n",
       "      <td>-19.356667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8693</th>\n",
       "      <td>363464</td>\n",
       "      <td>20181104031556</td>\n",
       "      <td>-20.576667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8743</th>\n",
       "      <td>365717</td>\n",
       "      <td>20181104052976</td>\n",
       "      <td>-14.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096</th>\n",
       "      <td>380720</td>\n",
       "      <td>20181111083498</td>\n",
       "      <td>-17.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9214</th>\n",
       "      <td>385666</td>\n",
       "      <td>20181118000638</td>\n",
       "      <td>-15.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9241</th>\n",
       "      <td>387053</td>\n",
       "      <td>20181118013022</td>\n",
       "      <td>-23.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10297</th>\n",
       "      <td>428961</td>\n",
       "      <td>20181209023794</td>\n",
       "      <td>-14.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index          PlayId        Gap\n",
       "1765    74330  20171012000641 -17.266667\n",
       "2514   104774  20171029001345 -17.480000\n",
       "2764   115313  20171030000776 -11.323333\n",
       "3612   150422  20171119071455  -7.046667\n",
       "4068   169975  20171127001488 -14.090000\n",
       "4301   179772  20171203081200 -15.310000\n",
       "5352   222285  20171224031478 -14.770000\n",
       "5926   246186  20171231124047 -13.766667\n",
       "6245   259490  20180909092856 -10.850000\n",
       "6476   269096  20180916043849 -17.550000\n",
       "6655   277106  20180917000823 -22.646667\n",
       "7540   314009  20181007072579 -15.650000\n",
       "7860   328383  20181014080144  -7.120000\n",
       "8243   344417  20181021102529 -19.000000\n",
       "8335   348620  20181028011355 -14.030000\n",
       "8449   353391  20181028061350 -20.593333\n",
       "8660   362065  20181104013560 -19.356667\n",
       "8693   363464  20181104031556 -20.576667\n",
       "8743   365717  20181104052976 -14.520000\n",
       "9096   380720  20181111083498 -17.440000\n",
       "9214   385666  20181118000638 -15.420000\n",
       "9241   387053  20181118013022 -23.620000\n",
       "10297  428961  20181209023794 -14.740000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_op[closest_op['Gap'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    df1 = df.loc[df['IsRusher']]\n",
    "    df2 = df.loc[df['IsOnOffense'] & (~df['IsRusher'])]\n",
    "    df3 = df.loc[~df['IsOnOffense']]\n",
    "\n",
    "# max yards\n",
    "    df1['Max_Yards'] = df1['YardLine']\n",
    "    df1.loc[(df1.FieldPosition.fillna('') == df1.PossessionTeam)&(df1.PlayDirection =='left'),  'Max_Yards'] \\\n",
    "    = 100 - df1.loc[(df1.FieldPosition.fillna('') == df1.PossessionTeam)&(df1.PlayDirection =='left'),  'Max_Yards']\n",
    "    df1.loc[(df1.FieldPosition.fillna('') != df1.PossessionTeam)&(df1.PlayDirection =='right'),  'Max_Yards'] \\\n",
    "    = 100 - df1.loc[(df1.FieldPosition.fillna('') != df1.PossessionTeam)&(df1.PlayDirection =='right'),  'Max_Yards']\n",
    "\n",
    "# min_time_to_tacke\n",
    "    df3['Min_Time_Tacke'] = (df3['Distance_to_Rusher']+0.01)/(df3['S']+0.01)\n",
    "    df3.loc[df3['Min_Time_Tacke'] == np.inf, 'Min_Time_Tacke'] = 20\n",
    "\n",
    "# defence_X_Y_spread\n",
    "    Defence_X_Y_std = df3[[\"PlayId\",'New_X','New_Y']].groupby(\"PlayId\").std().rename(columns={'New_X':'Defense_X_std','New_Y':'Defense_Y_std'}) \\\n",
    "    .reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed2_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed2_std'}).reset_index()\n",
    "\n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_Y_Removed2_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(4).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_X_Removed4_std = df3[[\"PlayId\",'New_X']].drop(np.hstack([df3.groupby('PlayId').tail(2).index, df3.groupby('PlayId').head(2).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Defense_X_Removed4_std'}).reset_index()\n",
    "    \n",
    "    df3 = df3.sort_values(['PlayId','New_X'])\n",
    "    Defense_Y_Removed4_std = df3[[\"PlayId\",'New_Y']].drop(np.hstack([df3.groupby('PlayId').tail(4).index, df3.groupby('PlayId').head(0).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Defense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Defence_X_Y_std, how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Defense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "\n",
    "#distance to QB\n",
    "    dis_QB = df2.loc[df2[\"Position\"] =='QB',['PlayId','Distance_to_Rusher']].groupby(['PlayId']).mean().rename(columns={'Distance_to_Rusher':'dis_to_QB'})\n",
    "    df1 = df1.merge(dis_QB,how = 'left', on='PlayId')\n",
    "\n",
    "#defence min,max,mean,std distance to rusher\n",
    "    stat = df3.groupby(['GameId','PlayId']).agg({'Distance_to_Rusher':['min','max','mean','std']})\n",
    "    stat.columns = stat.columns.droplevel()\n",
    "    df1 = df1.merge(stat,how = 'left', on='PlayId')\n",
    "\n",
    "# offense_X_Y_spread\n",
    "    df2 = df2.sort_values(['PlayId','New_X'])\n",
    "    Offense_X_Removed2_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed2_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed2_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(1).index, df2.groupby('PlayId').head(1).index]))\\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed2_std'}).reset_index()\n",
    "    \n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_X_Removed4_std = df2[[\"PlayId\",'New_X']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_X':'Offense_X_Removed4_std'}).reset_index()\n",
    "    df2 = df2.sort_values(['PlayId','New_Y'])\n",
    "    Offense_Y_Removed4_std = df2[[\"PlayId\",'New_Y']].drop(np.hstack([df2.groupby('PlayId').tail(2).index, df2.groupby('PlayId').head(2).index])) \\\n",
    "    .groupby('PlayId').std().rename(columns={'New_Y':'Offense_Y_Removed4_std'}).reset_index()\n",
    "    df1 = df1.merge(Offense_X_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed2_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_X_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    df1 = df1.merge(Offense_Y_Removed4_std,how = 'left',  on ='PlayId')\n",
    "    \n",
    "# nearest offenders to defender\n",
    "    dis_to_closest_offender = pd.DataFrame()\n",
    "    dis_to_closest_defender = pd.DataFrame()\n",
    "    for playid in df3['PlayId'].unique():\n",
    "        offense = df2.loc[df2['PlayId'] == playid]\n",
    "        defence = df3.loc[df3['PlayId'] == playid]\n",
    "        ary = scipy.spatial.distance.cdist(defence[['New_X','New_Y']], offense[['New_X','New_Y']], metric='euclidean')\n",
    "        ary.sort(axis=1)\n",
    "        ary = pd.DataFrame(data = ary)\n",
    "        ary['PlayId'] = playid\n",
    "        ary.reset_index(drop=True, inplace=True)\n",
    "        ary = pd.concat([ary, defence[['NflId']].reset_index(drop=True)], axis=1)\n",
    "        dis_to_closest_offender = dis_to_closest_offender.append(ary)\n",
    "        \n",
    "        ary = scipy.spatial.distance.cdist(offense[['New_X','New_Y']], defence[['New_X','New_Y']],  metric='euclidean')\n",
    "        ary.sort(axis=1)\n",
    "        ary = pd.DataFrame(data = ary)\n",
    "        ary['PlayId'] = playid\n",
    "        ary.reset_index(drop=True, inplace=True)\n",
    "        ary = pd.concat([ary, offense[['NflId']].reset_index(drop=True)], axis=1)\n",
    "        dis_to_closest_defender = dis_to_closest_defender.append(ary)\n",
    "    df3 = df3.merge(dis_to_closest_offender,how = 'left',on = ['PlayId','NflId'])\n",
    "    df2 = df2.merge(dis_to_closest_defender,how = 'left',on = ['PlayId','NflId'])\n",
    "\n",
    "#degree to closest offender\n",
    "    def Degree(x1,x2,y1,y2):\n",
    "        try:\n",
    "            tan = (y1-y2)/(x1-x2)\n",
    "        except:\n",
    "            tan = 0\n",
    "        degree = 90 - math.atan(tan)/(2*np.pi)*360\n",
    "        return degree\n",
    "    df4 = df3.merge(df2, how = 'left', on = ['PlayId',0],suffixes=('_defender', '_offender'))\n",
    "    df4['degree_to_closest_offender'] = df4[['New_X_offender','New_X_defender','New_Y_offender','New_Y_defender']].apply(lambda x: Degree(x[0],x[1],x[2],x[3]), axis = 1)\n",
    "    df3['degree_to_closest_offender'] = df4['degree_to_closest_offender']\n",
    "\n",
    "# personnel_features\n",
    "    def defense_formation(l):\n",
    "        dl = 0\n",
    "        lb = 0\n",
    "        db = 0\n",
    "        other = 0\n",
    "\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            if sub_string[1] == 'DL':\n",
    "                dl += int(sub_string[0])\n",
    "            elif sub_string[1] in ['LB','OL']:\n",
    "                lb += int(sub_string[0])\n",
    "            else:\n",
    "                db += int(sub_string[0])\n",
    "\n",
    "        counts = (dl,lb,db,other)\n",
    "\n",
    "        return counts\n",
    "    def offense_formation(l):\n",
    "        qb = 0\n",
    "        rb = 0\n",
    "        wr = 0\n",
    "        te = 0\n",
    "        ol = 0\n",
    "\n",
    "        sub_total = 0\n",
    "        qb_listed = False\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            pos = sub_string[1]\n",
    "            cnt = int(sub_string[0])\n",
    "\n",
    "            if pos == 'QB':\n",
    "                qb += cnt\n",
    "                sub_total += cnt\n",
    "                qb_listed = True\n",
    "            # Assuming LB is a line backer lined up as full back\n",
    "            elif pos in ['RB','LB']:\n",
    "                rb += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DB is a defensive back and lined up as WR\n",
    "            elif pos in ['WR','DB']:\n",
    "                wr += cnt\n",
    "                sub_total += cnt\n",
    "            elif pos == 'TE':\n",
    "                te += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DL is a defensive lineman lined up as an additional line man\n",
    "            else:\n",
    "                ol += cnt\n",
    "                sub_total += cnt\n",
    "\n",
    "        # If not all 11 players were noted at given positions we need to make some assumptions\n",
    "        # I will assume if a QB is not listed then there was 1 QB on the play\n",
    "        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n",
    "        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n",
    "        if sub_total < 11:\n",
    "            diff = 11 - sub_total\n",
    "            if not qb_listed:\n",
    "                qb += 1\n",
    "                diff -= 1\n",
    "            ol += diff\n",
    "\n",
    "        counts = (qb,rb,wr,te,ol)\n",
    "\n",
    "        return counts\n",
    "    def split_personnel(s):\n",
    "        splits = s.split(',')\n",
    "        for i in range(len(splits)):\n",
    "            splits[i] = splits[i].strip()\n",
    "\n",
    "        return splits    \n",
    "    def personnel_features(df):\n",
    "        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n",
    "        personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n",
    "\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n",
    "        personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n",
    "        personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n",
    "        personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n",
    "        personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n",
    "        personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n",
    "\n",
    "        # Let's create some features to specify if the OL is covered\n",
    "        personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n",
    "        personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n",
    "        # Let's create a feature to specify if the defense is preventing the run\n",
    "        # Let's just assume 7 or more DL and LB is run prevention\n",
    "        personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n",
    "\n",
    "        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n",
    "        \n",
    "        return personnel\n",
    "    \n",
    "    personnel = personnel_features(df1)   \n",
    "    df1 = df1.merge(personnel,how = 'left',  on ='PlayId')\n",
    "    \n",
    "# Gap\n",
    "    temp = df3.drop(df3[(df3['Position'].isin(['FS','S','SS'])) & (df3['Distance_to_Rusher']>15)].index)\n",
    "    temp = df3.merge(df.loc[df['IsRusher'],['PlayId','Dir_std']]\\\n",
    "                      .rename(columns={'Dir_std':'Rusher_Dir'}), on = 'PlayId',how = 'left')\n",
    "\n",
    "\n",
    "    op_up = temp[((temp['Rusher_Dir']<90)|(temp['Rusher_Dir']>270))&(temp['New_Y']>=temp['Rusher_Y'])]\n",
    "    op_up = op_up.sort_values(['PlayId','New_Y'])\n",
    "    op_up[['Next_Y','Next_X']] = op_up[['New_Y','New_X']].shift(1,axis = 0)\n",
    "    op_up['Gap'] = op_up['New_Y'] - op_up['Next_Y']\n",
    "    op_up = op_up[op_up['Gap'] > 0]\n",
    "    closest_op_up = op_up[['PlayId','Gap']].groupby('PlayId').head(1).reset_index()\n",
    "    best_up = op_up[['PlayId','Gap']].groupby('PlayId').max().reset_index()\n",
    "    def_num_up = op_up[['PlayId','Gap']].rename(columns={'Gap': 'num_def'}).groupby('PlayId').count().reset_index()\n",
    "\n",
    "    op_down = temp[(~((temp['Rusher_Dir']<90)|(temp['Rusher_Dir']>270)))&(temp['New_Y']<temp['Rusher_Y'])]\n",
    "    op_down = op_down.sort_values(['PlayId','New_Y'])\n",
    "    op_down[['Next_Y','Next_X']] = op_down[['New_Y','New_X']].shift(1,axis = 0)\n",
    "    op_down['Gap'] = op_down['New_Y'] - op_down['Next_Y']\n",
    "    closest_op_down = op_down[['PlayId','Gap']].groupby('PlayId').tail(1).reset_index()\n",
    "    best_down = op_down[['PlayId','Gap']].groupby('PlayId').max().reset_index()\n",
    "    def_num_down = op_down[['PlayId','Gap']].rename(columns={'Gap': 'num_def'}).groupby('PlayId').count().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    closest_op = closest_op_up.append(closest_op_down).rename(columns = {'Gap':'Closet_Gap'})\n",
    "    best = best_up.append(best_down).rename(columns = {'Gap':'Best_Gap'})\n",
    "    df1 = df1.merge(closest_op, on='PlayId',how = 'left')\n",
    "    df1 = df1.merge(best, on='PlayId',how = 'left')\n",
    "#select useful columns    \n",
    "    rusher = df1[['PlayId','TimeDelta','Team','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y', \\\n",
    "                 'Orientation_std','Dir_std','Dis_YardLine','Horizontal Speed','Vertical Speed','S','A','Dis','Position',\\\n",
    "                 'Quarter','GameClock','Down','Distance','OffenseFormation',\\\n",
    "                  'DefendersInTheBox','HomeScoreBeforePlay','VisitorScoreBeforePlay',\\\n",
    "                 'Offense_X_Removed2_std','Offense_Y_Removed2_std','Offense_X_Removed4_std','Offense_Y_Removed4_std',\\\n",
    "                 'Defense_X_std','Defense_Y_std','Defense_X_Removed2_std','Defense_Y_Removed2_std','Defense_X_Removed4_std',\\\n",
    "                 'Defense_Y_Removed4_std',\\\n",
    "                  'num_DL','num_LB','num_DB','num_QB','num_RB','num_WR','num_TE','num_OL','OL_diff','OL_TE_diff','run_def',\\\n",
    "                 'min','max','std','mean','dis_to_QB','Max_Yards','DiffScoreBeforePlay_ob','Closet_Gap','Best_Gap']]\n",
    "    rusher = rusher.sort_values('PlayId')\n",
    "    game = df1[['PlayId','Cleaned_GameWeather']]\n",
    "    game = game.sort_values('PlayId')\n",
    "    offender = df2[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff']]\n",
    "    offender = offender.sort_values(['PlayId','Distance_to_Rusher'])\n",
    "    defender = df3[['PlayId','PlayerAge','PlayerHeight','PlayerWeight','New_X','New_Y','Orientation_std','Dir_std',\\\n",
    "                  'Horizontal Speed','Vertical Speed','S','A','Dis','Position','Distance_to_Rusher',\\\n",
    "                   'Degree_to_Rusher','Degree_Diff','Min_Time_Tacke','Speed_Ratio','degree_to_closest_offender']+list(range(2))] #list(range(2)) two closest offenders\n",
    "    defender = defender.sort_values(['PlayId','Distance_to_Rusher'])\n",
    "\n",
    "    \n",
    "    return rusher, game, offender, defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "rusher, game, offender, defender = split_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove some columns\n",
    "rusher = rusher.drop('max',axis = 1)\n",
    "\n",
    "offender = offender.sort_values(['PlayId','Distance_to_Rusher']).groupby('PlayId').head(2)\n",
    "\n",
    "defender = defender.sort_values(['PlayId','Distance_to_Rusher']).drop(['New_Y','Position'],axis = 1).groupby('PlayId').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACE', 'C', 'CB', 'DE', 'DT', 'EMPTY', 'FB', 'G', 'HB', 'I_FORM',\n",
       "       'JUMBO', 'NT', 'OG', 'OLB', 'OT', 'PISTOL', 'QB', 'RB', 'SHOTGUN',\n",
       "       'SINGLEBACK', 'T', 'TE', 'WILDCAT', 'WR', 'away', 'home', 'nan'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding fit\n",
    "le = preprocessing.LabelEncoder()\n",
    "categories =[]\n",
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = rusher[i].astype(str)\n",
    "    categories.append(rusher[i].unique())\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = game[i].astype(str)\n",
    "    categories.append(game[i].unique())\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = offender[i].astype(str)\n",
    "    categories.append(offender[i].unique())\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = defender[i].astype(str)\n",
    "    categories.append(defender[i].unique())\n",
    "categories = np.hstack(categories)\n",
    "le.fit(categories)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding transform\n",
    "for i in rusher.dtypes[rusher.dtypes=='object'].index.tolist():\n",
    "    rusher[i] = le.transform(rusher[i])\n",
    "\n",
    "for i in game.dtypes[game.dtypes=='object'].index.tolist():\n",
    "    game[i] = le.transform(game[i])\n",
    "\n",
    "for i in offender.dtypes[offender.dtypes=='object'].index.tolist():\n",
    "    offender[i] = le.transform(offender[i])\n",
    "\n",
    "for i in defender.dtypes[defender.dtypes=='object'].index.tolist():\n",
    "    defender[i] = le.transform(defender[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape offender\n",
    "offender_players = [offender.drop('PlayId',axis = 1).iloc[np.arange(k, len(offender), 2)].reset_index(drop = True) for k in range(2)]\n",
    "offender_players = np.hstack([t.values for t in offender_players])\n",
    "offender_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 114)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape defender\n",
    "defender_players = [defender.drop('PlayId',axis = 1).iloc[np.arange(k, len(defender), 6)].reset_index(drop = True) for k in range(6)]\n",
    "defender_players = np.hstack([t.values for t in defender_players])\n",
    "defender_players.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 54)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusher.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_y =train.loc[train['IsRusher'],['Yards','PlayId']].sort_values('PlayId').drop('PlayId',axis = 1)\n",
    "train_x = np.hstack([rusher.drop('PlayId',axis = 1).values,defender_players,offender_players])\n",
    "train_y99 =(train_y + 99).reset_index(drop=True).Yards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def crps_eval(y_pred, dataset, is_higher_better=False):\n",
    "    labels = dataset.get_label()\n",
    "    labels = labels.astype('int')\n",
    "    y_true = np.zeros((len(labels),199))\n",
    "    for i, v in enumerate(labels):\n",
    "        y_true[i, v:] = 1\n",
    "    y_pred = y_pred.reshape(-1, 199, order='F')\n",
    "    y_pred = np.clip(y_pred.cumsum(axis=1), 0, 1)\n",
    "    return 'crps', np.mean((y_pred - y_true)**2), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "params = {'max_depth':5, 'lambda_l1': 1.4, 'lambda_l2': 1.2,\n",
    " 'num_leaves': 32, 'feature_fraction': 0.4,\n",
    " 'subsample': 0.4, 'min_child_samples': 15,\n",
    " 'learning_rate': 0.02,\n",
    " 'num_iterations': 10000, 'random_state': 42,\n",
    " 'objective': 'multiclass',\n",
    " 'min_gain_to_split':0.9,\n",
    " 'num_class':199,\n",
    " 'metric':'None'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-01c6e8be79d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                               feval=crps_eval)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1926\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_x)):\n",
    "        tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "        vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "        dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "        dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "        model = lgb.train(params, dtrain,\n",
    "                              num_boost_round=100000,\n",
    "                              valid_sets=[dtrain,dvalid],\n",
    "                              early_stopping_rounds=10,\n",
    "                              verbose_eval=100,\n",
    "                              feval=crps_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012891320000000001\n",
      "0.01277846\n",
      "0.01278668\n",
      "0.012749759999999999\n",
      "0.012697579999999997\n"
     ]
    }
   ],
   "source": [
    "#CV score\n",
    "# for leave out one feature importance compare\n",
    "print(np.mean([0.0129045,0.0128677,0.0127771,0.0127333,0.013174]))\n",
    "\n",
    "# 5 closest defense palyer drop 'New_Y','back_oriented_down_field',max\n",
    "print(np.mean([0.0128208, 0.0127364, 0.0126515, 0.0126222,0.0130614]))\n",
    "\n",
    "# all defense palyer\n",
    "print(np.mean([0.012802,0.0127486,0.0126934,0.0126226,0.0130668]))\n",
    "\n",
    "# 5 closest defender + 2 closest offender l1,l2 = 1.2\n",
    "print(np.mean([0.0127868,0.0127041,0.0126144,0.0125952,0.0130483]))\n",
    "\n",
    "# 6 closest defender + 2 closest offender with new feature\n",
    "print(np.mean([0.0127472, 0.0126321, 0.012575, 0.0125473, 0.0129863]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rusher = pd.DataFrame(rusher)\n",
    "X_Dense = rusher[['Dis_YardLine','PlayerAge','PlayerHeight','PlayerWeight', \\\n",
    "            'Orientation_std','Dir_std','New_X','New_Y','Horizontal Speed',\\\n",
    "            'Vertical Speed','S','A','Dis','GameClock',\\\n",
    "            'Distance','Max_Yards',\\\n",
    "            'Defense_X_std','Defense_Y_std','Defense_X_Removed2_std',\\\n",
    "            'Offense_Y_Removed2_std',\\\n",
    "            'min','std','mean','Max_Yards','dis_to_QB',\\\n",
    "            'HomeScoreBeforePlay','VisitorScoreBeforePlay',\\\n",
    "            \"DiffScoreBeforePlay_ob\",'Quarter','Down','Closet_Gap','Best_Gap']]\n",
    "X_Dense = X_Dense.fillna(0)\n",
    "yards = train.loc[train['IsRusher'],['Yards','PlayId']].\\\n",
    "sort_values('PlayId').drop('PlayId',axis = 1).Yards\n",
    "\n",
    "y = np.zeros((yards.shape[0], 199))\n",
    "for idx, target in enumerate(list(yards)):\n",
    "    y[idx][99 + target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import re\n",
    "from keras.losses import binary_crossentropy\n",
    "from  keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import codecs\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CRPSCallback(Callback):\n",
    "    \n",
    "    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n",
    "        super(CRPSCallback, self).__init__()\n",
    "        self.validation = validation\n",
    "        self.predict_batch_size = predict_batch_size\n",
    "        self.include_on_batch = include_on_batch\n",
    "        \n",
    "        print('validation shape',len(self.validation))\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('CRPS_score_val' in self.params['metrics']):\n",
    "            self.params['metrics'].append('CRPS_score_val')\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if (self.include_on_batch):\n",
    "            logs['CRPS_score_val'] = float('-inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['CRPS_score_val'] = float('-inf')\n",
    "            \n",
    "        if (self.validation):\n",
    "            X_valid, y_valid = self.validation[0], self.validation[1]\n",
    "            y_pred = self.model.predict(X_valid)\n",
    "            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "            val_s = np.round(val_s, 6)\n",
    "            logs['CRPS_score_val'] = val_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_tr,y_tr,x_val,y_val):\n",
    "    inp = Input(shape = (x_tr.shape[1],))\n",
    "    x = Dense(1024, input_dim=X.shape[1], activation='relu')(inp)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    out = Dense(199, activation='softmax')(x)\n",
    "    model = Model(inp,out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n",
    "    #add lookahead\n",
    "#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n",
    "#     lookahead.inject(model) # add into model\n",
    "\n",
    "    \n",
    "    es = EarlyStopping(monitor='CRPS_score_val', \n",
    "                       mode='min',\n",
    "                       restore_best_weights=True, \n",
    "                       verbose=1, \n",
    "                       patience=10)\n",
    "\n",
    "    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n",
    "                                   save_best_only=True, verbose=1, save_weights_only=True)\n",
    "    \n",
    "    bsz = 1024\n",
    "    steps = x_tr.shape[0]/bsz\n",
    "    \n",
    "\n",
    "\n",
    "    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=100, batch_size=bsz,verbose=1)\n",
    "    model.load_weights(\"best_model.h5\")\n",
    "    \n",
    "    y_pred = model.predict(x_val)\n",
    "    y_valid = y_val\n",
    "    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n",
    "    crps = np.round(val_s, 6)\n",
    "\n",
    "    return model,crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/100\n",
      "18536/18536 [==============================] - ETA: 11s - loss: 5.87 - ETA: 6s - loss: 5.8481 - ETA: 4s - loss: 5.831 - ETA: 3s - loss: 5.810 - ETA: 2s - loss: 5.795 - ETA: 2s - loss: 5.770 - ETA: 1s - loss: 5.757 - ETA: 1s - loss: 5.746 - ETA: 1s - loss: 5.733 - ETA: 1s - loss: 5.715 - ETA: 1s - loss: 5.709 - ETA: 0s - loss: 5.694 - ETA: 0s - loss: 5.680 - ETA: 0s - loss: 5.661 - ETA: 0s - loss: 5.648 - ETA: 0s - loss: 5.634 - ETA: 0s - loss: 5.617 - ETA: 0s - loss: 5.601 - 2s 120us/step - loss: 5.6005\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08286, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 5.322 - ETA: 1s - loss: 5.253 - ETA: 1s - loss: 5.226 - ETA: 1s - loss: 5.201 - ETA: 1s - loss: 5.202 - ETA: 1s - loss: 5.199 - ETA: 0s - loss: 5.182 - ETA: 0s - loss: 5.174 - ETA: 0s - loss: 5.174 - ETA: 0s - loss: 5.165 - ETA: 0s - loss: 5.151 - ETA: 0s - loss: 5.146 - ETA: 0s - loss: 5.136 - ETA: 0s - loss: 5.127 - ETA: 0s - loss: 5.121 - ETA: 0s - loss: 5.112 - ETA: 0s - loss: 5.100 - ETA: 0s - loss: 5.088 - 2s 90us/step - loss: 5.0885\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08286 to 0.07717, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 4.835 - ETA: 1s - loss: 4.806 - ETA: 1s - loss: 4.800 - ETA: 1s - loss: 4.781 - ETA: 1s - loss: 4.789 - ETA: 1s - loss: 4.780 - ETA: 1s - loss: 4.769 - ETA: 0s - loss: 4.758 - ETA: 0s - loss: 4.755 - ETA: 0s - loss: 4.749 - ETA: 0s - loss: 4.742 - ETA: 0s - loss: 4.731 - ETA: 0s - loss: 4.722 - ETA: 0s - loss: 4.715 - ETA: 0s - loss: 4.700 - ETA: 0s - loss: 4.677 - ETA: 0s - loss: 4.667 - ETA: 0s - loss: 4.659 - 2s 91us/step - loss: 4.6578\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.07717 to 0.06500, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 4.474 - ETA: 1s - loss: 4.441 - ETA: 1s - loss: 4.420 - ETA: 1s - loss: 4.405 - ETA: 1s - loss: 4.388 - ETA: 1s - loss: 4.371 - ETA: 1s - loss: 4.353 - ETA: 0s - loss: 4.344 - ETA: 0s - loss: 4.324 - ETA: 0s - loss: 4.315 - ETA: 0s - loss: 4.310 - ETA: 0s - loss: 4.294 - ETA: 0s - loss: 4.289 - ETA: 0s - loss: 4.279 - ETA: 0s - loss: 4.267 - ETA: 0s - loss: 4.258 - ETA: 0s - loss: 4.247 - ETA: 0s - loss: 4.237 - 2s 91us/step - loss: 4.2362\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.06500 to 0.04513, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 4.071 - ETA: 1s - loss: 4.031 - ETA: 1s - loss: 4.030 - ETA: 1s - loss: 4.018 - ETA: 1s - loss: 3.999 - ETA: 1s - loss: 3.994 - ETA: 1s - loss: 3.988 - ETA: 0s - loss: 3.982 - ETA: 0s - loss: 3.968 - ETA: 0s - loss: 3.953 - ETA: 0s - loss: 3.950 - ETA: 0s - loss: 3.937 - ETA: 0s - loss: 3.915 - ETA: 0s - loss: 3.909 - ETA: 0s - loss: 3.907 - ETA: 0s - loss: 3.895 - ETA: 0s - loss: 3.882 - ETA: 0s - loss: 3.870 - 2s 91us/step - loss: 3.8707\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.04513 to 0.02830, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 3.629 - ETA: 1s - loss: 3.658 - ETA: 1s - loss: 3.662 - ETA: 1s - loss: 3.639 - ETA: 1s - loss: 3.631 - ETA: 1s - loss: 3.622 - ETA: 1s - loss: 3.610 - ETA: 0s - loss: 3.608 - ETA: 0s - loss: 3.606 - ETA: 0s - loss: 3.600 - ETA: 0s - loss: 3.595 - ETA: 0s - loss: 3.589 - ETA: 0s - loss: 3.582 - ETA: 0s - loss: 3.572 - ETA: 0s - loss: 3.573 - ETA: 0s - loss: 3.567 - ETA: 0s - loss: 3.560 - ETA: 0s - loss: 3.550 - 2s 99us/step - loss: 3.5493\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.02830 to 0.01922, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 3.382 - ETA: 1s - loss: 3.390 - ETA: 1s - loss: 3.363 - ETA: 1s - loss: 3.349 - ETA: 1s - loss: 3.347 - ETA: 1s - loss: 3.335 - ETA: 1s - loss: 3.330 - ETA: 0s - loss: 3.324 - ETA: 0s - loss: 3.312 - ETA: 0s - loss: 3.305 - ETA: 0s - loss: 3.298 - ETA: 0s - loss: 3.288 - ETA: 0s - loss: 3.286 - ETA: 0s - loss: 3.280 - ETA: 0s - loss: 3.279 - ETA: 0s - loss: 3.281 - ETA: 0s - loss: 3.274 - ETA: 0s - loss: 3.270 - 2s 94us/step - loss: 3.2705\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01922 to 0.01525, saving model to best_model.h5\n",
      "Epoch 8/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 3.103 - ETA: 1s - loss: 3.140 - ETA: 1s - loss: 3.117 - ETA: 1s - loss: 3.124 - ETA: 1s - loss: 3.125 - ETA: 1s - loss: 3.119 - ETA: 1s - loss: 3.117 - ETA: 0s - loss: 3.116 - ETA: 0s - loss: 3.117 - ETA: 0s - loss: 3.113 - ETA: 0s - loss: 3.111 - ETA: 0s - loss: 3.105 - ETA: 0s - loss: 3.101 - ETA: 0s - loss: 3.103 - ETA: 0s - loss: 3.102 - ETA: 0s - loss: 3.102 - ETA: 0s - loss: 3.100 - ETA: 0s - loss: 3.093 - 2s 93us/step - loss: 3.0932\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01525 to 0.01390, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "10240/18536 [===============>..............] - ETA: 1s - loss: 3.026 - ETA: 1s - loss: 2.976 - ETA: 1s - loss: 2.985 - ETA: 1s - loss: 2.961 - ETA: 1s - loss: 2.967 - ETA: 1s - loss: 2.960 - ETA: 1s - loss: 2.963 - ETA: 0s - loss: 2.970 - ETA: 0s - loss: 2.972 - ETA: 0s - loss: 2.9782"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-22f10fc01272>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcrps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"the %d fold crps is %f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcrps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-dfa7820fa62f>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCRPSCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbsz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d = defender[['PlayId','S','A','Horizontal Speed','Vertical Speed']].fillna(0)\n",
    "d = [d.drop('PlayId',axis = 1).iloc[np.arange(k, len(d), 6)].reset_index(drop = True) for k in range(6)]\n",
    "d = np.hstack([t.values for t in d])\n",
    "\n",
    "\n",
    "\n",
    "X = np.hstack([X_Dense,d])\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import time\n",
    "\n",
    "losses = []\n",
    "models = []\n",
    "crps_csv = []\n",
    "\n",
    "s_time = time.time()\n",
    "\n",
    "\n",
    "for k in range(1):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n",
    "        print(\"-----------\")\n",
    "        print(\"-----------\")\n",
    "        tr_x,tr_y = X[tr_inds],y[tr_inds]\n",
    "        val_x,val_y = X[val_inds],y[val_inds]\n",
    "        model,crps = get_model(tr_x,tr_y,val_x,val_y)\n",
    "        models.append(model)\n",
    "        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n",
    "        crps_csv.append(crps)\n",
    " \n",
    "print(\"mean crps is %f\"%np.mean(crps_csv))\n",
    "\n",
    "\n",
    "def predict(x_te):\n",
    "    model_num = len(models)\n",
    "    for k,m in enumerate(models):\n",
    "        if k==0:\n",
    "            y_pred = m.predict(x_te,batch_size=1024)\n",
    "        else:\n",
    "            y_pred+=m.predict(x_te,batch_size=1024)\n",
    "            \n",
    "    y_pred = y_pred / model_num\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_opt(oof_nn, oof_rf, y_true):\n",
    "    weight_nn = np.inf\n",
    "    best_crps = np.inf\n",
    "    \n",
    "    for i in np.arange(0, 1.01, 0.05):\n",
    "        crps_blend = np.zeros(oof_nn.shape[0])\n",
    "        for k in range(oof_nn.shape[0]):\n",
    "            crps_blend[k] = crps_score(i * oof_nn[k,...] + (1-i) * oof_rf[k,...], y_true)\n",
    "        if np.mean(crps_blend) < best_crps:\n",
    "            best_crps = np.mean(crps_blend)\n",
    "            weight_nn = round(i, 2)\n",
    "            \n",
    "        print(str(round(i, 2)) + ' : mean crps (Blend) is ', round(np.mean(crps_blend), 6))\n",
    "        \n",
    "    print('-'*36)\n",
    "    print('Best weight for NN: ', weight_nn)\n",
    "    print('Best weight for LGBM: ', round(1-weight_nn, 2))\n",
    "#     print('Best weight for RF: ', round(1-weight_nn, 2))\n",
    "    print('Best mean crps (Blend): ', round(best_crps, 6))\n",
    "    \n",
    "    return weight_nn, round(1-weight_nn, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation shape 2\n",
      "Epoch 1/100\n",
      "18536/18536 [==============================] - ETA: 12s - loss: 5.85 - ETA: 6s - loss: 5.8509 - ETA: 4s - loss: 5.832 - ETA: 3s - loss: 5.815 - ETA: 3s - loss: 5.805 - ETA: 2s - loss: 5.790 - ETA: 2s - loss: 5.777 - ETA: 1s - loss: 5.762 - ETA: 1s - loss: 5.749 - ETA: 1s - loss: 5.735 - ETA: 1s - loss: 5.720 - ETA: 0s - loss: 5.706 - ETA: 0s - loss: 5.691 - ETA: 0s - loss: 5.675 - ETA: 0s - loss: 5.659 - ETA: 0s - loss: 5.645 - ETA: 0s - loss: 5.630 - ETA: 0s - loss: 5.619 - 3s 141us/step - loss: 5.6185\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08303, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 5.325 - ETA: 1s - loss: 5.283 - ETA: 1s - loss: 5.280 - ETA: 1s - loss: 5.263 - ETA: 1s - loss: 5.252 - ETA: 1s - loss: 5.248 - ETA: 1s - loss: 5.227 - ETA: 1s - loss: 5.213 - ETA: 1s - loss: 5.197 - ETA: 0s - loss: 5.193 - ETA: 0s - loss: 5.182 - ETA: 0s - loss: 5.173 - ETA: 0s - loss: 5.157 - ETA: 0s - loss: 5.148 - ETA: 0s - loss: 5.137 - ETA: 0s - loss: 5.130 - ETA: 0s - loss: 5.114 - ETA: 0s - loss: 5.101 - 2s 130us/step - loss: 5.1006\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08303 to 0.07767, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 4.803 - ETA: 2s - loss: 4.809 - ETA: 1s - loss: 4.790 - ETA: 1s - loss: 4.772 - ETA: 1s - loss: 4.767 - ETA: 1s - loss: 4.772 - ETA: 1s - loss: 4.781 - ETA: 1s - loss: 4.764 - ETA: 1s - loss: 4.754 - ETA: 1s - loss: 4.747 - ETA: 0s - loss: 4.743 - ETA: 0s - loss: 4.731 - ETA: 0s - loss: 4.718 - ETA: 0s - loss: 4.710 - ETA: 0s - loss: 4.698 - ETA: 0s - loss: 4.696 - ETA: 0s - loss: 4.686 - ETA: 0s - loss: 4.672 - 2s 126us/step - loss: 4.6715\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.07767 to 0.06572, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 4.418 - ETA: 2s - loss: 4.365 - ETA: 1s - loss: 4.364 - ETA: 1s - loss: 4.383 - ETA: 1s - loss: 4.358 - ETA: 1s - loss: 4.350 - ETA: 1s - loss: 4.347 - ETA: 1s - loss: 4.334 - ETA: 1s - loss: 4.331 - ETA: 1s - loss: 4.320 - ETA: 0s - loss: 4.310 - ETA: 0s - loss: 4.295 - ETA: 0s - loss: 4.291 - ETA: 0s - loss: 4.282 - ETA: 0s - loss: 4.271 - ETA: 0s - loss: 4.254 - ETA: 0s - loss: 4.244 - ETA: 0s - loss: 4.240 - 2s 127us/step - loss: 4.2409\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.06572 to 0.04635, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 4.017 - ETA: 1s - loss: 3.976 - ETA: 1s - loss: 3.995 - ETA: 1s - loss: 4.012 - ETA: 1s - loss: 3.988 - ETA: 1s - loss: 3.970 - ETA: 1s - loss: 3.961 - ETA: 1s - loss: 3.949 - ETA: 1s - loss: 3.942 - ETA: 0s - loss: 3.946 - ETA: 0s - loss: 3.939 - ETA: 0s - loss: 3.923 - ETA: 0s - loss: 3.910 - ETA: 0s - loss: 3.901 - ETA: 0s - loss: 3.895 - ETA: 0s - loss: 3.886 - ETA: 0s - loss: 3.880 - ETA: 0s - loss: 3.872 - 2s 118us/step - loss: 3.8726\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.04635 to 0.02935, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 3.623 - ETA: 1s - loss: 3.633 - ETA: 1s - loss: 3.625 - ETA: 1s - loss: 3.620 - ETA: 1s - loss: 3.632 - ETA: 1s - loss: 3.641 - ETA: 1s - loss: 3.645 - ETA: 1s - loss: 3.632 - ETA: 1s - loss: 3.625 - ETA: 0s - loss: 3.618 - ETA: 0s - loss: 3.604 - ETA: 0s - loss: 3.594 - ETA: 0s - loss: 3.583 - ETA: 0s - loss: 3.583 - ETA: 0s - loss: 3.571 - ETA: 0s - loss: 3.562 - ETA: 0s - loss: 3.559 - ETA: 0s - loss: 3.553 - 2s 118us/step - loss: 3.5528\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.02935 to 0.01935, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 3.283 - ETA: 1s - loss: 3.330 - ETA: 1s - loss: 3.337 - ETA: 1s - loss: 3.343 - ETA: 1s - loss: 3.353 - ETA: 1s - loss: 3.341 - ETA: 1s - loss: 3.342 - ETA: 1s - loss: 3.344 - ETA: 1s - loss: 3.339 - ETA: 0s - loss: 3.334 - ETA: 0s - loss: 3.322 - ETA: 0s - loss: 3.318 - ETA: 0s - loss: 3.308 - ETA: 0s - loss: 3.306 - ETA: 0s - loss: 3.299 - ETA: 0s - loss: 3.291 - ETA: 0s - loss: 3.284 - ETA: 0s - loss: 3.280 - 2s 119us/step - loss: 3.2819\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01935 to 0.01528, saving model to best_model.h5\n",
      "Epoch 8/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 3.113 - ETA: 1s - loss: 3.132 - ETA: 1s - loss: 3.116 - ETA: 1s - loss: 3.137 - ETA: 1s - loss: 3.135 - ETA: 1s - loss: 3.123 - ETA: 1s - loss: 3.123 - ETA: 1s - loss: 3.120 - ETA: 1s - loss: 3.120 - ETA: 0s - loss: 3.108 - ETA: 0s - loss: 3.109 - ETA: 0s - loss: 3.100 - ETA: 0s - loss: 3.093 - ETA: 0s - loss: 3.093 - ETA: 0s - loss: 3.093 - ETA: 0s - loss: 3.091 - ETA: 0s - loss: 3.087 - ETA: 0s - loss: 3.083 - 2s 117us/step - loss: 3.0848\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01528 to 0.01372, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.972 - ETA: 1s - loss: 2.988 - ETA: 1s - loss: 2.995 - ETA: 1s - loss: 3.012 - ETA: 1s - loss: 3.003 - ETA: 1s - loss: 2.986 - ETA: 1s - loss: 2.980 - ETA: 1s - loss: 2.973 - ETA: 1s - loss: 2.974 - ETA: 0s - loss: 2.975 - ETA: 0s - loss: 2.977 - ETA: 0s - loss: 2.982 - ETA: 0s - loss: 2.976 - ETA: 0s - loss: 2.979 - ETA: 0s - loss: 2.972 - ETA: 0s - loss: 2.974 - ETA: 0s - loss: 2.967 - ETA: 0s - loss: 2.964 - 2s 117us/step - loss: 2.9647\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01372 to 0.01305, saving model to best_model.h5\n",
      "Epoch 10/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.942 - ETA: 1s - loss: 2.949 - ETA: 1s - loss: 2.943 - ETA: 1s - loss: 2.936 - ETA: 1s - loss: 2.930 - ETA: 1s - loss: 2.926 - ETA: 1s - loss: 2.919 - ETA: 1s - loss: 2.920 - ETA: 1s - loss: 2.914 - ETA: 0s - loss: 2.916 - ETA: 0s - loss: 2.910 - ETA: 0s - loss: 2.902 - ETA: 0s - loss: 2.908 - ETA: 0s - loss: 2.903 - ETA: 0s - loss: 2.900 - ETA: 0s - loss: 2.903 - ETA: 0s - loss: 2.905 - ETA: 0s - loss: 2.900 - 2s 121us/step - loss: 2.9002\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01305 to 0.01276, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.836 - ETA: 1s - loss: 2.793 - ETA: 1s - loss: 2.791 - ETA: 1s - loss: 2.817 - ETA: 1s - loss: 2.830 - ETA: 1s - loss: 2.831 - ETA: 1s - loss: 2.833 - ETA: 1s - loss: 2.837 - ETA: 1s - loss: 2.836 - ETA: 0s - loss: 2.845 - ETA: 0s - loss: 2.845 - ETA: 0s - loss: 2.847 - ETA: 0s - loss: 2.848 - ETA: 0s - loss: 2.846 - ETA: 0s - loss: 2.849 - ETA: 0s - loss: 2.848 - ETA: 0s - loss: 2.849 - ETA: 0s - loss: 2.852 - 2s 122us/step - loss: 2.8532\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01276 to 0.01265, saving model to best_model.h5\n",
      "Epoch 12/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.826 - ETA: 1s - loss: 2.829 - ETA: 1s - loss: 2.835 - ETA: 1s - loss: 2.838 - ETA: 1s - loss: 2.835 - ETA: 1s - loss: 2.827 - ETA: 1s - loss: 2.833 - ETA: 1s - loss: 2.832 - ETA: 1s - loss: 2.835 - ETA: 0s - loss: 2.827 - ETA: 0s - loss: 2.832 - ETA: 0s - loss: 2.835 - ETA: 0s - loss: 2.831 - ETA: 0s - loss: 2.827 - ETA: 0s - loss: 2.828 - ETA: 0s - loss: 2.823 - ETA: 0s - loss: 2.822 - ETA: 0s - loss: 2.823 - 2s 121us/step - loss: 2.8223\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01265 to 0.01259, saving model to best_model.h5\n",
      "Epoch 13/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.798 - ETA: 1s - loss: 2.826 - ETA: 1s - loss: 2.805 - ETA: 1s - loss: 2.807 - ETA: 1s - loss: 2.824 - ETA: 1s - loss: 2.815 - ETA: 1s - loss: 2.805 - ETA: 1s - loss: 2.798 - ETA: 1s - loss: 2.803 - ETA: 0s - loss: 2.807 - ETA: 0s - loss: 2.803 - ETA: 0s - loss: 2.807 - ETA: 0s - loss: 2.808 - ETA: 0s - loss: 2.809 - ETA: 0s - loss: 2.808 - ETA: 0s - loss: 2.809 - ETA: 0s - loss: 2.808 - ETA: 0s - loss: 2.803 - 2s 122us/step - loss: 2.8041\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01259 to 0.01252, saving model to best_model.h5\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 1s - loss: 2.800 - ETA: 1s - loss: 2.783 - ETA: 1s - loss: 2.761 - ETA: 1s - loss: 2.782 - ETA: 1s - loss: 2.781 - ETA: 1s - loss: 2.783 - ETA: 1s - loss: 2.778 - ETA: 1s - loss: 2.777 - ETA: 1s - loss: 2.776 - ETA: 0s - loss: 2.774 - ETA: 0s - loss: 2.771 - ETA: 0s - loss: 2.774 - ETA: 0s - loss: 2.776 - ETA: 0s - loss: 2.772 - ETA: 0s - loss: 2.768 - ETA: 0s - loss: 2.772 - ETA: 0s - loss: 2.774 - ETA: 0s - loss: 2.774 - 2s 117us/step - loss: 2.7749\n",
      "\n",
      "Epoch 00014: CRPS_score_val improved from 0.01252 to 0.01249, saving model to best_model.h5\n",
      "Epoch 15/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.812 - ETA: 1s - loss: 2.801 - ETA: 1s - loss: 2.773 - ETA: 1s - loss: 2.762 - ETA: 1s - loss: 2.766 - ETA: 1s - loss: 2.776 - ETA: 1s - loss: 2.771 - ETA: 1s - loss: 2.762 - ETA: 1s - loss: 2.759 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.752 - ETA: 0s - loss: 2.755 - ETA: 0s - loss: 2.758 - ETA: 0s - loss: 2.755 - ETA: 0s - loss: 2.758 - ETA: 0s - loss: 2.759 - ETA: 0s - loss: 2.761 - ETA: 0s - loss: 2.761 - 2s 117us/step - loss: 2.7610\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01249 to 0.01246, saving model to best_model.h5\n",
      "Epoch 16/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.730 - ETA: 1s - loss: 2.748 - ETA: 1s - loss: 2.758 - ETA: 1s - loss: 2.736 - ETA: 1s - loss: 2.749 - ETA: 1s - loss: 2.763 - ETA: 1s - loss: 2.771 - ETA: 1s - loss: 2.773 - ETA: 1s - loss: 2.768 - ETA: 0s - loss: 2.764 - ETA: 0s - loss: 2.760 - ETA: 0s - loss: 2.761 - ETA: 0s - loss: 2.756 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.752 - ETA: 0s - loss: 2.753 - ETA: 0s - loss: 2.750 - ETA: 0s - loss: 2.751 - 2s 116us/step - loss: 2.7510\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01246 to 0.01242, saving model to best_model.h5\n",
      "Epoch 17/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.766 - ETA: 1s - loss: 2.759 - ETA: 1s - loss: 2.742 - ETA: 1s - loss: 2.732 - ETA: 1s - loss: 2.733 - ETA: 1s - loss: 2.742 - ETA: 1s - loss: 2.745 - ETA: 1s - loss: 2.743 - ETA: 1s - loss: 2.745 - ETA: 0s - loss: 2.738 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.740 - ETA: 0s - loss: 2.739 - ETA: 0s - loss: 2.737 - ETA: 0s - loss: 2.736 - ETA: 0s - loss: 2.739 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.734 - 2s 116us/step - loss: 2.7347\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01242 to 0.01241, saving model to best_model.h5\n",
      "Epoch 18/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.808 - ETA: 1s - loss: 2.723 - ETA: 1s - loss: 2.721 - ETA: 1s - loss: 2.708 - ETA: 1s - loss: 2.705 - ETA: 1s - loss: 2.716 - ETA: 1s - loss: 2.725 - ETA: 1s - loss: 2.721 - ETA: 1s - loss: 2.723 - ETA: 0s - loss: 2.727 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.724 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.722 - ETA: 0s - loss: 2.729 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.726 - ETA: 0s - loss: 2.728 - 2s 115us/step - loss: 2.7285\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01241 to 0.01237, saving model to best_model.h5\n",
      "Epoch 19/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.688 - ETA: 1s - loss: 2.706 - ETA: 1s - loss: 2.710 - ETA: 1s - loss: 2.731 - ETA: 1s - loss: 2.727 - ETA: 1s - loss: 2.730 - ETA: 1s - loss: 2.735 - ETA: 1s - loss: 2.732 - ETA: 1s - loss: 2.734 - ETA: 0s - loss: 2.734 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.733 - ETA: 0s - loss: 2.729 - ETA: 0s - loss: 2.724 - ETA: 0s - loss: 2.723 - ETA: 0s - loss: 2.724 - ETA: 0s - loss: 2.721 - ETA: 0s - loss: 2.721 - 2s 119us/step - loss: 2.7214\n",
      "\n",
      "Epoch 00019: CRPS_score_val improved from 0.01237 to 0.01235, saving model to best_model.h5\n",
      "Epoch 20/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.661 - ETA: 1s - loss: 2.689 - ETA: 1s - loss: 2.686 - ETA: 1s - loss: 2.673 - ETA: 1s - loss: 2.694 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.702 - ETA: 1s - loss: 2.704 - ETA: 0s - loss: 2.704 - ETA: 0s - loss: 2.700 - ETA: 0s - loss: 2.697 - ETA: 0s - loss: 2.703 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.705 - ETA: 0s - loss: 2.708 - ETA: 0s - loss: 2.708 - ETA: 0s - loss: 2.710 - 2s 116us/step - loss: 2.7096\n",
      "\n",
      "Epoch 00020: CRPS_score_val did not improve from 0.01235\n",
      "Epoch 21/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.741 - ETA: 1s - loss: 2.716 - ETA: 1s - loss: 2.697 - ETA: 1s - loss: 2.714 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.721 - ETA: 1s - loss: 2.720 - ETA: 1s - loss: 2.712 - ETA: 1s - loss: 2.718 - ETA: 0s - loss: 2.720 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.711 - ETA: 0s - loss: 2.713 - ETA: 0s - loss: 2.713 - ETA: 0s - loss: 2.714 - ETA: 0s - loss: 2.712 - ETA: 0s - loss: 2.710 - ETA: 0s - loss: 2.709 - 2s 117us/step - loss: 2.7089\n",
      "\n",
      "Epoch 00021: CRPS_score_val improved from 0.01235 to 0.01235, saving model to best_model.h5\n",
      "Epoch 22/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.768 - ETA: 1s - loss: 2.742 - ETA: 1s - loss: 2.698 - ETA: 1s - loss: 2.700 - ETA: 1s - loss: 2.696 - ETA: 1s - loss: 2.695 - ETA: 1s - loss: 2.691 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.683 - ETA: 0s - loss: 2.685 - ETA: 0s - loss: 2.694 - ETA: 0s - loss: 2.697 - ETA: 0s - loss: 2.693 - ETA: 0s - loss: 2.695 - ETA: 0s - loss: 2.692 - ETA: 0s - loss: 2.695 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.692 - 2s 117us/step - loss: 2.6919\n",
      "\n",
      "Epoch 00022: CRPS_score_val improved from 0.01235 to 0.01233, saving model to best_model.h5\n",
      "Epoch 23/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.685 - ETA: 1s - loss: 2.690 - ETA: 1s - loss: 2.692 - ETA: 1s - loss: 2.682 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.683 - ETA: 1s - loss: 2.684 - ETA: 1s - loss: 2.686 - ETA: 0s - loss: 2.688 - ETA: 0s - loss: 2.690 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.691 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.687 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.684 - ETA: 0s - loss: 2.684 - 2s 117us/step - loss: 2.6846\n",
      "\n",
      "Epoch 00023: CRPS_score_val improved from 0.01233 to 0.01232, saving model to best_model.h5\n",
      "Epoch 24/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.716 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.662 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.680 - ETA: 1s - loss: 2.678 - ETA: 1s - loss: 2.682 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.672 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.677 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.681 - ETA: 0s - loss: 2.680 - 2s 119us/step - loss: 2.6805\n",
      "\n",
      "Epoch 00024: CRPS_score_val did not improve from 0.01232\n",
      "Epoch 25/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.654 - ETA: 1s - loss: 2.671 - ETA: 1s - loss: 2.658 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.654 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.664 - ETA: 1s - loss: 2.665 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.664 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.670 - ETA: 0s - loss: 2.672 - 2s 117us/step - loss: 2.6715\n",
      "\n",
      "Epoch 00025: CRPS_score_val improved from 0.01232 to 0.01231, saving model to best_model.h5\n",
      "Epoch 26/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.600 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.655 - ETA: 1s - loss: 2.661 - ETA: 1s - loss: 2.668 - ETA: 1s - loss: 2.670 - ETA: 1s - loss: 2.669 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.670 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.668 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.673 - ETA: 0s - loss: 2.674 - ETA: 0s - loss: 2.676 - ETA: 0s - loss: 2.672 - 2s 117us/step - loss: 2.6728\n",
      "\n",
      "Epoch 00026: CRPS_score_val improved from 0.01231 to 0.01230, saving model to best_model.h5\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 2s - loss: 2.586 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.663 - ETA: 1s - loss: 2.665 - ETA: 1s - loss: 2.656 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.663 - ETA: 0s - loss: 2.665 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.667 - ETA: 0s - loss: 2.669 - ETA: 0s - loss: 2.671 - ETA: 0s - loss: 2.672 - 2s 117us/step - loss: 2.6715\n",
      "\n",
      "Epoch 00027: CRPS_score_val did not improve from 0.01230\n",
      "Epoch 28/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.672 - ETA: 1s - loss: 2.666 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.647 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.643 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.656 - ETA: 0s - loss: 2.658 - ETA: 0s - loss: 2.659 - ETA: 0s - loss: 2.661 - 2s 117us/step - loss: 2.6613\n",
      "\n",
      "Epoch 00028: CRPS_score_val did not improve from 0.01230\n",
      "Epoch 29/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.612 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.651 - ETA: 1s - loss: 2.649 - ETA: 1s - loss: 2.660 - ETA: 1s - loss: 2.659 - ETA: 1s - loss: 2.656 - ETA: 1s - loss: 2.660 - ETA: 0s - loss: 2.660 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.653 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.655 - ETA: 0s - loss: 2.654 - ETA: 0s - loss: 2.657 - 2s 117us/step - loss: 2.6577\n",
      "\n",
      "Epoch 00029: CRPS_score_val did not improve from 0.01230\n",
      "Epoch 30/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.665 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.630 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.641 - ETA: 0s - loss: 2.646 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.644 - ETA: 0s - loss: 2.645 - 2s 121us/step - loss: 2.6460\n",
      "\n",
      "Epoch 00030: CRPS_score_val improved from 0.01230 to 0.01229, saving model to best_model.h5\n",
      "Epoch 31/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.628 - ETA: 1s - loss: 2.634 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.640 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.645 - ETA: 0s - loss: 2.647 - ETA: 0s - loss: 2.648 - ETA: 0s - loss: 2.650 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.650 - 2s 117us/step - loss: 2.6510\n",
      "\n",
      "Epoch 00031: CRPS_score_val improved from 0.01229 to 0.01228, saving model to best_model.h5\n",
      "Epoch 32/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.644 - ETA: 1s - loss: 2.653 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.626 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.631 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.630 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.635 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.640 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.636 - 2s 117us/step - loss: 2.6383\n",
      "\n",
      "Epoch 00032: CRPS_score_val did not improve from 0.01228\n",
      "Epoch 33/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.650 - ETA: 1s - loss: 2.616 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.622 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.635 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.638 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.639 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.638 - 2s 117us/step - loss: 2.6395\n",
      "\n",
      "Epoch 00033: CRPS_score_val did not improve from 0.01228\n",
      "Epoch 34/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.635 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.640 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.631 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.636 - ETA: 0s - loss: 2.636 - 2s 117us/step - loss: 2.6363\n",
      "\n",
      "Epoch 00034: CRPS_score_val improved from 0.01228 to 0.01227, saving model to best_model.h5\n",
      "Epoch 35/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.676 - ETA: 1s - loss: 2.645 - ETA: 1s - loss: 2.643 - ETA: 1s - loss: 2.638 - ETA: 1s - loss: 2.635 - ETA: 1s - loss: 2.637 - ETA: 1s - loss: 2.636 - ETA: 1s - loss: 2.629 - ETA: 1s - loss: 2.628 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.631 - ETA: 0s - loss: 2.634 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.632 - ETA: 0s - loss: 2.633 - 2s 117us/step - loss: 2.6336\n",
      "\n",
      "Epoch 00035: CRPS_score_val improved from 0.01227 to 0.01226, saving model to best_model.h5\n",
      "Epoch 36/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.627 - ETA: 1s - loss: 2.612 - ETA: 1s - loss: 2.613 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.620 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.624 - 2s 120us/step - loss: 2.6241\n",
      "\n",
      "Epoch 00036: CRPS_score_val improved from 0.01226 to 0.01226, saving model to best_model.h5\n",
      "Epoch 37/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.609 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.614 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.618 - ETA: 1s - loss: 2.613 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.619 - 2s 116us/step - loss: 2.6202\n",
      "\n",
      "Epoch 00037: CRPS_score_val improved from 0.01226 to 0.01225, saving model to best_model.h5\n",
      "Epoch 38/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.537 - ETA: 1s - loss: 2.566 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.621 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.625 - ETA: 1s - loss: 2.624 - ETA: 1s - loss: 2.625 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.619 - 2s 118us/step - loss: 2.6186\n",
      "\n",
      "Epoch 00038: CRPS_score_val did not improve from 0.01225\n",
      "Epoch 39/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.678 - ETA: 1s - loss: 2.652 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.646 - ETA: 1s - loss: 2.641 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.633 - ETA: 1s - loss: 2.631 - ETA: 1s - loss: 2.621 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.610 - 2s 118us/step - loss: 2.6110\n",
      "\n",
      "Epoch 00039: CRPS_score_val did not improve from 0.01225\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 2s - loss: 2.569 - ETA: 1s - loss: 2.560 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.589 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.591 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.607 - ETA: 0s - loss: 2.607 - ETA: 0s - loss: 2.607 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.606 - 2s 117us/step - loss: 2.6073\n",
      "\n",
      "Epoch 00040: CRPS_score_val did not improve from 0.01225\n",
      "Epoch 41/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.574 - ETA: 1s - loss: 2.555 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.596 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.599 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.596 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.605 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.604 - 2s 121us/step - loss: 2.6035\n",
      "\n",
      "Epoch 00041: CRPS_score_val did not improve from 0.01225\n",
      "Epoch 42/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.596 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.605 - ETA: 1s - loss: 2.610 - ETA: 1s - loss: 2.609 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.613 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.606 - ETA: 0s - loss: 2.604 - ETA: 0s - loss: 2.601 - ETA: 0s - loss: 2.602 - ETA: 0s - loss: 2.600 - 2s 117us/step - loss: 2.6012\n",
      "\n",
      "Epoch 00042: CRPS_score_val did not improve from 0.01225\n",
      "Epoch 43/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.602 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.586 - ETA: 1s - loss: 2.588 - ETA: 1s - loss: 2.595 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.591 - ETA: 0s - loss: 2.592 - ETA: 0s - loss: 2.592 - ETA: 0s - loss: 2.595 - ETA: 0s - loss: 2.598 - ETA: 0s - loss: 2.597 - ETA: 0s - loss: 2.596 - 2s 117us/step - loss: 2.5964\n",
      "\n",
      "Epoch 00043: CRPS_score_val did not improve from 0.01225\n",
      "Epoch 44/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.615 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.587 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.571 - ETA: 1s - loss: 2.575 - ETA: 0s - loss: 2.576 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.578 - ETA: 0s - loss: 2.579 - ETA: 0s - loss: 2.583 - 2s 118us/step - loss: 2.5839\n",
      "\n",
      "Epoch 00044: CRPS_score_val did not improve from 0.01225\n",
      "Epoch 45/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.600 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.582 - ETA: 1s - loss: 2.583 - ETA: 1s - loss: 2.579 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.584 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.590 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.585 - ETA: 0s - loss: 2.584 - 2s 117us/step - loss: 2.5845\n",
      "\n",
      "Epoch 00045: CRPS_score_val did not improve from 0.01225\n",
      "Epoch 46/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.590 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.599 - ETA: 1s - loss: 2.608 - ETA: 1s - loss: 2.593 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.575 - ETA: 0s - loss: 2.580 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.576 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.579 - ETA: 0s - loss: 2.581 - ETA: 0s - loss: 2.582 - ETA: 0s - loss: 2.583 - ETA: 0s - loss: 2.583 - 2s 117us/step - loss: 2.5829\n",
      "\n",
      "Epoch 00046: CRPS_score_val did not improve from 0.01225\n",
      "Epoch 47/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.578 - ETA: 1s - loss: 2.559 - ETA: 1s - loss: 2.569 - ETA: 1s - loss: 2.564 - ETA: 1s - loss: 2.570 - ETA: 1s - loss: 2.574 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.581 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.576 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.577 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.575 - 2s 120us/step - loss: 2.5778\n",
      "\n",
      "Epoch 00047: CRPS_score_val improved from 0.01225 to 0.01224, saving model to best_model.h5\n",
      "Epoch 48/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.589 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.591 - ETA: 1s - loss: 2.579 - ETA: 1s - loss: 2.578 - ETA: 1s - loss: 2.566 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.565 - ETA: 0s - loss: 2.566 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.571 - 2s 116us/step - loss: 2.5724\n",
      "\n",
      "Epoch 00048: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 49/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.613 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.611 - ETA: 1s - loss: 2.584 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.577 - ETA: 1s - loss: 2.580 - ETA: 1s - loss: 2.575 - ETA: 1s - loss: 2.576 - ETA: 0s - loss: 2.574 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.572 - ETA: 0s - loss: 2.571 - ETA: 0s - loss: 2.575 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.573 - ETA: 0s - loss: 2.574 - 2s 117us/step - loss: 2.5739\n",
      "\n",
      "Epoch 00049: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 50/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.538 - ETA: 1s - loss: 2.525 - ETA: 1s - loss: 2.542 - ETA: 1s - loss: 2.561 - ETA: 1s - loss: 2.566 - ETA: 1s - loss: 2.572 - ETA: 1s - loss: 2.576 - ETA: 1s - loss: 2.568 - ETA: 1s - loss: 2.569 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.570 - ETA: 0s - loss: 2.568 - ETA: 0s - loss: 2.569 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.567 - ETA: 0s - loss: 2.563 - ETA: 0s - loss: 2.565 - ETA: 0s - loss: 2.563 - 2s 116us/step - loss: 2.5645\n",
      "\n",
      "Epoch 00050: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 51/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.551 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.546 - ETA: 1s - loss: 2.549 - ETA: 1s - loss: 2.555 - ETA: 1s - loss: 2.553 - ETA: 1s - loss: 2.558 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.553 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.556 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.558 - ETA: 0s - loss: 2.559 - ETA: 0s - loss: 2.560 - ETA: 0s - loss: 2.562 - ETA: 0s - loss: 2.562 - 2s 116us/step - loss: 2.5621\n",
      "\n",
      "Epoch 00051: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 52/100\n",
      "18536/18536 [==============================] - ETA: 1s - loss: 2.506 - ETA: 1s - loss: 2.519 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.533 - ETA: 1s - loss: 2.546 - ETA: 1s - loss: 2.542 - ETA: 1s - loss: 2.546 - ETA: 1s - loss: 2.550 - ETA: 1s - loss: 2.550 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.555 - ETA: 0s - loss: 2.558 - 2s 118us/step - loss: 2.5576\n",
      "\n",
      "Epoch 00052: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 53/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.523 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.538 - ETA: 1s - loss: 2.538 - ETA: 1s - loss: 2.553 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.551 - ETA: 1s - loss: 2.557 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.545 - ETA: 0s - loss: 2.541 - ETA: 0s - loss: 2.543 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.547 - 2s 120us/step - loss: 2.5464\n",
      "\n",
      "Epoch 00053: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18536/18536 [==============================] - ETA: 2s - loss: 2.577 - ETA: 2s - loss: 2.543 - ETA: 1s - loss: 2.523 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.531 - ETA: 1s - loss: 2.531 - ETA: 1s - loss: 2.528 - ETA: 1s - loss: 2.530 - ETA: 1s - loss: 2.530 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.533 - ETA: 0s - loss: 2.536 - ETA: 0s - loss: 2.537 - ETA: 0s - loss: 2.545 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.540 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.543 - 2s 118us/step - loss: 2.5446\n",
      "\n",
      "Epoch 00054: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 55/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.518 - ETA: 1s - loss: 2.532 - ETA: 1s - loss: 2.545 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.547 - ETA: 1s - loss: 2.550 - ETA: 1s - loss: 2.562 - ETA: 1s - loss: 2.555 - ETA: 1s - loss: 2.554 - ETA: 0s - loss: 2.545 - ETA: 0s - loss: 2.551 - ETA: 0s - loss: 2.554 - ETA: 0s - loss: 2.550 - ETA: 0s - loss: 2.553 - ETA: 0s - loss: 2.549 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.546 - 2s 116us/step - loss: 2.5471\n",
      "\n",
      "Epoch 00055: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 56/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.564 - ETA: 1s - loss: 2.552 - ETA: 1s - loss: 2.545 - ETA: 1s - loss: 2.545 - ETA: 1s - loss: 2.534 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.531 - ETA: 1s - loss: 2.533 - ETA: 1s - loss: 2.534 - ETA: 0s - loss: 2.531 - ETA: 0s - loss: 2.534 - ETA: 0s - loss: 2.541 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.545 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.542 - 2s 117us/step - loss: 2.5419\n",
      "\n",
      "Epoch 00056: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 57/100\n",
      "18536/18536 [==============================] - ETA: 2s - loss: 2.538 - ETA: 1s - loss: 2.544 - ETA: 1s - loss: 2.557 - ETA: 1s - loss: 2.541 - ETA: 1s - loss: 2.535 - ETA: 1s - loss: 2.539 - ETA: 1s - loss: 2.539 - ETA: 1s - loss: 2.538 - ETA: 1s - loss: 2.544 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.547 - ETA: 0s - loss: 2.544 - ETA: 0s - loss: 2.543 - ETA: 0s - loss: 2.543 - ETA: 0s - loss: 2.542 - ETA: 0s - loss: 2.541 - ETA: 0s - loss: 2.539 - ETA: 0s - loss: 2.536 - 2s 117us/step - loss: 2.5369\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00057: CRPS_score_val did not improve from 0.01224\n",
      "Epoch 00057: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's crps: 0.0128141\tvalid_1's crps: 0.0127408\n",
      "[200]\ttraining's crps: 0.0116616\tvalid_1's crps: 0.0124411\n",
      "[300]\ttraining's crps: 0.0109536\tvalid_1's crps: 0.0123218\n",
      "[400]\ttraining's crps: 0.0104986\tvalid_1's crps: 0.0122661\n",
      "[500]\ttraining's crps: 0.0101922\tvalid_1's crps: 0.0122348\n",
      "[600]\ttraining's crps: 0.00995145\tvalid_1's crps: 0.0122163\n",
      "[700]\ttraining's crps: 0.00976035\tvalid_1's crps: 0.0122016\n",
      "[800]\ttraining's crps: 0.00962853\tvalid_1's crps: 0.0121928\n",
      "[900]\ttraining's crps: 0.00954672\tvalid_1's crps: 0.0121881\n",
      "[1000]\ttraining's crps: 0.00949577\tvalid_1's crps: 0.0121845\n",
      "Early stopping, best iteration is:\n",
      "[1033]\ttraining's crps: 0.00948658\tvalid_1's crps: 0.0121836\n"
     ]
    }
   ],
   "source": [
    "weight_nn_list =[]\n",
    "kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n",
    "\n",
    "    \n",
    "    tr_x,tr_y = X[tr_inds],y[tr_inds]\n",
    "    val_x,val_y = X[val_inds],y[val_inds]\n",
    "    model2,crps = get_model(tr_x,tr_y,val_x,val_y)\n",
    "    ann_score = model2.predict(val_x)\n",
    "    ann_score = np.clip(ann_score.cumsum(axis=1), 0, 1)\n",
    "    \n",
    "    tr_x, tr_y = train_x[tr_inds], train_y99[tr_inds]    \n",
    "    vl_x, v_y = train_x[val_inds], train_y99[val_inds] \n",
    "    dtrain = lgb.Dataset(tr_x, label= tr_y)\n",
    "    dvalid = lgb.Dataset(vl_x, label= v_y)\n",
    "    model1 = lgb.train(params, dtrain,\n",
    "                              num_boost_round=100000,\n",
    "                              early_stopping_rounds=10,\n",
    "                                valid_sets=[dtrain,dvalid],\n",
    "                              verbose_eval=100,\n",
    "                              feval=crps_eval)\n",
    "    lgbm_score = model1.predict(vl_x)\n",
    "    lgbm_score = np.clip(lgbm_score.cumsum(axis=1), 0, 1)\n",
    "    \n",
    "    weight_nn = np.inf\n",
    "    best_crps = np.inf    \n",
    "    \n",
    "    real_y = np.zeros((len(v_y),199))\n",
    "    for g, v in enumerate(v_y):\n",
    "        real_y[g, v:] = 1\n",
    "    \n",
    "    for i in np.arange(0, 1.01, 0.05):\n",
    "        crps_blend = np.zeros(val_x.shape[0])\n",
    "        for k in range(val_x.shape[0]):\n",
    "            crps_blend[k] = np.mean(( np.clip((i * lgbm_score[k,...] + (1-i) * ann_score[k,...]), 0, 1) - real_y)**2)\n",
    "        if np.mean(crps_blend) < best_crps:\n",
    "            best_crps = np.mean(crps_blend)\n",
    "            weight_nn = round(i, 2)\n",
    "            \n",
    "    print(str(round(i, 2)) + ' : mean crps (Blend) is ', round(np.mean(crps_blend), 6))\n",
    "\n",
    "    print('-'*36)\n",
    "    print('Best weight for NN: ', weight_nn)\n",
    "    weight_nn_list.append(weight_nn)\n",
    "    print('Best weight for LGBM: ', round(1-weight_nn, 2))\n",
    "    #     print('Best weight for RF: ', round(1-weight_nn, 2))\n",
    "    print('Best mean crps (Blend): ', round(best_crps, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-ee8d727e1881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcrps_blend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mcrps_blend\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlgbm_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mann_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mreal_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrps_blend\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_crps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mbest_crps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrps_blend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   3116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3117\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 3118\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   3119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         ret = um.true_divide(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "real_y = np.zeros((len(v_y),199))\n",
    "for g, v in enumerate(v_y):\n",
    "    real_y[g, v:] = 1\n",
    "for i in np.arange(0, 1.01, 0.05):\n",
    "        crps_blend = np.zeros(val_x.shape[0])\n",
    "        for k in range(val_x.shape[0]):\n",
    "            crps_blend[k] = np.mean(( np.clip((i * lgbm_score[k,...] + (1-i) * ann_score[k,...]), 0, 1) - real_y)**2)\n",
    "        if np.mean(crps_blend) < best_crps:\n",
    "            best_crps = np.mean(crps_blend)\n",
    "            weight_nn = round(i, 2)\n",
    "            \n",
    "print(str(round(i, 2)) + ' : mean crps (Blend) is ', round(np.mean(crps_blend), 6))\n",
    "\n",
    "print('-'*36)\n",
    "print('Best weight for NN: ', weight_nn)\n",
    "weight_nn_list.append(weight_nn)\n",
    "print('Best weight for LGBM: ', round(1-weight_nn, 2))\n",
    "#     print('Best weight for RF: ', round(1-weight_nn, 2))\n",
    "print('Best mean crps (Blend): ', round(best_crps, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.35997665e-12, 6.32606910e-12, 1.62753728e-11, ...,\n",
       "        9.99929774e-01, 9.99932516e-01, 1.00000000e+00],\n",
       "       [1.35997665e-12, 6.32606910e-12, 1.62753728e-11, ...,\n",
       "        9.99929774e-01, 9.99932516e-01, 1.00000000e+00],\n",
       "       [1.35997665e-12, 6.32606910e-12, 1.62753728e-11, ...,\n",
       "        9.99929774e-01, 9.99932516e-01, 1.00000000e+00],\n",
       "       ...,\n",
       "       [1.35997665e-12, 6.32606910e-12, 1.62753728e-11, ...,\n",
       "        9.99929774e-01, 9.99932516e-01, 1.00000000e+00],\n",
       "       [1.35997665e-12, 6.32606910e-12, 1.62753728e-11, ...,\n",
       "        9.99929774e-01, 9.99932516e-01, 1.00000000e+00],\n",
       "       [1.35997665e-12, 6.32606910e-12, 1.62753728e-11, ...,\n",
       "        9.99929774e-01, 9.99932516e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( np.clip((i * lgbm_score[k,...] + (1-i) * ann_score[k,...]), 0, 1) - val_y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
